{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "a911ad1e-d244-4721-8954-4cf418a5865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import  CatBoostClassifier\n",
    "from lightgbm import  LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "627673fb-7141-408c-9298-30680b9db1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>branch</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>unusuallogin</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>Acct type</th>\n",
       "      <th>Date of transaction</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>3/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>India</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>5/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>India</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>Australia</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>6/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Australia</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>6/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>337.50</td>\n",
       "      <td>C1494306005</td>\n",
       "      <td>33107.0</td>\n",
       "      <td>32769.50</td>\n",
       "      <td>M1424027000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>3/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>5003.57</td>\n",
       "      <td>C1633890169</td>\n",
       "      <td>32769.5</td>\n",
       "      <td>27765.93</td>\n",
       "      <td>M1854745805</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>5/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Panama</td>\n",
       "      <td>10424.89</td>\n",
       "      <td>C1026138669</td>\n",
       "      <td>50780.0</td>\n",
       "      <td>40355.11</td>\n",
       "      <td>M1852900317</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Night</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2823.59</td>\n",
       "      <td>C378659213</td>\n",
       "      <td>986.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M301812950</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>6/1/2018</td>\n",
       "      <td>Night</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>8126.71</td>\n",
       "      <td>C1639296014</td>\n",
       "      <td>6423.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M129774606</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>2/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10125 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           type     branch    amount     nameOrig  oldbalanceOrg  \\\n",
       "0       PAYMENT  Indonesia   9839.64  C1231006815       170136.0   \n",
       "1       PAYMENT      India   1864.28  C1666544295        21249.0   \n",
       "2      TRANSFER      India    181.00  C1305486145          181.0   \n",
       "3      CASH_OUT  Australia    181.00   C840083671          181.0   \n",
       "4       PAYMENT  Australia  11668.14  C2048537720        41554.0   \n",
       "...         ...        ...       ...          ...            ...   \n",
       "10120   PAYMENT       Cuba    337.50  C1494306005        33107.0   \n",
       "10121   PAYMENT     Mexico   5003.57  C1633890169        32769.5   \n",
       "10122   PAYMENT     Panama  10424.89  C1026138669        50780.0   \n",
       "10123   PAYMENT     Mexico   2823.59   C378659213          986.0   \n",
       "10124   PAYMENT       Cuba   8126.71  C1639296014         6423.0   \n",
       "\n",
       "       newbalanceOrig     nameDest  unusuallogin  isFlaggedFraud Acct type  \\\n",
       "0           160296.36  M1979787155             9               0   Current   \n",
       "1            19384.72  M2044282225            10               0   Savings   \n",
       "2                0.00   C553264065             2               0   Current   \n",
       "3                0.00    C38997010             1               0   Current   \n",
       "4            29885.86  M1230701703            17               0   Current   \n",
       "...               ...          ...           ...             ...       ...   \n",
       "10120        32769.50  M1424027000             7               0   Current   \n",
       "10121        27765.93  M1854745805            11               0   Savings   \n",
       "10122        40355.11  M1852900317             6               0   Savings   \n",
       "10123            0.00   M301812950            12               0   Savings   \n",
       "10124            0.00   M129774606            11               0   Current   \n",
       "\n",
       "      Date of transaction Time of day  isFraud  \n",
       "0                3/1/2018     Morning        0  \n",
       "1                5/1/2018     Morning        0  \n",
       "2                7/1/2018     Morning        1  \n",
       "3                6/1/2018   Afternoon        1  \n",
       "4                6/1/2018     Morning        0  \n",
       "...                   ...         ...      ...  \n",
       "10120            3/1/2018   Afternoon        0  \n",
       "10121            5/1/2018     Morning        0  \n",
       "10122            7/1/2018       Night        0  \n",
       "10123            6/1/2018       Night        0  \n",
       "10124            2/1/2018   Afternoon        0  \n",
       "\n",
       "[10125 rows x 13 columns]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(r'C:\\Users\\Aysel Quliyeva\\Desktop\\data science with python\\lesson 19\\fraud_data.xlsx')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "ce4037f5-0b9f-4bda-a2db-9dc3832f4f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>branch</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>unusuallogin</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>Acct type</th>\n",
       "      <th>Date of transaction</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10125</td>\n",
       "      <td>10125</td>\n",
       "      <td>1.012500e+04</td>\n",
       "      <td>10125</td>\n",
       "      <td>1.012500e+04</td>\n",
       "      <td>1.012500e+04</td>\n",
       "      <td>10125</td>\n",
       "      <td>10125.000000</td>\n",
       "      <td>10125.0</td>\n",
       "      <td>10125</td>\n",
       "      <td>10125</td>\n",
       "      <td>10125</td>\n",
       "      <td>10125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C10001825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C985934102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Savings</td>\n",
       "      <td>6/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5544</td>\n",
       "      <td>1282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6995</td>\n",
       "      <td>1453</td>\n",
       "      <td>3628</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.048873e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.836949e+05</td>\n",
       "      <td>9.046314e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.513580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.706366e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.124555e+06</td>\n",
       "      <td>2.170130e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.809393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.107330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.390000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.397580e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.290000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.279882e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.136300e+04</td>\n",
       "      <td>1.019179e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.143818e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.724320e+05</td>\n",
       "      <td>1.707442e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.290000e+07</td>\n",
       "      <td>1.300000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           type          branch        amount   nameOrig  oldbalanceOrg  \\\n",
       "count     10125           10125  1.012500e+04      10125   1.012500e+04   \n",
       "unique        5             135           NaN      10119            NaN   \n",
       "top     PAYMENT  Estados Unidos           NaN  C10001825            NaN   \n",
       "freq       5544            1282           NaN          7            NaN   \n",
       "mean        NaN             NaN  1.048873e+05        NaN   8.836949e+05   \n",
       "std         NaN             NaN  2.706366e+05        NaN   2.124555e+06   \n",
       "min         NaN             NaN  2.390000e+00        NaN   0.000000e+00   \n",
       "25%         NaN             NaN  4.397580e+03        NaN   1.290000e+02   \n",
       "50%         NaN             NaN  1.279882e+04        NaN   2.136300e+04   \n",
       "75%         NaN             NaN  1.143818e+05        NaN   1.724320e+05   \n",
       "max         NaN             NaN  1.000000e+07        NaN   1.290000e+07   \n",
       "\n",
       "        newbalanceOrig    nameDest  unusuallogin  isFlaggedFraud Acct type  \\\n",
       "count     1.012500e+04       10125  10125.000000         10125.0     10125   \n",
       "unique             NaN        6494           NaN             NaN         2   \n",
       "top                NaN  C985934102           NaN             NaN   Savings   \n",
       "freq               NaN          68           NaN             NaN      6995   \n",
       "mean      9.046314e+05         NaN     10.513580             0.0       NaN   \n",
       "std       2.170130e+06         NaN      5.809393             0.0       NaN   \n",
       "min       0.000000e+00         NaN      0.000000             0.0       NaN   \n",
       "25%       0.000000e+00         NaN      6.000000             0.0       NaN   \n",
       "50%       1.019179e+04         NaN     10.000000             0.0       NaN   \n",
       "75%       1.707442e+05         NaN     16.000000             0.0       NaN   \n",
       "max       1.300000e+07         NaN     20.000000             0.0       NaN   \n",
       "\n",
       "       Date of transaction Time of day       isFraud  \n",
       "count                10125       10125  10125.000000  \n",
       "unique                  14           3           NaN  \n",
       "top               6/1/2018   Afternoon           NaN  \n",
       "freq                  1453        3628           NaN  \n",
       "mean                   NaN         NaN      0.011654  \n",
       "std                    NaN         NaN      0.107330  \n",
       "min                    NaN         NaN      0.000000  \n",
       "25%                    NaN         NaN      0.000000  \n",
       "50%                    NaN         NaN      0.000000  \n",
       "75%                    NaN         NaN      0.000000  \n",
       "max                    NaN         NaN      1.000000  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "5050a50d-3772-47ec-ac95-61dc889e69be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['nameOrig', 'nameDest', 'branch'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "128d01f1-5272-479d-b7f8-13ea24cd0987",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date of transaction'] = pd.to_datetime(data['Date of transaction'], dayfirst=True)\n",
    "\n",
    "data['transaction_year'] = data['Date of transaction'].dt.year\n",
    "data['transaction_month'] = data['Date of transaction'].dt.month\n",
    "data['transaction_day'] = data['Date of transaction'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "601bd73a-46cb-47a0-8b7b-7d8b2725ae63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-25 00:00:00 2018-01-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(data['Date of transaction'].max(), data['Date of transaction'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "1f17d47e-9a24-412c-865a-d68fdab79204",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Date of transaction', 'transaction_year' ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "2990d85d-893e-464f-bbf2-ef2f668fa587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                 0\n",
       "amount               0\n",
       "oldbalanceOrg        0\n",
       "newbalanceOrig       0\n",
       "unusuallogin         0\n",
       "isFlaggedFraud       0\n",
       "Acct type            0\n",
       "Time of day          0\n",
       "isFraud              0\n",
       "transaction_month    0\n",
       "transaction_day      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "8a4c6ce3-68ec-419b-b193-c94cf9a409bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "ed596966-2154-48f0-8cbd-46264e46890e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>unusuallogin</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>Acct type</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>transaction_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>Morning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>Morning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>Morning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>337.50</td>\n",
       "      <td>33107.0</td>\n",
       "      <td>32769.50</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>5003.57</td>\n",
       "      <td>32769.5</td>\n",
       "      <td>27765.93</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>Morning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>10424.89</td>\n",
       "      <td>50780.0</td>\n",
       "      <td>40355.11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>Night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>2823.59</td>\n",
       "      <td>986.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>Night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>8126.71</td>\n",
       "      <td>6423.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10125 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           type    amount  oldbalanceOrg  newbalanceOrig  unusuallogin  \\\n",
       "0       PAYMENT   9839.64       170136.0       160296.36             9   \n",
       "1       PAYMENT   1864.28        21249.0        19384.72            10   \n",
       "2      TRANSFER    181.00          181.0            0.00             2   \n",
       "3      CASH_OUT    181.00          181.0            0.00             1   \n",
       "4       PAYMENT  11668.14        41554.0        29885.86            17   \n",
       "...         ...       ...            ...             ...           ...   \n",
       "10120   PAYMENT    337.50        33107.0        32769.50             7   \n",
       "10121   PAYMENT   5003.57        32769.5        27765.93            11   \n",
       "10122   PAYMENT  10424.89        50780.0        40355.11             6   \n",
       "10123   PAYMENT   2823.59          986.0            0.00            12   \n",
       "10124   PAYMENT   8126.71         6423.0            0.00            11   \n",
       "\n",
       "       isFlaggedFraud Acct type Time of day  isFraud  transaction_month  \\\n",
       "0                   0   Current     Morning        0                  1   \n",
       "1                   0   Savings     Morning        0                  1   \n",
       "2                   0   Current     Morning        1                  1   \n",
       "3                   0   Current   Afternoon        1                  1   \n",
       "4                   0   Current     Morning        0                  1   \n",
       "...               ...       ...         ...      ...                ...   \n",
       "10120               0   Current   Afternoon        0                  1   \n",
       "10121               0   Savings     Morning        0                  1   \n",
       "10122               0   Savings       Night        0                  1   \n",
       "10123               0   Savings       Night        0                  1   \n",
       "10124               0   Current   Afternoon        0                  1   \n",
       "\n",
       "       transaction_day  \n",
       "0                    3  \n",
       "1                    5  \n",
       "2                    7  \n",
       "3                    6  \n",
       "4                    6  \n",
       "...                ...  \n",
       "10120                3  \n",
       "10121                5  \n",
       "10122                7  \n",
       "10123                6  \n",
       "10124                2  \n",
       "\n",
       "[10125 rows x 11 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "41c6acaa-96ad-4efd-929e-43b2323d4e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                  True\n",
       "amount               False\n",
       "oldbalanceOrg        False\n",
       "newbalanceOrig       False\n",
       "unusuallogin         False\n",
       "isFlaggedFraud       False\n",
       "Acct type             True\n",
       "Time of day           True\n",
       "isFraud              False\n",
       "transaction_month    False\n",
       "transaction_day      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.dtypes==object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "a75b0a61-5493-4b68-8fd1-3a472508d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sütun: type\n",
      "['PAYMENT' 'TRANSFER' 'CASH_OUT' 'DEBIT' 'CASH_IN']\n",
      "\n",
      "Sütun: Acct type\n",
      "['Current' 'Savings']\n",
      "\n",
      "Sütun: Time of day\n",
      "['Morning' 'Afternoon' 'Night']\n"
     ]
    }
   ],
   "source": [
    "cols = ['type', 'Acct type', 'Time of day']\n",
    "\n",
    "for col in cols:\n",
    "    print(f\"\\nSütun: {col}\")\n",
    "    print(new_data[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "d87d8724-7479-4ed1-80be-b83ac0522abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>unusuallogin</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>Acct type</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>transaction_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>3</td>\n",
       "      <td>337.50</td>\n",
       "      <td>33107.0</td>\n",
       "      <td>32769.50</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>3</td>\n",
       "      <td>5003.57</td>\n",
       "      <td>32769.5</td>\n",
       "      <td>27765.93</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>3</td>\n",
       "      <td>10424.89</td>\n",
       "      <td>50780.0</td>\n",
       "      <td>40355.11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>3</td>\n",
       "      <td>2823.59</td>\n",
       "      <td>986.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>3</td>\n",
       "      <td>8126.71</td>\n",
       "      <td>6423.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10125 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type    amount  oldbalanceOrg  newbalanceOrig  unusuallogin  \\\n",
       "0         3   9839.64       170136.0       160296.36             9   \n",
       "1         3   1864.28        21249.0        19384.72            10   \n",
       "2         4    181.00          181.0            0.00             2   \n",
       "3         1    181.00          181.0            0.00             1   \n",
       "4         3  11668.14        41554.0        29885.86            17   \n",
       "...     ...       ...            ...             ...           ...   \n",
       "10120     3    337.50        33107.0        32769.50             7   \n",
       "10121     3   5003.57        32769.5        27765.93            11   \n",
       "10122     3  10424.89        50780.0        40355.11             6   \n",
       "10123     3   2823.59          986.0            0.00            12   \n",
       "10124     3   8126.71         6423.0            0.00            11   \n",
       "\n",
       "       isFlaggedFraud  Acct type  Time of day  isFraud  transaction_month  \\\n",
       "0                   0          0            1        0                  1   \n",
       "1                   0          1            1        0                  1   \n",
       "2                   0          0            1        1                  1   \n",
       "3                   0          0            0        1                  1   \n",
       "4                   0          0            1        0                  1   \n",
       "...               ...        ...          ...      ...                ...   \n",
       "10120               0          0            0        0                  1   \n",
       "10121               0          1            1        0                  1   \n",
       "10122               0          1            2        0                  1   \n",
       "10123               0          1            2        0                  1   \n",
       "10124               0          0            0        0                  1   \n",
       "\n",
       "       transaction_day  \n",
       "0                    3  \n",
       "1                    5  \n",
       "2                    7  \n",
       "3                    6  \n",
       "4                    6  \n",
       "...                ...  \n",
       "10120                3  \n",
       "10121                5  \n",
       "10122                7  \n",
       "10123                6  \n",
       "10124                2  \n",
       "\n",
       "[10125 rows x 11 columns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoders = {}\n",
    "for i in new_data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    new_data[i] = le.fit_transform(new_data[i])\n",
    "    encoders[i] = le\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859eebe-e677-49bc-9677-fa67049fbaa0",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "52f2e5ac-6d8b-4ed5-9bd7-863dac11cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = new_data.drop('isFraud', axis=1)\n",
    "output = new_data['isFraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, output, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "3fa78b19-50a0-41b6-87db-aa14a6c75bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_cat = data.drop('isFraud', axis=1)\n",
    "outputs_cat = data['isFraud']\n",
    "\n",
    "columns_to_fill = cols\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(inputs_cat, outputs_cat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "88107ff4-9103-422d-ac3d-1159478ed562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def train_and_evaluate_model(model_name, model, X_train, y_train, X_test, y_test):\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_prob_train = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "        roc_prob_train = roc_auc_score(y_train, y_prob_train)\n",
    "        gini_prob_train = roc_prob_train * 2 - 1\n",
    "        confusion_matrix_result_train = confusion_matrix(y_train, y_pred_train)\n",
    "        classification_report_result_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "        print(f'Model Performance for {model_name}')\n",
    "        print('Train Gini prob is', gini_prob_train * 100)\n",
    "        print(classification_report_result_train)\n",
    "        print(confusion_matrix_result_train)\n",
    "\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_prob_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        roc_prob_test = roc_auc_score(y_test, y_prob_test)\n",
    "        gini_prob_test = roc_prob_test * 2 - 1\n",
    "        confusion_matrix_result_test = confusion_matrix(y_test, y_pred_test)\n",
    "        classification_report_result_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "        print(f'Model Performance for {model_name}')\n",
    "        print('Test Gini prob is', gini_prob_test * 100)\n",
    "        print(classification_report_result_test)\n",
    "        print(confusion_matrix_result_test)\n",
    "\n",
    "        return [gini_prob_train, gini_prob_test]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while evaluating the model {model_name}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "853c4320-5743-4e83-92a9-fc66a895b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "xgb_model_def = XGBClassifier(random_state=42)\n",
    "lgb_model_def = LGBMClassifier(random_state=42)\n",
    "catboost_model_def = CatBoostClassifier(random_state=42)\n",
    "catboost_model_custom = CatBoostClassifier(cat_features=cols, random_state=42)\n",
    "random_forest_def= RandomForestClassifier(random_state=42)\n",
    "models.extend([\n",
    "    ('XGBoost', xgb_model_def),\n",
    "    ('LightGBM', lgb_model_def),\n",
    "    ('CatBoost', catboost_model_def),\n",
    "    ('CatBoost_Custom', catboost_model_custom),\n",
    "    ('RandomForest', random_forest_def)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "f518278c-90bd-4b6b-8bed-ded81c427f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for XGBoost\n",
      "Train Gini prob is 100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8004\n",
      "           1       1.00      0.98      0.99        96\n",
      "\n",
      "    accuracy                           1.00      8100\n",
      "   macro avg       1.00      0.99      0.99      8100\n",
      "weighted avg       1.00      1.00      1.00      8100\n",
      "\n",
      "[[8004    0]\n",
      " [   2   94]]\n",
      "Model Performance for XGBoost\n",
      "Test Gini prob is 65.88753233785684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2003\n",
      "           1       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       1.00      0.70      0.79      2025\n",
      "weighted avg       0.99      0.99      0.99      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  13    9]]\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 96, number of negative: 8004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 8100, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011852 -> initscore=-4.423349\n",
      "[LightGBM] [Info] Start training from score -4.423349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\390598664.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  gini_df = pd.concat([gini_df, pd.DataFrame({'Model': [model_name], 'Train Gini': [gini_prob[0]], 'Test Gini': [gini_prob[1]]})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for LightGBM\n",
      "Train Gini prob is 100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8004\n",
      "           1       1.00      1.00      1.00        96\n",
      "\n",
      "    accuracy                           1.00      8100\n",
      "   macro avg       1.00      1.00      1.00      8100\n",
      "weighted avg       1.00      1.00      1.00      8100\n",
      "\n",
      "[[8004    0]\n",
      " [   0   96]]\n",
      "Model Performance for LightGBM\n",
      "Test Gini prob is 65.61521354332139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2003\n",
      "           1       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       1.00      0.68      0.76      2025\n",
      "weighted avg       0.99      0.99      0.99      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  14    8]]\n",
      "Learning rate set to 0.025168\n",
      "0:\tlearn: 0.6376547\ttotal: 40ms\tremaining: 40s\n",
      "1:\tlearn: 0.5878906\ttotal: 43.2ms\tremaining: 21.6s\n",
      "2:\tlearn: 0.5400500\ttotal: 47.7ms\tremaining: 15.9s\n",
      "3:\tlearn: 0.4957989\ttotal: 51ms\tremaining: 12.7s\n",
      "4:\tlearn: 0.4578048\ttotal: 54.2ms\tremaining: 10.8s\n",
      "5:\tlearn: 0.4242619\ttotal: 57.1ms\tremaining: 9.46s\n",
      "6:\tlearn: 0.3939977\ttotal: 59ms\tremaining: 8.37s\n",
      "7:\tlearn: 0.3641347\ttotal: 61.9ms\tremaining: 7.67s\n",
      "8:\tlearn: 0.3372645\ttotal: 64.8ms\tremaining: 7.13s\n",
      "9:\tlearn: 0.3136433\ttotal: 67.3ms\tremaining: 6.66s\n",
      "10:\tlearn: 0.2922656\ttotal: 70.3ms\tremaining: 6.32s\n",
      "11:\tlearn: 0.2725947\ttotal: 72.8ms\tremaining: 6s\n",
      "12:\tlearn: 0.2538276\ttotal: 75.7ms\tremaining: 5.75s\n",
      "13:\tlearn: 0.2360517\ttotal: 78.6ms\tremaining: 5.54s\n",
      "14:\tlearn: 0.2193261\ttotal: 81.4ms\tremaining: 5.34s\n",
      "15:\tlearn: 0.2063066\ttotal: 84.4ms\tremaining: 5.19s\n",
      "16:\tlearn: 0.1932133\ttotal: 87.3ms\tremaining: 5.05s\n",
      "17:\tlearn: 0.1821219\ttotal: 90.3ms\tremaining: 4.92s\n",
      "18:\tlearn: 0.1718759\ttotal: 93.1ms\tremaining: 4.81s\n",
      "19:\tlearn: 0.1628592\ttotal: 95.4ms\tremaining: 4.67s\n",
      "20:\tlearn: 0.1543125\ttotal: 98.4ms\tremaining: 4.59s\n",
      "21:\tlearn: 0.1460224\ttotal: 101ms\tremaining: 4.5s\n",
      "22:\tlearn: 0.1396018\ttotal: 103ms\tremaining: 4.39s\n",
      "23:\tlearn: 0.1331361\ttotal: 106ms\tremaining: 4.32s\n",
      "24:\tlearn: 0.1271882\ttotal: 109ms\tremaining: 4.26s\n",
      "25:\tlearn: 0.1218532\ttotal: 112ms\tremaining: 4.2s\n",
      "26:\tlearn: 0.1164891\ttotal: 115ms\tremaining: 4.15s\n",
      "27:\tlearn: 0.1116077\ttotal: 118ms\tremaining: 4.1s\n",
      "28:\tlearn: 0.1071817\ttotal: 121ms\tremaining: 4.05s\n",
      "29:\tlearn: 0.1034511\ttotal: 124ms\tremaining: 4.01s\n",
      "30:\tlearn: 0.0992790\ttotal: 127ms\tremaining: 3.96s\n",
      "31:\tlearn: 0.0955468\ttotal: 131ms\tremaining: 3.95s\n",
      "32:\tlearn: 0.0928580\ttotal: 134ms\tremaining: 3.92s\n",
      "33:\tlearn: 0.0898604\ttotal: 137ms\tremaining: 3.9s\n",
      "34:\tlearn: 0.0865198\ttotal: 140ms\tremaining: 3.87s\n",
      "35:\tlearn: 0.0832559\ttotal: 143ms\tremaining: 3.84s\n",
      "36:\tlearn: 0.0811247\ttotal: 147ms\tremaining: 3.81s\n",
      "37:\tlearn: 0.0791716\ttotal: 149ms\tremaining: 3.78s\n",
      "38:\tlearn: 0.0770381\ttotal: 152ms\tremaining: 3.75s\n",
      "39:\tlearn: 0.0750155\ttotal: 155ms\tremaining: 3.73s\n",
      "40:\tlearn: 0.0731708\ttotal: 158ms\tremaining: 3.7s\n",
      "41:\tlearn: 0.0719091\ttotal: 161ms\tremaining: 3.68s\n",
      "42:\tlearn: 0.0706082\ttotal: 164ms\tremaining: 3.66s\n",
      "43:\tlearn: 0.0689528\ttotal: 168ms\tremaining: 3.64s\n",
      "44:\tlearn: 0.0676372\ttotal: 171ms\tremaining: 3.63s\n",
      "45:\tlearn: 0.0661760\ttotal: 175ms\tremaining: 3.62s\n",
      "46:\tlearn: 0.0649190\ttotal: 178ms\tremaining: 3.6s\n",
      "47:\tlearn: 0.0635611\ttotal: 181ms\tremaining: 3.59s\n",
      "48:\tlearn: 0.0622064\ttotal: 185ms\tremaining: 3.58s\n",
      "49:\tlearn: 0.0610100\ttotal: 188ms\tremaining: 3.57s\n",
      "50:\tlearn: 0.0600636\ttotal: 191ms\tremaining: 3.56s\n",
      "51:\tlearn: 0.0589653\ttotal: 194ms\tremaining: 3.54s\n",
      "52:\tlearn: 0.0583425\ttotal: 198ms\tremaining: 3.53s\n",
      "53:\tlearn: 0.0574837\ttotal: 200ms\tremaining: 3.51s\n",
      "54:\tlearn: 0.0566718\ttotal: 204ms\tremaining: 3.5s\n",
      "55:\tlearn: 0.0560845\ttotal: 207ms\tremaining: 3.48s\n",
      "56:\tlearn: 0.0556247\ttotal: 210ms\tremaining: 3.47s\n",
      "57:\tlearn: 0.0549067\ttotal: 213ms\tremaining: 3.45s\n",
      "58:\tlearn: 0.0543056\ttotal: 215ms\tremaining: 3.44s\n",
      "59:\tlearn: 0.0536227\ttotal: 218ms\tremaining: 3.42s\n",
      "60:\tlearn: 0.0528158\ttotal: 221ms\tremaining: 3.41s\n",
      "61:\tlearn: 0.0523297\ttotal: 224ms\tremaining: 3.4s\n",
      "62:\tlearn: 0.0519247\ttotal: 227ms\tremaining: 3.38s\n",
      "63:\tlearn: 0.0515695\ttotal: 230ms\tremaining: 3.37s\n",
      "64:\tlearn: 0.0508321\ttotal: 234ms\tremaining: 3.36s\n",
      "65:\tlearn: 0.0502896\ttotal: 236ms\tremaining: 3.35s\n",
      "66:\tlearn: 0.0499969\ttotal: 239ms\tremaining: 3.33s\n",
      "67:\tlearn: 0.0494056\ttotal: 242ms\tremaining: 3.32s\n",
      "68:\tlearn: 0.0489532\ttotal: 245ms\tremaining: 3.31s\n",
      "69:\tlearn: 0.0484631\ttotal: 248ms\tremaining: 3.3s\n",
      "70:\tlearn: 0.0482055\ttotal: 251ms\tremaining: 3.29s\n",
      "71:\tlearn: 0.0478408\ttotal: 254ms\tremaining: 3.27s\n",
      "72:\tlearn: 0.0474009\ttotal: 257ms\tremaining: 3.26s\n",
      "73:\tlearn: 0.0469846\ttotal: 260ms\tremaining: 3.25s\n",
      "74:\tlearn: 0.0465663\ttotal: 263ms\tremaining: 3.25s\n",
      "75:\tlearn: 0.0463169\ttotal: 266ms\tremaining: 3.24s\n",
      "76:\tlearn: 0.0460015\ttotal: 269ms\tremaining: 3.23s\n",
      "77:\tlearn: 0.0457256\ttotal: 272ms\tremaining: 3.21s\n",
      "78:\tlearn: 0.0455282\ttotal: 275ms\tremaining: 3.21s\n",
      "79:\tlearn: 0.0453088\ttotal: 278ms\tremaining: 3.2s\n",
      "80:\tlearn: 0.0450415\ttotal: 281ms\tremaining: 3.19s\n",
      "81:\tlearn: 0.0448489\ttotal: 284ms\tremaining: 3.18s\n",
      "82:\tlearn: 0.0447622\ttotal: 287ms\tremaining: 3.17s\n",
      "83:\tlearn: 0.0445999\ttotal: 290ms\tremaining: 3.16s\n",
      "84:\tlearn: 0.0445585\ttotal: 292ms\tremaining: 3.14s\n",
      "85:\tlearn: 0.0443320\ttotal: 295ms\tremaining: 3.13s\n",
      "86:\tlearn: 0.0439786\ttotal: 298ms\tremaining: 3.13s\n",
      "87:\tlearn: 0.0436907\ttotal: 301ms\tremaining: 3.12s\n",
      "88:\tlearn: 0.0434847\ttotal: 304ms\tremaining: 3.11s\n",
      "89:\tlearn: 0.0431913\ttotal: 307ms\tremaining: 3.1s\n",
      "90:\tlearn: 0.0428953\ttotal: 310ms\tremaining: 3.1s\n",
      "91:\tlearn: 0.0428710\ttotal: 312ms\tremaining: 3.08s\n",
      "92:\tlearn: 0.0426036\ttotal: 315ms\tremaining: 3.07s\n",
      "93:\tlearn: 0.0423350\ttotal: 318ms\tremaining: 3.07s\n",
      "94:\tlearn: 0.0420372\ttotal: 321ms\tremaining: 3.06s\n",
      "95:\tlearn: 0.0420187\ttotal: 324ms\tremaining: 3.05s\n",
      "96:\tlearn: 0.0418252\ttotal: 328ms\tremaining: 3.05s\n",
      "97:\tlearn: 0.0415748\ttotal: 331ms\tremaining: 3.04s\n",
      "98:\tlearn: 0.0413355\ttotal: 334ms\tremaining: 3.04s\n",
      "99:\tlearn: 0.0411209\ttotal: 337ms\tremaining: 3.04s\n",
      "100:\tlearn: 0.0409199\ttotal: 341ms\tremaining: 3.03s\n",
      "101:\tlearn: 0.0407865\ttotal: 344ms\tremaining: 3.03s\n",
      "102:\tlearn: 0.0405907\ttotal: 347ms\tremaining: 3.02s\n",
      "103:\tlearn: 0.0404502\ttotal: 350ms\tremaining: 3.01s\n",
      "104:\tlearn: 0.0403785\ttotal: 353ms\tremaining: 3.01s\n",
      "105:\tlearn: 0.0402410\ttotal: 356ms\tremaining: 3s\n",
      "106:\tlearn: 0.0400808\ttotal: 359ms\tremaining: 2.99s\n",
      "107:\tlearn: 0.0399637\ttotal: 362ms\tremaining: 2.99s\n",
      "108:\tlearn: 0.0398659\ttotal: 365ms\tremaining: 2.98s\n",
      "109:\tlearn: 0.0397588\ttotal: 368ms\tremaining: 2.98s\n",
      "110:\tlearn: 0.0397014\ttotal: 371ms\tremaining: 2.97s\n",
      "111:\tlearn: 0.0395276\ttotal: 374ms\tremaining: 2.96s\n",
      "112:\tlearn: 0.0394452\ttotal: 377ms\tremaining: 2.96s\n",
      "113:\tlearn: 0.0393688\ttotal: 380ms\tremaining: 2.95s\n",
      "114:\tlearn: 0.0392883\ttotal: 382ms\tremaining: 2.94s\n",
      "115:\tlearn: 0.0391493\ttotal: 385ms\tremaining: 2.94s\n",
      "116:\tlearn: 0.0391101\ttotal: 388ms\tremaining: 2.93s\n",
      "117:\tlearn: 0.0390259\ttotal: 391ms\tremaining: 2.92s\n",
      "118:\tlearn: 0.0388933\ttotal: 394ms\tremaining: 2.92s\n",
      "119:\tlearn: 0.0387113\ttotal: 397ms\tremaining: 2.91s\n",
      "120:\tlearn: 0.0385691\ttotal: 400ms\tremaining: 2.91s\n",
      "121:\tlearn: 0.0384826\ttotal: 404ms\tremaining: 2.9s\n",
      "122:\tlearn: 0.0383512\ttotal: 407ms\tremaining: 2.9s\n",
      "123:\tlearn: 0.0382205\ttotal: 410ms\tremaining: 2.9s\n",
      "124:\tlearn: 0.0381227\ttotal: 413ms\tremaining: 2.89s\n",
      "125:\tlearn: 0.0379879\ttotal: 416ms\tremaining: 2.89s\n",
      "126:\tlearn: 0.0378834\ttotal: 420ms\tremaining: 2.88s\n",
      "127:\tlearn: 0.0378261\ttotal: 423ms\tremaining: 2.88s\n",
      "128:\tlearn: 0.0376764\ttotal: 426ms\tremaining: 2.88s\n",
      "129:\tlearn: 0.0376149\ttotal: 430ms\tremaining: 2.87s\n",
      "130:\tlearn: 0.0375319\ttotal: 433ms\tremaining: 2.87s\n",
      "131:\tlearn: 0.0374448\ttotal: 436ms\tremaining: 2.87s\n",
      "132:\tlearn: 0.0373020\ttotal: 439ms\tremaining: 2.86s\n",
      "133:\tlearn: 0.0371853\ttotal: 442ms\tremaining: 2.86s\n",
      "134:\tlearn: 0.0370457\ttotal: 445ms\tremaining: 2.85s\n",
      "135:\tlearn: 0.0369139\ttotal: 448ms\tremaining: 2.85s\n",
      "136:\tlearn: 0.0368537\ttotal: 451ms\tremaining: 2.84s\n",
      "137:\tlearn: 0.0367754\ttotal: 454ms\tremaining: 2.83s\n",
      "138:\tlearn: 0.0367298\ttotal: 457ms\tremaining: 2.83s\n",
      "139:\tlearn: 0.0366059\ttotal: 460ms\tremaining: 2.83s\n",
      "140:\tlearn: 0.0365169\ttotal: 463ms\tremaining: 2.82s\n",
      "141:\tlearn: 0.0364953\ttotal: 466ms\tremaining: 2.82s\n",
      "142:\tlearn: 0.0364869\ttotal: 468ms\tremaining: 2.81s\n",
      "143:\tlearn: 0.0363992\ttotal: 471ms\tremaining: 2.8s\n",
      "144:\tlearn: 0.0363301\ttotal: 474ms\tremaining: 2.8s\n",
      "145:\tlearn: 0.0362710\ttotal: 477ms\tremaining: 2.79s\n",
      "146:\tlearn: 0.0362689\ttotal: 480ms\tremaining: 2.79s\n",
      "147:\tlearn: 0.0362129\ttotal: 483ms\tremaining: 2.78s\n",
      "148:\tlearn: 0.0361806\ttotal: 486ms\tremaining: 2.77s\n",
      "149:\tlearn: 0.0360998\ttotal: 489ms\tremaining: 2.77s\n",
      "150:\tlearn: 0.0360688\ttotal: 492ms\tremaining: 2.77s\n",
      "151:\tlearn: 0.0359905\ttotal: 496ms\tremaining: 2.77s\n",
      "152:\tlearn: 0.0359271\ttotal: 499ms\tremaining: 2.76s\n",
      "153:\tlearn: 0.0358876\ttotal: 502ms\tremaining: 2.76s\n",
      "154:\tlearn: 0.0357764\ttotal: 506ms\tremaining: 2.76s\n",
      "155:\tlearn: 0.0357693\ttotal: 508ms\tremaining: 2.75s\n",
      "156:\tlearn: 0.0356602\ttotal: 512ms\tremaining: 2.75s\n",
      "157:\tlearn: 0.0355813\ttotal: 515ms\tremaining: 2.74s\n",
      "158:\tlearn: 0.0355325\ttotal: 519ms\tremaining: 2.74s\n",
      "159:\tlearn: 0.0354835\ttotal: 522ms\tremaining: 2.74s\n",
      "160:\tlearn: 0.0354461\ttotal: 525ms\tremaining: 2.74s\n",
      "161:\tlearn: 0.0353676\ttotal: 529ms\tremaining: 2.73s\n",
      "162:\tlearn: 0.0353320\ttotal: 532ms\tremaining: 2.73s\n",
      "163:\tlearn: 0.0353038\ttotal: 536ms\tremaining: 2.73s\n",
      "164:\tlearn: 0.0352270\ttotal: 539ms\tremaining: 2.73s\n",
      "165:\tlearn: 0.0351927\ttotal: 542ms\tremaining: 2.72s\n",
      "166:\tlearn: 0.0351754\ttotal: 546ms\tremaining: 2.72s\n",
      "167:\tlearn: 0.0351293\ttotal: 550ms\tremaining: 2.72s\n",
      "168:\tlearn: 0.0351027\ttotal: 553ms\tremaining: 2.72s\n",
      "169:\tlearn: 0.0350525\ttotal: 556ms\tremaining: 2.71s\n",
      "170:\tlearn: 0.0349711\ttotal: 560ms\tremaining: 2.71s\n",
      "171:\tlearn: 0.0349197\ttotal: 563ms\tremaining: 2.71s\n",
      "172:\tlearn: 0.0348331\ttotal: 566ms\tremaining: 2.71s\n",
      "173:\tlearn: 0.0348154\ttotal: 570ms\tremaining: 2.7s\n",
      "174:\tlearn: 0.0347356\ttotal: 573ms\tremaining: 2.7s\n",
      "175:\tlearn: 0.0346758\ttotal: 576ms\tremaining: 2.7s\n",
      "176:\tlearn: 0.0346435\ttotal: 580ms\tremaining: 2.7s\n",
      "177:\tlearn: 0.0345735\ttotal: 583ms\tremaining: 2.69s\n",
      "178:\tlearn: 0.0345275\ttotal: 587ms\tremaining: 2.69s\n",
      "179:\tlearn: 0.0344600\ttotal: 590ms\tremaining: 2.69s\n",
      "180:\tlearn: 0.0343686\ttotal: 594ms\tremaining: 2.69s\n",
      "181:\tlearn: 0.0342929\ttotal: 598ms\tremaining: 2.69s\n",
      "182:\tlearn: 0.0342282\ttotal: 602ms\tremaining: 2.69s\n",
      "183:\tlearn: 0.0342061\ttotal: 606ms\tremaining: 2.69s\n",
      "184:\tlearn: 0.0341540\ttotal: 611ms\tremaining: 2.69s\n",
      "185:\tlearn: 0.0341394\ttotal: 615ms\tremaining: 2.69s\n",
      "186:\tlearn: 0.0340510\ttotal: 619ms\tremaining: 2.69s\n",
      "187:\tlearn: 0.0339913\ttotal: 622ms\tremaining: 2.69s\n",
      "188:\tlearn: 0.0339444\ttotal: 626ms\tremaining: 2.69s\n",
      "189:\tlearn: 0.0338725\ttotal: 630ms\tremaining: 2.68s\n",
      "190:\tlearn: 0.0338059\ttotal: 634ms\tremaining: 2.68s\n",
      "191:\tlearn: 0.0337689\ttotal: 637ms\tremaining: 2.68s\n",
      "192:\tlearn: 0.0337226\ttotal: 640ms\tremaining: 2.68s\n",
      "193:\tlearn: 0.0336577\ttotal: 643ms\tremaining: 2.67s\n",
      "194:\tlearn: 0.0336080\ttotal: 647ms\tremaining: 2.67s\n",
      "195:\tlearn: 0.0335528\ttotal: 650ms\tremaining: 2.67s\n",
      "196:\tlearn: 0.0335081\ttotal: 653ms\tremaining: 2.66s\n",
      "197:\tlearn: 0.0334161\ttotal: 657ms\tremaining: 2.66s\n",
      "198:\tlearn: 0.0333712\ttotal: 661ms\tremaining: 2.66s\n",
      "199:\tlearn: 0.0333438\ttotal: 664ms\tremaining: 2.66s\n",
      "200:\tlearn: 0.0332933\ttotal: 668ms\tremaining: 2.65s\n",
      "201:\tlearn: 0.0332650\ttotal: 671ms\tremaining: 2.65s\n",
      "202:\tlearn: 0.0332353\ttotal: 675ms\tremaining: 2.65s\n",
      "203:\tlearn: 0.0332001\ttotal: 678ms\tremaining: 2.65s\n",
      "204:\tlearn: 0.0331371\ttotal: 681ms\tremaining: 2.64s\n",
      "205:\tlearn: 0.0331071\ttotal: 685ms\tremaining: 2.64s\n",
      "206:\tlearn: 0.0330350\ttotal: 688ms\tremaining: 2.64s\n",
      "207:\tlearn: 0.0329949\ttotal: 692ms\tremaining: 2.64s\n",
      "208:\tlearn: 0.0329763\ttotal: 696ms\tremaining: 2.63s\n",
      "209:\tlearn: 0.0328993\ttotal: 699ms\tremaining: 2.63s\n",
      "210:\tlearn: 0.0327884\ttotal: 703ms\tremaining: 2.63s\n",
      "211:\tlearn: 0.0327326\ttotal: 706ms\tremaining: 2.63s\n",
      "212:\tlearn: 0.0327008\ttotal: 710ms\tremaining: 2.62s\n",
      "213:\tlearn: 0.0326638\ttotal: 714ms\tremaining: 2.62s\n",
      "214:\tlearn: 0.0326384\ttotal: 717ms\tremaining: 2.62s\n",
      "215:\tlearn: 0.0325948\ttotal: 721ms\tremaining: 2.62s\n",
      "216:\tlearn: 0.0325331\ttotal: 724ms\tremaining: 2.61s\n",
      "217:\tlearn: 0.0325087\ttotal: 728ms\tremaining: 2.61s\n",
      "218:\tlearn: 0.0324230\ttotal: 731ms\tremaining: 2.61s\n",
      "219:\tlearn: 0.0323793\ttotal: 735ms\tremaining: 2.6s\n",
      "220:\tlearn: 0.0323466\ttotal: 738ms\tremaining: 2.6s\n",
      "221:\tlearn: 0.0322538\ttotal: 742ms\tremaining: 2.6s\n",
      "222:\tlearn: 0.0321864\ttotal: 745ms\tremaining: 2.59s\n",
      "223:\tlearn: 0.0321612\ttotal: 748ms\tremaining: 2.59s\n",
      "224:\tlearn: 0.0321190\ttotal: 751ms\tremaining: 2.59s\n",
      "225:\tlearn: 0.0320508\ttotal: 754ms\tremaining: 2.58s\n",
      "226:\tlearn: 0.0320245\ttotal: 757ms\tremaining: 2.58s\n",
      "227:\tlearn: 0.0319457\ttotal: 760ms\tremaining: 2.57s\n",
      "228:\tlearn: 0.0318813\ttotal: 763ms\tremaining: 2.57s\n",
      "229:\tlearn: 0.0318460\ttotal: 766ms\tremaining: 2.56s\n",
      "230:\tlearn: 0.0318143\ttotal: 769ms\tremaining: 2.56s\n",
      "231:\tlearn: 0.0317383\ttotal: 772ms\tremaining: 2.56s\n",
      "232:\tlearn: 0.0317161\ttotal: 775ms\tremaining: 2.55s\n",
      "233:\tlearn: 0.0317008\ttotal: 778ms\tremaining: 2.55s\n",
      "234:\tlearn: 0.0316352\ttotal: 781ms\tremaining: 2.54s\n",
      "235:\tlearn: 0.0315233\ttotal: 784ms\tremaining: 2.54s\n",
      "236:\tlearn: 0.0314915\ttotal: 787ms\tremaining: 2.53s\n",
      "237:\tlearn: 0.0314666\ttotal: 790ms\tremaining: 2.53s\n",
      "238:\tlearn: 0.0314432\ttotal: 793ms\tremaining: 2.53s\n",
      "239:\tlearn: 0.0314218\ttotal: 796ms\tremaining: 2.52s\n",
      "240:\tlearn: 0.0313501\ttotal: 799ms\tremaining: 2.52s\n",
      "241:\tlearn: 0.0312691\ttotal: 802ms\tremaining: 2.51s\n",
      "242:\tlearn: 0.0312198\ttotal: 805ms\tremaining: 2.51s\n",
      "243:\tlearn: 0.0311834\ttotal: 808ms\tremaining: 2.5s\n",
      "244:\tlearn: 0.0311095\ttotal: 811ms\tremaining: 2.5s\n",
      "245:\tlearn: 0.0310678\ttotal: 814ms\tremaining: 2.5s\n",
      "246:\tlearn: 0.0310330\ttotal: 817ms\tremaining: 2.49s\n",
      "247:\tlearn: 0.0309957\ttotal: 820ms\tremaining: 2.49s\n",
      "248:\tlearn: 0.0309730\ttotal: 823ms\tremaining: 2.48s\n",
      "249:\tlearn: 0.0309390\ttotal: 826ms\tremaining: 2.48s\n",
      "250:\tlearn: 0.0308937\ttotal: 829ms\tremaining: 2.47s\n",
      "251:\tlearn: 0.0308631\ttotal: 832ms\tremaining: 2.47s\n",
      "252:\tlearn: 0.0307927\ttotal: 835ms\tremaining: 2.46s\n",
      "253:\tlearn: 0.0307548\ttotal: 838ms\tremaining: 2.46s\n",
      "254:\tlearn: 0.0307272\ttotal: 841ms\tremaining: 2.46s\n",
      "255:\tlearn: 0.0306637\ttotal: 844ms\tremaining: 2.45s\n",
      "256:\tlearn: 0.0306328\ttotal: 846ms\tremaining: 2.45s\n",
      "257:\tlearn: 0.0305939\ttotal: 850ms\tremaining: 2.44s\n",
      "258:\tlearn: 0.0305645\ttotal: 853ms\tremaining: 2.44s\n",
      "259:\tlearn: 0.0305386\ttotal: 855ms\tremaining: 2.43s\n",
      "260:\tlearn: 0.0305160\ttotal: 858ms\tremaining: 2.43s\n",
      "261:\tlearn: 0.0304575\ttotal: 861ms\tremaining: 2.43s\n",
      "262:\tlearn: 0.0304405\ttotal: 864ms\tremaining: 2.42s\n",
      "263:\tlearn: 0.0304120\ttotal: 868ms\tremaining: 2.42s\n",
      "264:\tlearn: 0.0303712\ttotal: 871ms\tremaining: 2.41s\n",
      "265:\tlearn: 0.0303270\ttotal: 874ms\tremaining: 2.41s\n",
      "266:\tlearn: 0.0302968\ttotal: 877ms\tremaining: 2.41s\n",
      "267:\tlearn: 0.0302680\ttotal: 880ms\tremaining: 2.4s\n",
      "268:\tlearn: 0.0302163\ttotal: 883ms\tremaining: 2.4s\n",
      "269:\tlearn: 0.0301968\ttotal: 886ms\tremaining: 2.4s\n",
      "270:\tlearn: 0.0301503\ttotal: 889ms\tremaining: 2.39s\n",
      "271:\tlearn: 0.0300852\ttotal: 892ms\tremaining: 2.39s\n",
      "272:\tlearn: 0.0300554\ttotal: 896ms\tremaining: 2.38s\n",
      "273:\tlearn: 0.0300233\ttotal: 899ms\tremaining: 2.38s\n",
      "274:\tlearn: 0.0299719\ttotal: 902ms\tremaining: 2.38s\n",
      "275:\tlearn: 0.0299196\ttotal: 906ms\tremaining: 2.38s\n",
      "276:\tlearn: 0.0298852\ttotal: 909ms\tremaining: 2.37s\n",
      "277:\tlearn: 0.0298338\ttotal: 913ms\tremaining: 2.37s\n",
      "278:\tlearn: 0.0297470\ttotal: 916ms\tremaining: 2.37s\n",
      "279:\tlearn: 0.0297151\ttotal: 920ms\tremaining: 2.37s\n",
      "280:\tlearn: 0.0296545\ttotal: 923ms\tremaining: 2.36s\n",
      "281:\tlearn: 0.0296346\ttotal: 927ms\tremaining: 2.36s\n",
      "282:\tlearn: 0.0296092\ttotal: 931ms\tremaining: 2.36s\n",
      "283:\tlearn: 0.0295576\ttotal: 934ms\tremaining: 2.35s\n",
      "284:\tlearn: 0.0295022\ttotal: 937ms\tremaining: 2.35s\n",
      "285:\tlearn: 0.0294702\ttotal: 940ms\tremaining: 2.35s\n",
      "286:\tlearn: 0.0294388\ttotal: 943ms\tremaining: 2.34s\n",
      "287:\tlearn: 0.0294133\ttotal: 947ms\tremaining: 2.34s\n",
      "288:\tlearn: 0.0294002\ttotal: 949ms\tremaining: 2.33s\n",
      "289:\tlearn: 0.0293416\ttotal: 953ms\tremaining: 2.33s\n",
      "290:\tlearn: 0.0292816\ttotal: 956ms\tremaining: 2.33s\n",
      "291:\tlearn: 0.0292780\ttotal: 958ms\tremaining: 2.32s\n",
      "292:\tlearn: 0.0292169\ttotal: 961ms\tremaining: 2.32s\n",
      "293:\tlearn: 0.0291794\ttotal: 964ms\tremaining: 2.31s\n",
      "294:\tlearn: 0.0291320\ttotal: 967ms\tremaining: 2.31s\n",
      "295:\tlearn: 0.0290977\ttotal: 970ms\tremaining: 2.31s\n",
      "296:\tlearn: 0.0290529\ttotal: 974ms\tremaining: 2.3s\n",
      "297:\tlearn: 0.0289926\ttotal: 977ms\tremaining: 2.3s\n",
      "298:\tlearn: 0.0289329\ttotal: 981ms\tremaining: 2.3s\n",
      "299:\tlearn: 0.0288823\ttotal: 984ms\tremaining: 2.3s\n",
      "300:\tlearn: 0.0288449\ttotal: 987ms\tremaining: 2.29s\n",
      "301:\tlearn: 0.0288150\ttotal: 990ms\tremaining: 2.29s\n",
      "302:\tlearn: 0.0287833\ttotal: 993ms\tremaining: 2.28s\n",
      "303:\tlearn: 0.0287638\ttotal: 996ms\tremaining: 2.28s\n",
      "304:\tlearn: 0.0287186\ttotal: 1000ms\tremaining: 2.28s\n",
      "305:\tlearn: 0.0286817\ttotal: 1s\tremaining: 2.27s\n",
      "306:\tlearn: 0.0286596\ttotal: 1s\tremaining: 2.27s\n",
      "307:\tlearn: 0.0285993\ttotal: 1.01s\tremaining: 2.27s\n",
      "308:\tlearn: 0.0285542\ttotal: 1.01s\tremaining: 2.26s\n",
      "309:\tlearn: 0.0285131\ttotal: 1.01s\tremaining: 2.26s\n",
      "310:\tlearn: 0.0284991\ttotal: 1.02s\tremaining: 2.25s\n",
      "311:\tlearn: 0.0284135\ttotal: 1.02s\tremaining: 2.25s\n",
      "312:\tlearn: 0.0283999\ttotal: 1.02s\tremaining: 2.25s\n",
      "313:\tlearn: 0.0283812\ttotal: 1.03s\tremaining: 2.24s\n",
      "314:\tlearn: 0.0283164\ttotal: 1.03s\tremaining: 2.24s\n",
      "315:\tlearn: 0.0282727\ttotal: 1.03s\tremaining: 2.23s\n",
      "316:\tlearn: 0.0282017\ttotal: 1.03s\tremaining: 2.23s\n",
      "317:\tlearn: 0.0281599\ttotal: 1.04s\tremaining: 2.23s\n",
      "318:\tlearn: 0.0280850\ttotal: 1.04s\tremaining: 2.22s\n",
      "319:\tlearn: 0.0280331\ttotal: 1.04s\tremaining: 2.22s\n",
      "320:\tlearn: 0.0280247\ttotal: 1.05s\tremaining: 2.22s\n",
      "321:\tlearn: 0.0279901\ttotal: 1.05s\tremaining: 2.21s\n",
      "322:\tlearn: 0.0279583\ttotal: 1.05s\tremaining: 2.21s\n",
      "323:\tlearn: 0.0279317\ttotal: 1.06s\tremaining: 2.21s\n",
      "324:\tlearn: 0.0278730\ttotal: 1.06s\tremaining: 2.2s\n",
      "325:\tlearn: 0.0278458\ttotal: 1.06s\tremaining: 2.2s\n",
      "326:\tlearn: 0.0277724\ttotal: 1.06s\tremaining: 2.19s\n",
      "327:\tlearn: 0.0277346\ttotal: 1.07s\tremaining: 2.19s\n",
      "328:\tlearn: 0.0276981\ttotal: 1.07s\tremaining: 2.19s\n",
      "329:\tlearn: 0.0276940\ttotal: 1.07s\tremaining: 2.18s\n",
      "330:\tlearn: 0.0276334\ttotal: 1.08s\tremaining: 2.18s\n",
      "331:\tlearn: 0.0276155\ttotal: 1.08s\tremaining: 2.17s\n",
      "332:\tlearn: 0.0275957\ttotal: 1.08s\tremaining: 2.17s\n",
      "333:\tlearn: 0.0275630\ttotal: 1.09s\tremaining: 2.17s\n",
      "334:\tlearn: 0.0275510\ttotal: 1.09s\tremaining: 2.16s\n",
      "335:\tlearn: 0.0274977\ttotal: 1.09s\tremaining: 2.16s\n",
      "336:\tlearn: 0.0274645\ttotal: 1.09s\tremaining: 2.15s\n",
      "337:\tlearn: 0.0274514\ttotal: 1.1s\tremaining: 2.15s\n",
      "338:\tlearn: 0.0274377\ttotal: 1.1s\tremaining: 2.15s\n",
      "339:\tlearn: 0.0274165\ttotal: 1.1s\tremaining: 2.14s\n",
      "340:\tlearn: 0.0273846\ttotal: 1.11s\tremaining: 2.14s\n",
      "341:\tlearn: 0.0273568\ttotal: 1.11s\tremaining: 2.13s\n",
      "342:\tlearn: 0.0272963\ttotal: 1.11s\tremaining: 2.13s\n",
      "343:\tlearn: 0.0272664\ttotal: 1.12s\tremaining: 2.13s\n",
      "344:\tlearn: 0.0272433\ttotal: 1.12s\tremaining: 2.13s\n",
      "345:\tlearn: 0.0272315\ttotal: 1.12s\tremaining: 2.12s\n",
      "346:\tlearn: 0.0271637\ttotal: 1.13s\tremaining: 2.12s\n",
      "347:\tlearn: 0.0271130\ttotal: 1.13s\tremaining: 2.12s\n",
      "348:\tlearn: 0.0270738\ttotal: 1.13s\tremaining: 2.11s\n",
      "349:\tlearn: 0.0270365\ttotal: 1.14s\tremaining: 2.11s\n",
      "350:\tlearn: 0.0270140\ttotal: 1.14s\tremaining: 2.11s\n",
      "351:\tlearn: 0.0269859\ttotal: 1.14s\tremaining: 2.1s\n",
      "352:\tlearn: 0.0269444\ttotal: 1.15s\tremaining: 2.1s\n",
      "353:\tlearn: 0.0268908\ttotal: 1.15s\tremaining: 2.1s\n",
      "354:\tlearn: 0.0268319\ttotal: 1.15s\tremaining: 2.09s\n",
      "355:\tlearn: 0.0267915\ttotal: 1.15s\tremaining: 2.09s\n",
      "356:\tlearn: 0.0267377\ttotal: 1.16s\tremaining: 2.08s\n",
      "357:\tlearn: 0.0267091\ttotal: 1.16s\tremaining: 2.08s\n",
      "358:\tlearn: 0.0266603\ttotal: 1.16s\tremaining: 2.08s\n",
      "359:\tlearn: 0.0266414\ttotal: 1.17s\tremaining: 2.07s\n",
      "360:\tlearn: 0.0266014\ttotal: 1.17s\tremaining: 2.07s\n",
      "361:\tlearn: 0.0265601\ttotal: 1.18s\tremaining: 2.07s\n",
      "362:\tlearn: 0.0265260\ttotal: 1.18s\tremaining: 2.07s\n",
      "363:\tlearn: 0.0264797\ttotal: 1.18s\tremaining: 2.06s\n",
      "364:\tlearn: 0.0264312\ttotal: 1.18s\tremaining: 2.06s\n",
      "365:\tlearn: 0.0264025\ttotal: 1.19s\tremaining: 2.06s\n",
      "366:\tlearn: 0.0263396\ttotal: 1.19s\tremaining: 2.05s\n",
      "367:\tlearn: 0.0263014\ttotal: 1.19s\tremaining: 2.05s\n",
      "368:\tlearn: 0.0262587\ttotal: 1.2s\tremaining: 2.05s\n",
      "369:\tlearn: 0.0262394\ttotal: 1.2s\tremaining: 2.04s\n",
      "370:\tlearn: 0.0262192\ttotal: 1.2s\tremaining: 2.04s\n",
      "371:\tlearn: 0.0262083\ttotal: 1.21s\tremaining: 2.04s\n",
      "372:\tlearn: 0.0261922\ttotal: 1.21s\tremaining: 2.03s\n",
      "373:\tlearn: 0.0261717\ttotal: 1.21s\tremaining: 2.03s\n",
      "374:\tlearn: 0.0261395\ttotal: 1.21s\tremaining: 2.02s\n",
      "375:\tlearn: 0.0261153\ttotal: 1.22s\tremaining: 2.02s\n",
      "376:\tlearn: 0.0261034\ttotal: 1.22s\tremaining: 2.02s\n",
      "377:\tlearn: 0.0260561\ttotal: 1.22s\tremaining: 2.01s\n",
      "378:\tlearn: 0.0260263\ttotal: 1.23s\tremaining: 2.01s\n",
      "379:\tlearn: 0.0259951\ttotal: 1.23s\tremaining: 2s\n",
      "380:\tlearn: 0.0259751\ttotal: 1.23s\tremaining: 2s\n",
      "381:\tlearn: 0.0259418\ttotal: 1.24s\tremaining: 2s\n",
      "382:\tlearn: 0.0259383\ttotal: 1.24s\tremaining: 1.99s\n",
      "383:\tlearn: 0.0259039\ttotal: 1.24s\tremaining: 1.99s\n",
      "384:\tlearn: 0.0258558\ttotal: 1.24s\tremaining: 1.99s\n",
      "385:\tlearn: 0.0258115\ttotal: 1.25s\tremaining: 1.98s\n",
      "386:\tlearn: 0.0257830\ttotal: 1.25s\tremaining: 1.98s\n",
      "387:\tlearn: 0.0257494\ttotal: 1.25s\tremaining: 1.98s\n",
      "388:\tlearn: 0.0257142\ttotal: 1.25s\tremaining: 1.97s\n",
      "389:\tlearn: 0.0256919\ttotal: 1.26s\tremaining: 1.97s\n",
      "390:\tlearn: 0.0256487\ttotal: 1.26s\tremaining: 1.96s\n",
      "391:\tlearn: 0.0256172\ttotal: 1.26s\tremaining: 1.96s\n",
      "392:\tlearn: 0.0256014\ttotal: 1.27s\tremaining: 1.96s\n",
      "393:\tlearn: 0.0255900\ttotal: 1.27s\tremaining: 1.95s\n",
      "394:\tlearn: 0.0255858\ttotal: 1.27s\tremaining: 1.95s\n",
      "395:\tlearn: 0.0255540\ttotal: 1.28s\tremaining: 1.95s\n",
      "396:\tlearn: 0.0255392\ttotal: 1.28s\tremaining: 1.94s\n",
      "397:\tlearn: 0.0255032\ttotal: 1.28s\tremaining: 1.94s\n",
      "398:\tlearn: 0.0254589\ttotal: 1.29s\tremaining: 1.94s\n",
      "399:\tlearn: 0.0254259\ttotal: 1.29s\tremaining: 1.94s\n",
      "400:\tlearn: 0.0254009\ttotal: 1.29s\tremaining: 1.93s\n",
      "401:\tlearn: 0.0253532\ttotal: 1.3s\tremaining: 1.93s\n",
      "402:\tlearn: 0.0253239\ttotal: 1.3s\tremaining: 1.93s\n",
      "403:\tlearn: 0.0253003\ttotal: 1.3s\tremaining: 1.92s\n",
      "404:\tlearn: 0.0252910\ttotal: 1.31s\tremaining: 1.92s\n",
      "405:\tlearn: 0.0252709\ttotal: 1.31s\tremaining: 1.92s\n",
      "406:\tlearn: 0.0252456\ttotal: 1.32s\tremaining: 1.92s\n",
      "407:\tlearn: 0.0252168\ttotal: 1.32s\tremaining: 1.91s\n",
      "408:\tlearn: 0.0252067\ttotal: 1.32s\tremaining: 1.91s\n",
      "409:\tlearn: 0.0251934\ttotal: 1.32s\tremaining: 1.91s\n",
      "410:\tlearn: 0.0251785\ttotal: 1.33s\tremaining: 1.91s\n",
      "411:\tlearn: 0.0251598\ttotal: 1.33s\tremaining: 1.9s\n",
      "412:\tlearn: 0.0251535\ttotal: 1.34s\tremaining: 1.9s\n",
      "413:\tlearn: 0.0251429\ttotal: 1.34s\tremaining: 1.9s\n",
      "414:\tlearn: 0.0251337\ttotal: 1.34s\tremaining: 1.89s\n",
      "415:\tlearn: 0.0251222\ttotal: 1.35s\tremaining: 1.89s\n",
      "416:\tlearn: 0.0250787\ttotal: 1.35s\tremaining: 1.89s\n",
      "417:\tlearn: 0.0250525\ttotal: 1.35s\tremaining: 1.88s\n",
      "418:\tlearn: 0.0250416\ttotal: 1.35s\tremaining: 1.88s\n",
      "419:\tlearn: 0.0250065\ttotal: 1.36s\tremaining: 1.88s\n",
      "420:\tlearn: 0.0249898\ttotal: 1.36s\tremaining: 1.87s\n",
      "421:\tlearn: 0.0249799\ttotal: 1.36s\tremaining: 1.87s\n",
      "422:\tlearn: 0.0249769\ttotal: 1.37s\tremaining: 1.87s\n",
      "423:\tlearn: 0.0249615\ttotal: 1.37s\tremaining: 1.86s\n",
      "424:\tlearn: 0.0249519\ttotal: 1.37s\tremaining: 1.86s\n",
      "425:\tlearn: 0.0249433\ttotal: 1.38s\tremaining: 1.86s\n",
      "426:\tlearn: 0.0249116\ttotal: 1.38s\tremaining: 1.85s\n",
      "427:\tlearn: 0.0248994\ttotal: 1.38s\tremaining: 1.85s\n",
      "428:\tlearn: 0.0248830\ttotal: 1.39s\tremaining: 1.85s\n",
      "429:\tlearn: 0.0248655\ttotal: 1.39s\tremaining: 1.84s\n",
      "430:\tlearn: 0.0248573\ttotal: 1.39s\tremaining: 1.84s\n",
      "431:\tlearn: 0.0248446\ttotal: 1.4s\tremaining: 1.84s\n",
      "432:\tlearn: 0.0248349\ttotal: 1.4s\tremaining: 1.83s\n",
      "433:\tlearn: 0.0248134\ttotal: 1.4s\tremaining: 1.83s\n",
      "434:\tlearn: 0.0248045\ttotal: 1.41s\tremaining: 1.83s\n",
      "435:\tlearn: 0.0247713\ttotal: 1.41s\tremaining: 1.83s\n",
      "436:\tlearn: 0.0247312\ttotal: 1.42s\tremaining: 1.82s\n",
      "437:\tlearn: 0.0247155\ttotal: 1.42s\tremaining: 1.82s\n",
      "438:\tlearn: 0.0247138\ttotal: 1.42s\tremaining: 1.82s\n",
      "439:\tlearn: 0.0246887\ttotal: 1.43s\tremaining: 1.81s\n",
      "440:\tlearn: 0.0246582\ttotal: 1.43s\tremaining: 1.81s\n",
      "441:\tlearn: 0.0246422\ttotal: 1.43s\tremaining: 1.81s\n",
      "442:\tlearn: 0.0246346\ttotal: 1.43s\tremaining: 1.8s\n",
      "443:\tlearn: 0.0246262\ttotal: 1.44s\tremaining: 1.8s\n",
      "444:\tlearn: 0.0246196\ttotal: 1.44s\tremaining: 1.8s\n",
      "445:\tlearn: 0.0245886\ttotal: 1.44s\tremaining: 1.79s\n",
      "446:\tlearn: 0.0245821\ttotal: 1.45s\tremaining: 1.79s\n",
      "447:\tlearn: 0.0245753\ttotal: 1.45s\tremaining: 1.79s\n",
      "448:\tlearn: 0.0245660\ttotal: 1.45s\tremaining: 1.78s\n",
      "449:\tlearn: 0.0245446\ttotal: 1.46s\tremaining: 1.78s\n",
      "450:\tlearn: 0.0245378\ttotal: 1.46s\tremaining: 1.78s\n",
      "451:\tlearn: 0.0245304\ttotal: 1.47s\tremaining: 1.78s\n",
      "452:\tlearn: 0.0245234\ttotal: 1.48s\tremaining: 1.78s\n",
      "453:\tlearn: 0.0245008\ttotal: 1.48s\tremaining: 1.78s\n",
      "454:\tlearn: 0.0244690\ttotal: 1.49s\tremaining: 1.79s\n",
      "455:\tlearn: 0.0244619\ttotal: 1.51s\tremaining: 1.8s\n",
      "456:\tlearn: 0.0244338\ttotal: 1.53s\tremaining: 1.82s\n",
      "457:\tlearn: 0.0244279\ttotal: 1.54s\tremaining: 1.82s\n",
      "458:\tlearn: 0.0244210\ttotal: 1.54s\tremaining: 1.82s\n",
      "459:\tlearn: 0.0244144\ttotal: 1.55s\tremaining: 1.81s\n",
      "460:\tlearn: 0.0244025\ttotal: 1.55s\tremaining: 1.81s\n",
      "461:\tlearn: 0.0243954\ttotal: 1.56s\tremaining: 1.81s\n",
      "462:\tlearn: 0.0243901\ttotal: 1.58s\tremaining: 1.83s\n",
      "463:\tlearn: 0.0243530\ttotal: 1.58s\tremaining: 1.83s\n",
      "464:\tlearn: 0.0243466\ttotal: 1.59s\tremaining: 1.83s\n",
      "465:\tlearn: 0.0243346\ttotal: 1.6s\tremaining: 1.83s\n",
      "466:\tlearn: 0.0243274\ttotal: 1.6s\tremaining: 1.83s\n",
      "467:\tlearn: 0.0243053\ttotal: 1.61s\tremaining: 1.83s\n",
      "468:\tlearn: 0.0242932\ttotal: 1.62s\tremaining: 1.83s\n",
      "469:\tlearn: 0.0242817\ttotal: 1.62s\tremaining: 1.83s\n",
      "470:\tlearn: 0.0242701\ttotal: 1.63s\tremaining: 1.83s\n",
      "471:\tlearn: 0.0242644\ttotal: 1.64s\tremaining: 1.83s\n",
      "472:\tlearn: 0.0242531\ttotal: 1.64s\tremaining: 1.83s\n",
      "473:\tlearn: 0.0242468\ttotal: 1.65s\tremaining: 1.83s\n",
      "474:\tlearn: 0.0242419\ttotal: 1.66s\tremaining: 1.83s\n",
      "475:\tlearn: 0.0242282\ttotal: 1.67s\tremaining: 1.83s\n",
      "476:\tlearn: 0.0242219\ttotal: 1.67s\tremaining: 1.83s\n",
      "477:\tlearn: 0.0242163\ttotal: 1.68s\tremaining: 1.83s\n",
      "478:\tlearn: 0.0242096\ttotal: 1.68s\tremaining: 1.83s\n",
      "479:\tlearn: 0.0241892\ttotal: 1.69s\tremaining: 1.83s\n",
      "480:\tlearn: 0.0241725\ttotal: 1.69s\tremaining: 1.83s\n",
      "481:\tlearn: 0.0241569\ttotal: 1.72s\tremaining: 1.85s\n",
      "482:\tlearn: 0.0241392\ttotal: 1.73s\tremaining: 1.85s\n",
      "483:\tlearn: 0.0241274\ttotal: 1.73s\tremaining: 1.85s\n",
      "484:\tlearn: 0.0241162\ttotal: 1.74s\tremaining: 1.84s\n",
      "485:\tlearn: 0.0241088\ttotal: 1.74s\tremaining: 1.84s\n",
      "486:\tlearn: 0.0240703\ttotal: 1.74s\tremaining: 1.84s\n",
      "487:\tlearn: 0.0240660\ttotal: 1.75s\tremaining: 1.83s\n",
      "488:\tlearn: 0.0240444\ttotal: 1.75s\tremaining: 1.83s\n",
      "489:\tlearn: 0.0240382\ttotal: 1.75s\tremaining: 1.82s\n",
      "490:\tlearn: 0.0240146\ttotal: 1.76s\tremaining: 1.82s\n",
      "491:\tlearn: 0.0239800\ttotal: 1.76s\tremaining: 1.82s\n",
      "492:\tlearn: 0.0239681\ttotal: 1.76s\tremaining: 1.81s\n",
      "493:\tlearn: 0.0239256\ttotal: 1.77s\tremaining: 1.81s\n",
      "494:\tlearn: 0.0239202\ttotal: 1.77s\tremaining: 1.8s\n",
      "495:\tlearn: 0.0238929\ttotal: 1.77s\tremaining: 1.8s\n",
      "496:\tlearn: 0.0238822\ttotal: 1.78s\tremaining: 1.8s\n",
      "497:\tlearn: 0.0238582\ttotal: 1.78s\tremaining: 1.8s\n",
      "498:\tlearn: 0.0238346\ttotal: 1.79s\tremaining: 1.8s\n",
      "499:\tlearn: 0.0238190\ttotal: 1.8s\tremaining: 1.8s\n",
      "500:\tlearn: 0.0238088\ttotal: 1.81s\tremaining: 1.8s\n",
      "501:\tlearn: 0.0237949\ttotal: 1.81s\tremaining: 1.79s\n",
      "502:\tlearn: 0.0237679\ttotal: 1.81s\tremaining: 1.79s\n",
      "503:\tlearn: 0.0237627\ttotal: 1.82s\tremaining: 1.79s\n",
      "504:\tlearn: 0.0237532\ttotal: 1.82s\tremaining: 1.79s\n",
      "505:\tlearn: 0.0237492\ttotal: 1.82s\tremaining: 1.78s\n",
      "506:\tlearn: 0.0237305\ttotal: 1.83s\tremaining: 1.78s\n",
      "507:\tlearn: 0.0237242\ttotal: 1.83s\tremaining: 1.77s\n",
      "508:\tlearn: 0.0237153\ttotal: 1.84s\tremaining: 1.77s\n",
      "509:\tlearn: 0.0237067\ttotal: 1.84s\tremaining: 1.77s\n",
      "510:\tlearn: 0.0237027\ttotal: 1.84s\tremaining: 1.76s\n",
      "511:\tlearn: 0.0236975\ttotal: 1.85s\tremaining: 1.76s\n",
      "512:\tlearn: 0.0236890\ttotal: 1.85s\tremaining: 1.76s\n",
      "513:\tlearn: 0.0236790\ttotal: 1.85s\tremaining: 1.75s\n",
      "514:\tlearn: 0.0236377\ttotal: 1.86s\tremaining: 1.75s\n",
      "515:\tlearn: 0.0236200\ttotal: 1.86s\tremaining: 1.75s\n",
      "516:\tlearn: 0.0236135\ttotal: 1.86s\tremaining: 1.74s\n",
      "517:\tlearn: 0.0236099\ttotal: 1.87s\tremaining: 1.74s\n",
      "518:\tlearn: 0.0236048\ttotal: 1.87s\tremaining: 1.74s\n",
      "519:\tlearn: 0.0235998\ttotal: 1.88s\tremaining: 1.73s\n",
      "520:\tlearn: 0.0235962\ttotal: 1.88s\tremaining: 1.73s\n",
      "521:\tlearn: 0.0235926\ttotal: 1.88s\tremaining: 1.73s\n",
      "522:\tlearn: 0.0235754\ttotal: 1.89s\tremaining: 1.72s\n",
      "523:\tlearn: 0.0235450\ttotal: 1.89s\tremaining: 1.72s\n",
      "524:\tlearn: 0.0235334\ttotal: 1.89s\tremaining: 1.71s\n",
      "525:\tlearn: 0.0235254\ttotal: 1.9s\tremaining: 1.71s\n",
      "526:\tlearn: 0.0235197\ttotal: 1.9s\tremaining: 1.71s\n",
      "527:\tlearn: 0.0235096\ttotal: 1.9s\tremaining: 1.7s\n",
      "528:\tlearn: 0.0234843\ttotal: 1.91s\tremaining: 1.7s\n",
      "529:\tlearn: 0.0234745\ttotal: 1.91s\tremaining: 1.69s\n",
      "530:\tlearn: 0.0234581\ttotal: 1.91s\tremaining: 1.69s\n",
      "531:\tlearn: 0.0234504\ttotal: 1.92s\tremaining: 1.69s\n",
      "532:\tlearn: 0.0234429\ttotal: 1.92s\tremaining: 1.68s\n",
      "533:\tlearn: 0.0234206\ttotal: 1.92s\tremaining: 1.68s\n",
      "534:\tlearn: 0.0234049\ttotal: 1.92s\tremaining: 1.67s\n",
      "535:\tlearn: 0.0233955\ttotal: 1.93s\tremaining: 1.67s\n",
      "536:\tlearn: 0.0233827\ttotal: 1.93s\tremaining: 1.66s\n",
      "537:\tlearn: 0.0233787\ttotal: 1.93s\tremaining: 1.66s\n",
      "538:\tlearn: 0.0233754\ttotal: 1.94s\tremaining: 1.66s\n",
      "539:\tlearn: 0.0233630\ttotal: 1.94s\tremaining: 1.65s\n",
      "540:\tlearn: 0.0233405\ttotal: 1.94s\tremaining: 1.65s\n",
      "541:\tlearn: 0.0232913\ttotal: 1.95s\tremaining: 1.65s\n",
      "542:\tlearn: 0.0232787\ttotal: 1.95s\tremaining: 1.64s\n",
      "543:\tlearn: 0.0232664\ttotal: 1.95s\tremaining: 1.64s\n",
      "544:\tlearn: 0.0232196\ttotal: 1.96s\tremaining: 1.63s\n",
      "545:\tlearn: 0.0232046\ttotal: 1.96s\tremaining: 1.63s\n",
      "546:\tlearn: 0.0231591\ttotal: 1.96s\tremaining: 1.63s\n",
      "547:\tlearn: 0.0231156\ttotal: 1.97s\tremaining: 1.62s\n",
      "548:\tlearn: 0.0231123\ttotal: 1.97s\tremaining: 1.62s\n",
      "549:\tlearn: 0.0231091\ttotal: 1.97s\tremaining: 1.61s\n",
      "550:\tlearn: 0.0230940\ttotal: 1.98s\tremaining: 1.61s\n",
      "551:\tlearn: 0.0230713\ttotal: 1.98s\tremaining: 1.61s\n",
      "552:\tlearn: 0.0230294\ttotal: 1.98s\tremaining: 1.6s\n",
      "553:\tlearn: 0.0230055\ttotal: 1.99s\tremaining: 1.6s\n",
      "554:\tlearn: 0.0229967\ttotal: 1.99s\tremaining: 1.59s\n",
      "555:\tlearn: 0.0229818\ttotal: 1.99s\tremaining: 1.59s\n",
      "556:\tlearn: 0.0229750\ttotal: 1.99s\tremaining: 1.59s\n",
      "557:\tlearn: 0.0229607\ttotal: 2s\tremaining: 1.58s\n",
      "558:\tlearn: 0.0229274\ttotal: 2s\tremaining: 1.58s\n",
      "559:\tlearn: 0.0229044\ttotal: 2s\tremaining: 1.57s\n",
      "560:\tlearn: 0.0228503\ttotal: 2.01s\tremaining: 1.57s\n",
      "561:\tlearn: 0.0228439\ttotal: 2.01s\tremaining: 1.57s\n",
      "562:\tlearn: 0.0228216\ttotal: 2.01s\tremaining: 1.56s\n",
      "563:\tlearn: 0.0227999\ttotal: 2.02s\tremaining: 1.56s\n",
      "564:\tlearn: 0.0227745\ttotal: 2.02s\tremaining: 1.55s\n",
      "565:\tlearn: 0.0227391\ttotal: 2.02s\tremaining: 1.55s\n",
      "566:\tlearn: 0.0227137\ttotal: 2.02s\tremaining: 1.55s\n",
      "567:\tlearn: 0.0226938\ttotal: 2.03s\tremaining: 1.54s\n",
      "568:\tlearn: 0.0226908\ttotal: 2.03s\tremaining: 1.54s\n",
      "569:\tlearn: 0.0226697\ttotal: 2.03s\tremaining: 1.53s\n",
      "570:\tlearn: 0.0226491\ttotal: 2.04s\tremaining: 1.53s\n",
      "571:\tlearn: 0.0225948\ttotal: 2.04s\tremaining: 1.52s\n",
      "572:\tlearn: 0.0225748\ttotal: 2.04s\tremaining: 1.52s\n",
      "573:\tlearn: 0.0225231\ttotal: 2.04s\tremaining: 1.52s\n",
      "574:\tlearn: 0.0224916\ttotal: 2.05s\tremaining: 1.51s\n",
      "575:\tlearn: 0.0224437\ttotal: 2.05s\tremaining: 1.51s\n",
      "576:\tlearn: 0.0224139\ttotal: 2.05s\tremaining: 1.5s\n",
      "577:\tlearn: 0.0223677\ttotal: 2.06s\tremaining: 1.5s\n",
      "578:\tlearn: 0.0223425\ttotal: 2.06s\tremaining: 1.5s\n",
      "579:\tlearn: 0.0223229\ttotal: 2.06s\tremaining: 1.49s\n",
      "580:\tlearn: 0.0222983\ttotal: 2.07s\tremaining: 1.49s\n",
      "581:\tlearn: 0.0222508\ttotal: 2.07s\tremaining: 1.49s\n",
      "582:\tlearn: 0.0222313\ttotal: 2.08s\tremaining: 1.49s\n",
      "583:\tlearn: 0.0222068\ttotal: 2.08s\tremaining: 1.48s\n",
      "584:\tlearn: 0.0221963\ttotal: 2.09s\tremaining: 1.48s\n",
      "585:\tlearn: 0.0221774\ttotal: 2.09s\tremaining: 1.48s\n",
      "586:\tlearn: 0.0221344\ttotal: 2.09s\tremaining: 1.47s\n",
      "587:\tlearn: 0.0220931\ttotal: 2.1s\tremaining: 1.47s\n",
      "588:\tlearn: 0.0220511\ttotal: 2.1s\tremaining: 1.46s\n",
      "589:\tlearn: 0.0220252\ttotal: 2.1s\tremaining: 1.46s\n",
      "590:\tlearn: 0.0219963\ttotal: 2.1s\tremaining: 1.46s\n",
      "591:\tlearn: 0.0219781\ttotal: 2.11s\tremaining: 1.45s\n",
      "592:\tlearn: 0.0219557\ttotal: 2.11s\tremaining: 1.45s\n",
      "593:\tlearn: 0.0219391\ttotal: 2.11s\tremaining: 1.45s\n",
      "594:\tlearn: 0.0219261\ttotal: 2.12s\tremaining: 1.44s\n",
      "595:\tlearn: 0.0219085\ttotal: 2.12s\tremaining: 1.44s\n",
      "596:\tlearn: 0.0218867\ttotal: 2.12s\tremaining: 1.43s\n",
      "597:\tlearn: 0.0218469\ttotal: 2.13s\tremaining: 1.43s\n",
      "598:\tlearn: 0.0218183\ttotal: 2.13s\tremaining: 1.43s\n",
      "599:\tlearn: 0.0217993\ttotal: 2.13s\tremaining: 1.42s\n",
      "600:\tlearn: 0.0217598\ttotal: 2.13s\tremaining: 1.42s\n",
      "601:\tlearn: 0.0217426\ttotal: 2.14s\tremaining: 1.41s\n",
      "602:\tlearn: 0.0217044\ttotal: 2.14s\tremaining: 1.41s\n",
      "603:\tlearn: 0.0216834\ttotal: 2.15s\tremaining: 1.41s\n",
      "604:\tlearn: 0.0216440\ttotal: 2.15s\tremaining: 1.4s\n",
      "605:\tlearn: 0.0216263\ttotal: 2.15s\tremaining: 1.4s\n",
      "606:\tlearn: 0.0216059\ttotal: 2.15s\tremaining: 1.4s\n",
      "607:\tlearn: 0.0215931\ttotal: 2.16s\tremaining: 1.39s\n",
      "608:\tlearn: 0.0215581\ttotal: 2.16s\tremaining: 1.39s\n",
      "609:\tlearn: 0.0215289\ttotal: 2.16s\tremaining: 1.38s\n",
      "610:\tlearn: 0.0215119\ttotal: 2.17s\tremaining: 1.38s\n",
      "611:\tlearn: 0.0214623\ttotal: 2.17s\tremaining: 1.38s\n",
      "612:\tlearn: 0.0214458\ttotal: 2.17s\tremaining: 1.37s\n",
      "613:\tlearn: 0.0214261\ttotal: 2.18s\tremaining: 1.37s\n",
      "614:\tlearn: 0.0213930\ttotal: 2.18s\tremaining: 1.36s\n",
      "615:\tlearn: 0.0213581\ttotal: 2.18s\tremaining: 1.36s\n",
      "616:\tlearn: 0.0213405\ttotal: 2.19s\tremaining: 1.36s\n",
      "617:\tlearn: 0.0213031\ttotal: 2.19s\tremaining: 1.35s\n",
      "618:\tlearn: 0.0212873\ttotal: 2.19s\tremaining: 1.35s\n",
      "619:\tlearn: 0.0212600\ttotal: 2.19s\tremaining: 1.34s\n",
      "620:\tlearn: 0.0212429\ttotal: 2.2s\tremaining: 1.34s\n",
      "621:\tlearn: 0.0212113\ttotal: 2.2s\tremaining: 1.34s\n",
      "622:\tlearn: 0.0211780\ttotal: 2.2s\tremaining: 1.33s\n",
      "623:\tlearn: 0.0211626\ttotal: 2.21s\tremaining: 1.33s\n",
      "624:\tlearn: 0.0211477\ttotal: 2.21s\tremaining: 1.33s\n",
      "625:\tlearn: 0.0211332\ttotal: 2.21s\tremaining: 1.32s\n",
      "626:\tlearn: 0.0210873\ttotal: 2.22s\tremaining: 1.32s\n",
      "627:\tlearn: 0.0210603\ttotal: 2.22s\tremaining: 1.32s\n",
      "628:\tlearn: 0.0210462\ttotal: 2.23s\tremaining: 1.31s\n",
      "629:\tlearn: 0.0210170\ttotal: 2.23s\tremaining: 1.31s\n",
      "630:\tlearn: 0.0209889\ttotal: 2.23s\tremaining: 1.3s\n",
      "631:\tlearn: 0.0209617\ttotal: 2.23s\tremaining: 1.3s\n",
      "632:\tlearn: 0.0209437\ttotal: 2.24s\tremaining: 1.3s\n",
      "633:\tlearn: 0.0209221\ttotal: 2.24s\tremaining: 1.29s\n",
      "634:\tlearn: 0.0208980\ttotal: 2.24s\tremaining: 1.29s\n",
      "635:\tlearn: 0.0208900\ttotal: 2.25s\tremaining: 1.29s\n",
      "636:\tlearn: 0.0208479\ttotal: 2.25s\tremaining: 1.28s\n",
      "637:\tlearn: 0.0208356\ttotal: 2.25s\tremaining: 1.28s\n",
      "638:\tlearn: 0.0208303\ttotal: 2.25s\tremaining: 1.27s\n",
      "639:\tlearn: 0.0208166\ttotal: 2.26s\tremaining: 1.27s\n",
      "640:\tlearn: 0.0207863\ttotal: 2.26s\tremaining: 1.27s\n",
      "641:\tlearn: 0.0207786\ttotal: 2.27s\tremaining: 1.26s\n",
      "642:\tlearn: 0.0207558\ttotal: 2.27s\tremaining: 1.26s\n",
      "643:\tlearn: 0.0207274\ttotal: 2.27s\tremaining: 1.25s\n",
      "644:\tlearn: 0.0207100\ttotal: 2.27s\tremaining: 1.25s\n",
      "645:\tlearn: 0.0206968\ttotal: 2.28s\tremaining: 1.25s\n",
      "646:\tlearn: 0.0206814\ttotal: 2.28s\tremaining: 1.24s\n",
      "647:\tlearn: 0.0206740\ttotal: 2.28s\tremaining: 1.24s\n",
      "648:\tlearn: 0.0206486\ttotal: 2.29s\tremaining: 1.24s\n",
      "649:\tlearn: 0.0206306\ttotal: 2.29s\tremaining: 1.23s\n",
      "650:\tlearn: 0.0206278\ttotal: 2.29s\tremaining: 1.23s\n",
      "651:\tlearn: 0.0206227\ttotal: 2.29s\tremaining: 1.22s\n",
      "652:\tlearn: 0.0206060\ttotal: 2.3s\tremaining: 1.22s\n",
      "653:\tlearn: 0.0205523\ttotal: 2.3s\tremaining: 1.22s\n",
      "654:\tlearn: 0.0205481\ttotal: 2.3s\tremaining: 1.21s\n",
      "655:\tlearn: 0.0205238\ttotal: 2.31s\tremaining: 1.21s\n",
      "656:\tlearn: 0.0204945\ttotal: 2.31s\tremaining: 1.21s\n",
      "657:\tlearn: 0.0204767\ttotal: 2.31s\tremaining: 1.2s\n",
      "658:\tlearn: 0.0204596\ttotal: 2.31s\tremaining: 1.2s\n",
      "659:\tlearn: 0.0204548\ttotal: 2.32s\tremaining: 1.19s\n",
      "660:\tlearn: 0.0204265\ttotal: 2.32s\tremaining: 1.19s\n",
      "661:\tlearn: 0.0204158\ttotal: 2.32s\tremaining: 1.19s\n",
      "662:\tlearn: 0.0203897\ttotal: 2.33s\tremaining: 1.18s\n",
      "663:\tlearn: 0.0203825\ttotal: 2.33s\tremaining: 1.18s\n",
      "664:\tlearn: 0.0203658\ttotal: 2.33s\tremaining: 1.18s\n",
      "665:\tlearn: 0.0203582\ttotal: 2.33s\tremaining: 1.17s\n",
      "666:\tlearn: 0.0203557\ttotal: 2.34s\tremaining: 1.17s\n",
      "667:\tlearn: 0.0203478\ttotal: 2.34s\tremaining: 1.16s\n",
      "668:\tlearn: 0.0203401\ttotal: 2.35s\tremaining: 1.16s\n",
      "669:\tlearn: 0.0203170\ttotal: 2.35s\tremaining: 1.16s\n",
      "670:\tlearn: 0.0202989\ttotal: 2.35s\tremaining: 1.15s\n",
      "671:\tlearn: 0.0202915\ttotal: 2.35s\tremaining: 1.15s\n",
      "672:\tlearn: 0.0202890\ttotal: 2.36s\tremaining: 1.15s\n",
      "673:\tlearn: 0.0202616\ttotal: 2.36s\tremaining: 1.14s\n",
      "674:\tlearn: 0.0202363\ttotal: 2.37s\tremaining: 1.14s\n",
      "675:\tlearn: 0.0202141\ttotal: 2.37s\tremaining: 1.14s\n",
      "676:\tlearn: 0.0202116\ttotal: 2.37s\tremaining: 1.13s\n",
      "677:\tlearn: 0.0202042\ttotal: 2.37s\tremaining: 1.13s\n",
      "678:\tlearn: 0.0201949\ttotal: 2.38s\tremaining: 1.12s\n",
      "679:\tlearn: 0.0201698\ttotal: 2.38s\tremaining: 1.12s\n",
      "680:\tlearn: 0.0201535\ttotal: 2.38s\tremaining: 1.12s\n",
      "681:\tlearn: 0.0201374\ttotal: 2.39s\tremaining: 1.11s\n",
      "682:\tlearn: 0.0201110\ttotal: 2.39s\tremaining: 1.11s\n",
      "683:\tlearn: 0.0200641\ttotal: 2.39s\tremaining: 1.1s\n",
      "684:\tlearn: 0.0200568\ttotal: 2.4s\tremaining: 1.1s\n",
      "685:\tlearn: 0.0200444\ttotal: 2.4s\tremaining: 1.1s\n",
      "686:\tlearn: 0.0200394\ttotal: 2.4s\tremaining: 1.09s\n",
      "687:\tlearn: 0.0200326\ttotal: 2.4s\tremaining: 1.09s\n",
      "688:\tlearn: 0.0199951\ttotal: 2.41s\tremaining: 1.09s\n",
      "689:\tlearn: 0.0199725\ttotal: 2.41s\tremaining: 1.08s\n",
      "690:\tlearn: 0.0199518\ttotal: 2.41s\tremaining: 1.08s\n",
      "691:\tlearn: 0.0199303\ttotal: 2.42s\tremaining: 1.07s\n",
      "692:\tlearn: 0.0199155\ttotal: 2.42s\tremaining: 1.07s\n",
      "693:\tlearn: 0.0198803\ttotal: 2.42s\tremaining: 1.07s\n",
      "694:\tlearn: 0.0198630\ttotal: 2.43s\tremaining: 1.07s\n",
      "695:\tlearn: 0.0198560\ttotal: 2.43s\tremaining: 1.06s\n",
      "696:\tlearn: 0.0198491\ttotal: 2.44s\tremaining: 1.06s\n",
      "697:\tlearn: 0.0198426\ttotal: 2.44s\tremaining: 1.05s\n",
      "698:\tlearn: 0.0198377\ttotal: 2.44s\tremaining: 1.05s\n",
      "699:\tlearn: 0.0198121\ttotal: 2.44s\tremaining: 1.05s\n",
      "700:\tlearn: 0.0197952\ttotal: 2.45s\tremaining: 1.04s\n",
      "701:\tlearn: 0.0197799\ttotal: 2.45s\tremaining: 1.04s\n",
      "702:\tlearn: 0.0197695\ttotal: 2.45s\tremaining: 1.04s\n",
      "703:\tlearn: 0.0197448\ttotal: 2.46s\tremaining: 1.03s\n",
      "704:\tlearn: 0.0197424\ttotal: 2.46s\tremaining: 1.03s\n",
      "705:\tlearn: 0.0197278\ttotal: 2.46s\tremaining: 1.02s\n",
      "706:\tlearn: 0.0197212\ttotal: 2.46s\tremaining: 1.02s\n",
      "707:\tlearn: 0.0196997\ttotal: 2.47s\tremaining: 1.02s\n",
      "708:\tlearn: 0.0196965\ttotal: 2.47s\tremaining: 1.01s\n",
      "709:\tlearn: 0.0196778\ttotal: 2.47s\tremaining: 1.01s\n",
      "710:\tlearn: 0.0196480\ttotal: 2.48s\tremaining: 1.01s\n",
      "711:\tlearn: 0.0196241\ttotal: 2.48s\tremaining: 1s\n",
      "712:\tlearn: 0.0196016\ttotal: 2.48s\tremaining: 1000ms\n",
      "713:\tlearn: 0.0195785\ttotal: 2.49s\tremaining: 996ms\n",
      "714:\tlearn: 0.0195721\ttotal: 2.49s\tremaining: 992ms\n",
      "715:\tlearn: 0.0195493\ttotal: 2.49s\tremaining: 989ms\n",
      "716:\tlearn: 0.0195471\ttotal: 2.5s\tremaining: 985ms\n",
      "717:\tlearn: 0.0195328\ttotal: 2.5s\tremaining: 981ms\n",
      "718:\tlearn: 0.0195299\ttotal: 2.5s\tremaining: 978ms\n",
      "719:\tlearn: 0.0195130\ttotal: 2.5s\tremaining: 974ms\n",
      "720:\tlearn: 0.0195069\ttotal: 2.51s\tremaining: 970ms\n",
      "721:\tlearn: 0.0194849\ttotal: 2.51s\tremaining: 967ms\n",
      "722:\tlearn: 0.0194633\ttotal: 2.51s\tremaining: 963ms\n",
      "723:\tlearn: 0.0194435\ttotal: 2.52s\tremaining: 959ms\n",
      "724:\tlearn: 0.0194255\ttotal: 2.52s\tremaining: 956ms\n",
      "725:\tlearn: 0.0194157\ttotal: 2.52s\tremaining: 952ms\n",
      "726:\tlearn: 0.0193845\ttotal: 2.52s\tremaining: 948ms\n",
      "727:\tlearn: 0.0193655\ttotal: 2.53s\tremaining: 945ms\n",
      "728:\tlearn: 0.0193493\ttotal: 2.53s\tremaining: 941ms\n",
      "729:\tlearn: 0.0193367\ttotal: 2.54s\tremaining: 938ms\n",
      "730:\tlearn: 0.0193181\ttotal: 2.54s\tremaining: 934ms\n",
      "731:\tlearn: 0.0193062\ttotal: 2.54s\tremaining: 931ms\n",
      "732:\tlearn: 0.0192889\ttotal: 2.54s\tremaining: 927ms\n",
      "733:\tlearn: 0.0192861\ttotal: 2.55s\tremaining: 923ms\n",
      "734:\tlearn: 0.0192593\ttotal: 2.55s\tremaining: 920ms\n",
      "735:\tlearn: 0.0192530\ttotal: 2.55s\tremaining: 916ms\n",
      "736:\tlearn: 0.0192414\ttotal: 2.56s\tremaining: 913ms\n",
      "737:\tlearn: 0.0192367\ttotal: 2.56s\tremaining: 909ms\n",
      "738:\tlearn: 0.0192132\ttotal: 2.56s\tremaining: 906ms\n",
      "739:\tlearn: 0.0191841\ttotal: 2.57s\tremaining: 902ms\n",
      "740:\tlearn: 0.0191660\ttotal: 2.57s\tremaining: 898ms\n",
      "741:\tlearn: 0.0191336\ttotal: 2.57s\tremaining: 895ms\n",
      "742:\tlearn: 0.0191170\ttotal: 2.58s\tremaining: 891ms\n",
      "743:\tlearn: 0.0190973\ttotal: 2.58s\tremaining: 887ms\n",
      "744:\tlearn: 0.0190804\ttotal: 2.58s\tremaining: 884ms\n",
      "745:\tlearn: 0.0190761\ttotal: 2.58s\tremaining: 880ms\n",
      "746:\tlearn: 0.0190716\ttotal: 2.59s\tremaining: 877ms\n",
      "747:\tlearn: 0.0190603\ttotal: 2.59s\tremaining: 873ms\n",
      "748:\tlearn: 0.0190545\ttotal: 2.59s\tremaining: 869ms\n",
      "749:\tlearn: 0.0190413\ttotal: 2.6s\tremaining: 866ms\n",
      "750:\tlearn: 0.0190250\ttotal: 2.6s\tremaining: 862ms\n",
      "751:\tlearn: 0.0190034\ttotal: 2.6s\tremaining: 859ms\n",
      "752:\tlearn: 0.0189744\ttotal: 2.61s\tremaining: 855ms\n",
      "753:\tlearn: 0.0189467\ttotal: 2.61s\tremaining: 851ms\n",
      "754:\tlearn: 0.0189263\ttotal: 2.61s\tremaining: 848ms\n",
      "755:\tlearn: 0.0189090\ttotal: 2.62s\tremaining: 844ms\n",
      "756:\tlearn: 0.0189002\ttotal: 2.62s\tremaining: 841ms\n",
      "757:\tlearn: 0.0188845\ttotal: 2.62s\tremaining: 837ms\n",
      "758:\tlearn: 0.0188694\ttotal: 2.63s\tremaining: 834ms\n",
      "759:\tlearn: 0.0188638\ttotal: 2.63s\tremaining: 830ms\n",
      "760:\tlearn: 0.0188545\ttotal: 2.63s\tremaining: 827ms\n",
      "761:\tlearn: 0.0188486\ttotal: 2.63s\tremaining: 823ms\n",
      "762:\tlearn: 0.0188262\ttotal: 2.64s\tremaining: 819ms\n",
      "763:\tlearn: 0.0188116\ttotal: 2.64s\tremaining: 816ms\n",
      "764:\tlearn: 0.0187967\ttotal: 2.64s\tremaining: 812ms\n",
      "765:\tlearn: 0.0187910\ttotal: 2.65s\tremaining: 809ms\n",
      "766:\tlearn: 0.0187742\ttotal: 2.65s\tremaining: 805ms\n",
      "767:\tlearn: 0.0187479\ttotal: 2.65s\tremaining: 801ms\n",
      "768:\tlearn: 0.0187322\ttotal: 2.65s\tremaining: 798ms\n",
      "769:\tlearn: 0.0187113\ttotal: 2.66s\tremaining: 794ms\n",
      "770:\tlearn: 0.0187023\ttotal: 2.66s\tremaining: 791ms\n",
      "771:\tlearn: 0.0186821\ttotal: 2.66s\tremaining: 787ms\n",
      "772:\tlearn: 0.0186702\ttotal: 2.67s\tremaining: 783ms\n",
      "773:\tlearn: 0.0186504\ttotal: 2.67s\tremaining: 780ms\n",
      "774:\tlearn: 0.0186448\ttotal: 2.67s\tremaining: 776ms\n",
      "775:\tlearn: 0.0186358\ttotal: 2.68s\tremaining: 773ms\n",
      "776:\tlearn: 0.0186244\ttotal: 2.68s\tremaining: 769ms\n",
      "777:\tlearn: 0.0186048\ttotal: 2.68s\tremaining: 765ms\n",
      "778:\tlearn: 0.0185994\ttotal: 2.69s\tremaining: 762ms\n",
      "779:\tlearn: 0.0185941\ttotal: 2.69s\tremaining: 758ms\n",
      "780:\tlearn: 0.0185811\ttotal: 2.69s\tremaining: 755ms\n",
      "781:\tlearn: 0.0185649\ttotal: 2.69s\tremaining: 751ms\n",
      "782:\tlearn: 0.0185598\ttotal: 2.7s\tremaining: 748ms\n",
      "783:\tlearn: 0.0185486\ttotal: 2.7s\tremaining: 744ms\n",
      "784:\tlearn: 0.0185303\ttotal: 2.7s\tremaining: 740ms\n",
      "785:\tlearn: 0.0185089\ttotal: 2.71s\tremaining: 737ms\n",
      "786:\tlearn: 0.0184978\ttotal: 2.71s\tremaining: 733ms\n",
      "787:\tlearn: 0.0184788\ttotal: 2.71s\tremaining: 730ms\n",
      "788:\tlearn: 0.0184637\ttotal: 2.71s\tremaining: 726ms\n",
      "789:\tlearn: 0.0184340\ttotal: 2.72s\tremaining: 723ms\n",
      "790:\tlearn: 0.0184089\ttotal: 2.72s\tremaining: 719ms\n",
      "791:\tlearn: 0.0183841\ttotal: 2.72s\tremaining: 715ms\n",
      "792:\tlearn: 0.0183753\ttotal: 2.73s\tremaining: 712ms\n",
      "793:\tlearn: 0.0183612\ttotal: 2.73s\tremaining: 708ms\n",
      "794:\tlearn: 0.0183560\ttotal: 2.73s\tremaining: 705ms\n",
      "795:\tlearn: 0.0183330\ttotal: 2.74s\tremaining: 701ms\n",
      "796:\tlearn: 0.0183178\ttotal: 2.74s\tremaining: 698ms\n",
      "797:\tlearn: 0.0183126\ttotal: 2.74s\tremaining: 694ms\n",
      "798:\tlearn: 0.0182969\ttotal: 2.75s\tremaining: 691ms\n",
      "799:\tlearn: 0.0182686\ttotal: 2.75s\tremaining: 688ms\n",
      "800:\tlearn: 0.0182395\ttotal: 2.75s\tremaining: 684ms\n",
      "801:\tlearn: 0.0182309\ttotal: 2.76s\tremaining: 681ms\n",
      "802:\tlearn: 0.0182156\ttotal: 2.76s\tremaining: 677ms\n",
      "803:\tlearn: 0.0182049\ttotal: 2.76s\tremaining: 674ms\n",
      "804:\tlearn: 0.0181964\ttotal: 2.77s\tremaining: 670ms\n",
      "805:\tlearn: 0.0181826\ttotal: 2.77s\tremaining: 667ms\n",
      "806:\tlearn: 0.0181682\ttotal: 2.77s\tremaining: 663ms\n",
      "807:\tlearn: 0.0181482\ttotal: 2.78s\tremaining: 660ms\n",
      "808:\tlearn: 0.0181299\ttotal: 2.78s\tremaining: 656ms\n",
      "809:\tlearn: 0.0181250\ttotal: 2.78s\tremaining: 653ms\n",
      "810:\tlearn: 0.0181073\ttotal: 2.78s\tremaining: 649ms\n",
      "811:\tlearn: 0.0181029\ttotal: 2.79s\tremaining: 645ms\n",
      "812:\tlearn: 0.0180924\ttotal: 2.79s\tremaining: 642ms\n",
      "813:\tlearn: 0.0180877\ttotal: 2.79s\tremaining: 638ms\n",
      "814:\tlearn: 0.0180693\ttotal: 2.8s\tremaining: 635ms\n",
      "815:\tlearn: 0.0180447\ttotal: 2.8s\tremaining: 631ms\n",
      "816:\tlearn: 0.0180213\ttotal: 2.8s\tremaining: 628ms\n",
      "817:\tlearn: 0.0179794\ttotal: 2.81s\tremaining: 624ms\n",
      "818:\tlearn: 0.0179655\ttotal: 2.81s\tremaining: 621ms\n",
      "819:\tlearn: 0.0179467\ttotal: 2.81s\tremaining: 617ms\n",
      "820:\tlearn: 0.0179364\ttotal: 2.81s\tremaining: 614ms\n",
      "821:\tlearn: 0.0179166\ttotal: 2.82s\tremaining: 610ms\n",
      "822:\tlearn: 0.0178762\ttotal: 2.82s\tremaining: 607ms\n",
      "823:\tlearn: 0.0178630\ttotal: 2.82s\tremaining: 603ms\n",
      "824:\tlearn: 0.0178455\ttotal: 2.83s\tremaining: 600ms\n",
      "825:\tlearn: 0.0178372\ttotal: 2.83s\tremaining: 596ms\n",
      "826:\tlearn: 0.0178274\ttotal: 2.83s\tremaining: 593ms\n",
      "827:\tlearn: 0.0178081\ttotal: 2.84s\tremaining: 589ms\n",
      "828:\tlearn: 0.0177951\ttotal: 2.84s\tremaining: 586ms\n",
      "829:\tlearn: 0.0177858\ttotal: 2.84s\tremaining: 582ms\n",
      "830:\tlearn: 0.0177737\ttotal: 2.85s\tremaining: 579ms\n",
      "831:\tlearn: 0.0177559\ttotal: 2.85s\tremaining: 575ms\n",
      "832:\tlearn: 0.0177369\ttotal: 2.85s\tremaining: 572ms\n",
      "833:\tlearn: 0.0177134\ttotal: 2.85s\tremaining: 568ms\n",
      "834:\tlearn: 0.0177097\ttotal: 2.86s\tremaining: 565ms\n",
      "835:\tlearn: 0.0176921\ttotal: 2.86s\tremaining: 561ms\n",
      "836:\tlearn: 0.0176839\ttotal: 2.86s\tremaining: 558ms\n",
      "837:\tlearn: 0.0176623\ttotal: 2.87s\tremaining: 554ms\n",
      "838:\tlearn: 0.0176499\ttotal: 2.87s\tremaining: 551ms\n",
      "839:\tlearn: 0.0176287\ttotal: 2.87s\tremaining: 547ms\n",
      "840:\tlearn: 0.0176031\ttotal: 2.88s\tremaining: 544ms\n",
      "841:\tlearn: 0.0175906\ttotal: 2.88s\tremaining: 540ms\n",
      "842:\tlearn: 0.0175785\ttotal: 2.88s\tremaining: 537ms\n",
      "843:\tlearn: 0.0175561\ttotal: 2.88s\tremaining: 533ms\n",
      "844:\tlearn: 0.0175439\ttotal: 2.89s\tremaining: 530ms\n",
      "845:\tlearn: 0.0175403\ttotal: 2.89s\tremaining: 526ms\n",
      "846:\tlearn: 0.0175360\ttotal: 2.89s\tremaining: 523ms\n",
      "847:\tlearn: 0.0175137\ttotal: 2.9s\tremaining: 519ms\n",
      "848:\tlearn: 0.0175058\ttotal: 2.9s\tremaining: 516ms\n",
      "849:\tlearn: 0.0174948\ttotal: 2.9s\tremaining: 512ms\n",
      "850:\tlearn: 0.0174848\ttotal: 2.91s\tremaining: 509ms\n",
      "851:\tlearn: 0.0174731\ttotal: 2.91s\tremaining: 506ms\n",
      "852:\tlearn: 0.0174499\ttotal: 2.91s\tremaining: 502ms\n",
      "853:\tlearn: 0.0174312\ttotal: 2.92s\tremaining: 499ms\n",
      "854:\tlearn: 0.0174276\ttotal: 2.92s\tremaining: 495ms\n",
      "855:\tlearn: 0.0174236\ttotal: 2.92s\tremaining: 492ms\n",
      "856:\tlearn: 0.0173993\ttotal: 2.93s\tremaining: 488ms\n",
      "857:\tlearn: 0.0173874\ttotal: 2.93s\tremaining: 485ms\n",
      "858:\tlearn: 0.0173608\ttotal: 2.93s\tremaining: 481ms\n",
      "859:\tlearn: 0.0173442\ttotal: 2.94s\tremaining: 478ms\n",
      "860:\tlearn: 0.0173403\ttotal: 2.94s\tremaining: 475ms\n",
      "861:\tlearn: 0.0173242\ttotal: 2.94s\tremaining: 471ms\n",
      "862:\tlearn: 0.0173058\ttotal: 2.95s\tremaining: 468ms\n",
      "863:\tlearn: 0.0172827\ttotal: 2.95s\tremaining: 464ms\n",
      "864:\tlearn: 0.0172730\ttotal: 2.95s\tremaining: 461ms\n",
      "865:\tlearn: 0.0172670\ttotal: 2.96s\tremaining: 458ms\n",
      "866:\tlearn: 0.0172576\ttotal: 2.96s\tremaining: 454ms\n",
      "867:\tlearn: 0.0172405\ttotal: 2.96s\tremaining: 451ms\n",
      "868:\tlearn: 0.0172385\ttotal: 2.97s\tremaining: 447ms\n",
      "869:\tlearn: 0.0172265\ttotal: 2.97s\tremaining: 444ms\n",
      "870:\tlearn: 0.0171925\ttotal: 2.97s\tremaining: 440ms\n",
      "871:\tlearn: 0.0171892\ttotal: 2.98s\tremaining: 437ms\n",
      "872:\tlearn: 0.0171738\ttotal: 2.98s\tremaining: 433ms\n",
      "873:\tlearn: 0.0171571\ttotal: 2.98s\tremaining: 430ms\n",
      "874:\tlearn: 0.0171409\ttotal: 2.98s\tremaining: 427ms\n",
      "875:\tlearn: 0.0171240\ttotal: 2.99s\tremaining: 423ms\n",
      "876:\tlearn: 0.0171006\ttotal: 2.99s\tremaining: 420ms\n",
      "877:\tlearn: 0.0170830\ttotal: 2.99s\tremaining: 416ms\n",
      "878:\tlearn: 0.0170714\ttotal: 3s\tremaining: 413ms\n",
      "879:\tlearn: 0.0170598\ttotal: 3s\tremaining: 409ms\n",
      "880:\tlearn: 0.0170427\ttotal: 3s\tremaining: 406ms\n",
      "881:\tlearn: 0.0170314\ttotal: 3.01s\tremaining: 402ms\n",
      "882:\tlearn: 0.0170148\ttotal: 3.01s\tremaining: 399ms\n",
      "883:\tlearn: 0.0170056\ttotal: 3.01s\tremaining: 395ms\n",
      "884:\tlearn: 0.0169966\ttotal: 3.02s\tremaining: 392ms\n",
      "885:\tlearn: 0.0169875\ttotal: 3.02s\tremaining: 388ms\n",
      "886:\tlearn: 0.0169705\ttotal: 3.02s\tremaining: 385ms\n",
      "887:\tlearn: 0.0169531\ttotal: 3.02s\tremaining: 382ms\n",
      "888:\tlearn: 0.0169387\ttotal: 3.03s\tremaining: 378ms\n",
      "889:\tlearn: 0.0169278\ttotal: 3.03s\tremaining: 375ms\n",
      "890:\tlearn: 0.0169238\ttotal: 3.03s\tremaining: 371ms\n",
      "891:\tlearn: 0.0169207\ttotal: 3.04s\tremaining: 368ms\n",
      "892:\tlearn: 0.0169018\ttotal: 3.04s\tremaining: 364ms\n",
      "893:\tlearn: 0.0168933\ttotal: 3.04s\tremaining: 361ms\n",
      "894:\tlearn: 0.0168845\ttotal: 3.05s\tremaining: 357ms\n",
      "895:\tlearn: 0.0168704\ttotal: 3.05s\tremaining: 354ms\n",
      "896:\tlearn: 0.0168618\ttotal: 3.05s\tremaining: 351ms\n",
      "897:\tlearn: 0.0168535\ttotal: 3.06s\tremaining: 347ms\n",
      "898:\tlearn: 0.0168399\ttotal: 3.06s\tremaining: 344ms\n",
      "899:\tlearn: 0.0168155\ttotal: 3.06s\tremaining: 340ms\n",
      "900:\tlearn: 0.0168125\ttotal: 3.06s\tremaining: 337ms\n",
      "901:\tlearn: 0.0167959\ttotal: 3.07s\tremaining: 333ms\n",
      "902:\tlearn: 0.0167872\ttotal: 3.07s\tremaining: 330ms\n",
      "903:\tlearn: 0.0167724\ttotal: 3.08s\tremaining: 327ms\n",
      "904:\tlearn: 0.0167490\ttotal: 3.08s\tremaining: 323ms\n",
      "905:\tlearn: 0.0167373\ttotal: 3.08s\tremaining: 320ms\n",
      "906:\tlearn: 0.0167042\ttotal: 3.08s\tremaining: 316ms\n",
      "907:\tlearn: 0.0166791\ttotal: 3.09s\tremaining: 313ms\n",
      "908:\tlearn: 0.0166641\ttotal: 3.09s\tremaining: 309ms\n",
      "909:\tlearn: 0.0166483\ttotal: 3.09s\tremaining: 306ms\n",
      "910:\tlearn: 0.0166408\ttotal: 3.1s\tremaining: 302ms\n",
      "911:\tlearn: 0.0166251\ttotal: 3.1s\tremaining: 299ms\n",
      "912:\tlearn: 0.0166097\ttotal: 3.1s\tremaining: 296ms\n",
      "913:\tlearn: 0.0166013\ttotal: 3.1s\tremaining: 292ms\n",
      "914:\tlearn: 0.0165833\ttotal: 3.11s\tremaining: 289ms\n",
      "915:\tlearn: 0.0165776\ttotal: 3.11s\tremaining: 285ms\n",
      "916:\tlearn: 0.0165721\ttotal: 3.11s\tremaining: 282ms\n",
      "917:\tlearn: 0.0165638\ttotal: 3.12s\tremaining: 278ms\n",
      "918:\tlearn: 0.0165565\ttotal: 3.12s\tremaining: 275ms\n",
      "919:\tlearn: 0.0165458\ttotal: 3.12s\tremaining: 272ms\n",
      "920:\tlearn: 0.0165352\ttotal: 3.13s\tremaining: 268ms\n",
      "921:\tlearn: 0.0165271\ttotal: 3.13s\tremaining: 265ms\n",
      "922:\tlearn: 0.0165241\ttotal: 3.13s\tremaining: 261ms\n",
      "923:\tlearn: 0.0165162\ttotal: 3.14s\tremaining: 258ms\n",
      "924:\tlearn: 0.0165016\ttotal: 3.14s\tremaining: 255ms\n",
      "925:\tlearn: 0.0164875\ttotal: 3.15s\tremaining: 251ms\n",
      "926:\tlearn: 0.0164760\ttotal: 3.15s\tremaining: 248ms\n",
      "927:\tlearn: 0.0164667\ttotal: 3.15s\tremaining: 245ms\n",
      "928:\tlearn: 0.0164496\ttotal: 3.16s\tremaining: 241ms\n",
      "929:\tlearn: 0.0164442\ttotal: 3.16s\tremaining: 238ms\n",
      "930:\tlearn: 0.0164295\ttotal: 3.16s\tremaining: 235ms\n",
      "931:\tlearn: 0.0164160\ttotal: 3.17s\tremaining: 231ms\n",
      "932:\tlearn: 0.0164139\ttotal: 3.17s\tremaining: 228ms\n",
      "933:\tlearn: 0.0164061\ttotal: 3.17s\tremaining: 224ms\n",
      "934:\tlearn: 0.0163848\ttotal: 3.18s\tremaining: 221ms\n",
      "935:\tlearn: 0.0163736\ttotal: 3.18s\tremaining: 217ms\n",
      "936:\tlearn: 0.0163683\ttotal: 3.18s\tremaining: 214ms\n",
      "937:\tlearn: 0.0163497\ttotal: 3.19s\tremaining: 211ms\n",
      "938:\tlearn: 0.0163413\ttotal: 3.19s\tremaining: 207ms\n",
      "939:\tlearn: 0.0163338\ttotal: 3.19s\tremaining: 204ms\n",
      "940:\tlearn: 0.0163206\ttotal: 3.2s\tremaining: 200ms\n",
      "941:\tlearn: 0.0163186\ttotal: 3.2s\tremaining: 197ms\n",
      "942:\tlearn: 0.0163110\ttotal: 3.2s\tremaining: 194ms\n",
      "943:\tlearn: 0.0163037\ttotal: 3.21s\tremaining: 190ms\n",
      "944:\tlearn: 0.0162893\ttotal: 3.21s\tremaining: 187ms\n",
      "945:\tlearn: 0.0162820\ttotal: 3.21s\tremaining: 183ms\n",
      "946:\tlearn: 0.0162713\ttotal: 3.21s\tremaining: 180ms\n",
      "947:\tlearn: 0.0162588\ttotal: 3.22s\tremaining: 177ms\n",
      "948:\tlearn: 0.0162363\ttotal: 3.22s\tremaining: 173ms\n",
      "949:\tlearn: 0.0162244\ttotal: 3.23s\tremaining: 170ms\n",
      "950:\tlearn: 0.0162079\ttotal: 3.23s\tremaining: 166ms\n",
      "951:\tlearn: 0.0162027\ttotal: 3.23s\tremaining: 163ms\n",
      "952:\tlearn: 0.0161889\ttotal: 3.23s\tremaining: 160ms\n",
      "953:\tlearn: 0.0161793\ttotal: 3.24s\tremaining: 156ms\n",
      "954:\tlearn: 0.0161596\ttotal: 3.24s\tremaining: 153ms\n",
      "955:\tlearn: 0.0161496\ttotal: 3.25s\tremaining: 149ms\n",
      "956:\tlearn: 0.0161295\ttotal: 3.25s\tremaining: 146ms\n",
      "957:\tlearn: 0.0161123\ttotal: 3.25s\tremaining: 143ms\n",
      "958:\tlearn: 0.0160980\ttotal: 3.25s\tremaining: 139ms\n",
      "959:\tlearn: 0.0160787\ttotal: 3.26s\tremaining: 136ms\n",
      "960:\tlearn: 0.0160710\ttotal: 3.26s\tremaining: 132ms\n",
      "961:\tlearn: 0.0160613\ttotal: 3.26s\tremaining: 129ms\n",
      "962:\tlearn: 0.0160522\ttotal: 3.27s\tremaining: 126ms\n",
      "963:\tlearn: 0.0160442\ttotal: 3.27s\tremaining: 122ms\n",
      "964:\tlearn: 0.0160303\ttotal: 3.27s\tremaining: 119ms\n",
      "965:\tlearn: 0.0160182\ttotal: 3.28s\tremaining: 115ms\n",
      "966:\tlearn: 0.0160113\ttotal: 3.28s\tremaining: 112ms\n",
      "967:\tlearn: 0.0160011\ttotal: 3.28s\tremaining: 109ms\n",
      "968:\tlearn: 0.0159961\ttotal: 3.29s\tremaining: 105ms\n",
      "969:\tlearn: 0.0159652\ttotal: 3.29s\tremaining: 102ms\n",
      "970:\tlearn: 0.0159434\ttotal: 3.29s\tremaining: 98.4ms\n",
      "971:\tlearn: 0.0159414\ttotal: 3.3s\tremaining: 95ms\n",
      "972:\tlearn: 0.0159194\ttotal: 3.3s\tremaining: 91.6ms\n",
      "973:\tlearn: 0.0158971\ttotal: 3.3s\tremaining: 88.2ms\n",
      "974:\tlearn: 0.0158878\ttotal: 3.31s\tremaining: 84.8ms\n",
      "975:\tlearn: 0.0158775\ttotal: 3.31s\tremaining: 81.4ms\n",
      "976:\tlearn: 0.0158618\ttotal: 3.31s\tremaining: 78ms\n",
      "977:\tlearn: 0.0158541\ttotal: 3.31s\tremaining: 74.6ms\n",
      "978:\tlearn: 0.0158443\ttotal: 3.32s\tremaining: 71.2ms\n",
      "979:\tlearn: 0.0158372\ttotal: 3.32s\tremaining: 67.8ms\n",
      "980:\tlearn: 0.0158295\ttotal: 3.33s\tremaining: 64.4ms\n",
      "981:\tlearn: 0.0158266\ttotal: 3.33s\tremaining: 61ms\n",
      "982:\tlearn: 0.0158135\ttotal: 3.33s\tremaining: 57.6ms\n",
      "983:\tlearn: 0.0157926\ttotal: 3.33s\tremaining: 54.2ms\n",
      "984:\tlearn: 0.0157859\ttotal: 3.34s\tremaining: 50.8ms\n",
      "985:\tlearn: 0.0157744\ttotal: 3.34s\tremaining: 47.4ms\n",
      "986:\tlearn: 0.0157674\ttotal: 3.34s\tremaining: 44ms\n",
      "987:\tlearn: 0.0157594\ttotal: 3.35s\tremaining: 40.7ms\n",
      "988:\tlearn: 0.0157483\ttotal: 3.36s\tremaining: 37.4ms\n",
      "989:\tlearn: 0.0157322\ttotal: 3.36s\tremaining: 34ms\n",
      "990:\tlearn: 0.0157260\ttotal: 3.37s\tremaining: 30.6ms\n",
      "991:\tlearn: 0.0157128\ttotal: 3.37s\tremaining: 27.2ms\n",
      "992:\tlearn: 0.0157079\ttotal: 3.37s\tremaining: 23.8ms\n",
      "993:\tlearn: 0.0156981\ttotal: 3.38s\tremaining: 20.4ms\n",
      "994:\tlearn: 0.0156942\ttotal: 3.38s\tremaining: 17ms\n",
      "995:\tlearn: 0.0156772\ttotal: 3.38s\tremaining: 13.6ms\n",
      "996:\tlearn: 0.0156695\ttotal: 3.38s\tremaining: 10.2ms\n",
      "997:\tlearn: 0.0156647\ttotal: 3.39s\tremaining: 6.79ms\n",
      "998:\tlearn: 0.0156520\ttotal: 3.39s\tremaining: 3.39ms\n",
      "999:\tlearn: 0.0156439\ttotal: 3.39s\tremaining: 0us\n",
      "Model Performance for CatBoost\n",
      "Train Gini prob is 98.92657837747794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8004\n",
      "           1       1.00      0.62      0.77        96\n",
      "\n",
      "    accuracy                           1.00      8100\n",
      "   macro avg       1.00      0.81      0.88      8100\n",
      "weighted avg       1.00      1.00      1.00      8100\n",
      "\n",
      "[[8004    0]\n",
      " [  36   60]]\n",
      "Model Performance for CatBoost\n",
      "Test Gini prob is 56.87831888530839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2003\n",
      "           1       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       1.00      0.64      0.71      2025\n",
      "weighted avg       0.99      0.99      0.99      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  16    6]]\n",
      "Learning rate set to 0.025168\n",
      "0:\tlearn: 0.6393145\ttotal: 25.4ms\tremaining: 25.3s\n",
      "1:\tlearn: 0.5880384\ttotal: 45.3ms\tremaining: 22.6s\n",
      "2:\tlearn: 0.5413889\ttotal: 74.2ms\tremaining: 24.7s\n",
      "3:\tlearn: 0.4975526\ttotal: 109ms\tremaining: 27.1s\n",
      "4:\tlearn: 0.4608172\ttotal: 127ms\tremaining: 25.4s\n",
      "5:\tlearn: 0.4271679\ttotal: 169ms\tremaining: 28s\n",
      "6:\tlearn: 0.3947726\ttotal: 201ms\tremaining: 28.6s\n",
      "7:\tlearn: 0.3659844\ttotal: 230ms\tremaining: 28.5s\n",
      "8:\tlearn: 0.3391748\ttotal: 264ms\tremaining: 29.1s\n",
      "9:\tlearn: 0.3163983\ttotal: 273ms\tremaining: 27s\n",
      "10:\tlearn: 0.2956276\ttotal: 280ms\tremaining: 25.2s\n",
      "11:\tlearn: 0.2765124\ttotal: 303ms\tremaining: 25s\n",
      "12:\tlearn: 0.2580932\ttotal: 336ms\tremaining: 25.5s\n",
      "13:\tlearn: 0.2414801\ttotal: 358ms\tremaining: 25.2s\n",
      "14:\tlearn: 0.2269762\ttotal: 371ms\tremaining: 24.3s\n",
      "15:\tlearn: 0.2123943\ttotal: 404ms\tremaining: 24.8s\n",
      "16:\tlearn: 0.2000149\ttotal: 417ms\tremaining: 24.1s\n",
      "17:\tlearn: 0.1886223\ttotal: 454ms\tremaining: 24.8s\n",
      "18:\tlearn: 0.1788890\ttotal: 474ms\tremaining: 24.5s\n",
      "19:\tlearn: 0.1696728\ttotal: 497ms\tremaining: 24.3s\n",
      "20:\tlearn: 0.1615642\ttotal: 505ms\tremaining: 23.5s\n",
      "21:\tlearn: 0.1529455\ttotal: 539ms\tremaining: 24s\n",
      "22:\tlearn: 0.1462055\ttotal: 548ms\tremaining: 23.3s\n",
      "23:\tlearn: 0.1392208\ttotal: 583ms\tremaining: 23.7s\n",
      "24:\tlearn: 0.1333287\ttotal: 610ms\tremaining: 23.8s\n",
      "25:\tlearn: 0.1277874\ttotal: 643ms\tremaining: 24.1s\n",
      "26:\tlearn: 0.1219595\ttotal: 679ms\tremaining: 24.5s\n",
      "27:\tlearn: 0.1173419\ttotal: 702ms\tremaining: 24.4s\n",
      "28:\tlearn: 0.1129761\ttotal: 736ms\tremaining: 24.7s\n",
      "29:\tlearn: 0.1085955\ttotal: 768ms\tremaining: 24.8s\n",
      "30:\tlearn: 0.1051349\ttotal: 791ms\tremaining: 24.7s\n",
      "31:\tlearn: 0.1020923\ttotal: 799ms\tremaining: 24.2s\n",
      "32:\tlearn: 0.0990628\ttotal: 831ms\tremaining: 24.4s\n",
      "33:\tlearn: 0.0963604\ttotal: 849ms\tremaining: 24.1s\n",
      "34:\tlearn: 0.0925924\ttotal: 881ms\tremaining: 24.3s\n",
      "35:\tlearn: 0.0899368\ttotal: 903ms\tremaining: 24.2s\n",
      "36:\tlearn: 0.0874568\ttotal: 939ms\tremaining: 24.4s\n",
      "37:\tlearn: 0.0848595\ttotal: 973ms\tremaining: 24.6s\n",
      "38:\tlearn: 0.0831971\ttotal: 982ms\tremaining: 24.2s\n",
      "39:\tlearn: 0.0810208\ttotal: 1.01s\tremaining: 24.3s\n",
      "40:\tlearn: 0.0790707\ttotal: 1.04s\tremaining: 24.5s\n",
      "41:\tlearn: 0.0775850\ttotal: 1.06s\tremaining: 24.2s\n",
      "42:\tlearn: 0.0763842\ttotal: 1.07s\tremaining: 23.8s\n",
      "43:\tlearn: 0.0749132\ttotal: 1.1s\tremaining: 24s\n",
      "44:\tlearn: 0.0738793\ttotal: 1.11s\tremaining: 23.6s\n",
      "45:\tlearn: 0.0725112\ttotal: 1.14s\tremaining: 23.7s\n",
      "46:\tlearn: 0.0710269\ttotal: 1.18s\tremaining: 23.9s\n",
      "47:\tlearn: 0.0702135\ttotal: 1.19s\tremaining: 23.5s\n",
      "48:\tlearn: 0.0693943\ttotal: 1.2s\tremaining: 23.2s\n",
      "49:\tlearn: 0.0686290\ttotal: 1.21s\tremaining: 23.1s\n",
      "50:\tlearn: 0.0672616\ttotal: 1.25s\tremaining: 23.2s\n",
      "51:\tlearn: 0.0656455\ttotal: 1.28s\tremaining: 23.3s\n",
      "52:\tlearn: 0.0642685\ttotal: 1.31s\tremaining: 23.4s\n",
      "53:\tlearn: 0.0629514\ttotal: 1.34s\tremaining: 23.6s\n",
      "54:\tlearn: 0.0616647\ttotal: 1.38s\tremaining: 23.7s\n",
      "55:\tlearn: 0.0608021\ttotal: 1.41s\tremaining: 23.7s\n",
      "56:\tlearn: 0.0598288\ttotal: 1.44s\tremaining: 23.8s\n",
      "57:\tlearn: 0.0594910\ttotal: 1.45s\tremaining: 23.5s\n",
      "58:\tlearn: 0.0585131\ttotal: 1.48s\tremaining: 23.6s\n",
      "59:\tlearn: 0.0579215\ttotal: 1.51s\tremaining: 23.7s\n",
      "60:\tlearn: 0.0576232\ttotal: 1.54s\tremaining: 23.6s\n",
      "61:\tlearn: 0.0568345\ttotal: 1.57s\tremaining: 23.7s\n",
      "62:\tlearn: 0.0561596\ttotal: 1.6s\tremaining: 23.8s\n",
      "63:\tlearn: 0.0553691\ttotal: 1.64s\tremaining: 23.9s\n",
      "64:\tlearn: 0.0551549\ttotal: 1.65s\tremaining: 23.7s\n",
      "65:\tlearn: 0.0546880\ttotal: 1.69s\tremaining: 23.8s\n",
      "66:\tlearn: 0.0539565\ttotal: 1.72s\tremaining: 23.9s\n",
      "67:\tlearn: 0.0535416\ttotal: 1.75s\tremaining: 24s\n",
      "68:\tlearn: 0.0532734\ttotal: 1.78s\tremaining: 24.1s\n",
      "69:\tlearn: 0.0529105\ttotal: 1.81s\tremaining: 24.1s\n",
      "70:\tlearn: 0.0521654\ttotal: 1.85s\tremaining: 24.2s\n",
      "71:\tlearn: 0.0517181\ttotal: 1.88s\tremaining: 24.2s\n",
      "72:\tlearn: 0.0512763\ttotal: 1.91s\tremaining: 24.2s\n",
      "73:\tlearn: 0.0506695\ttotal: 1.94s\tremaining: 24.3s\n",
      "74:\tlearn: 0.0500893\ttotal: 1.97s\tremaining: 24.4s\n",
      "75:\tlearn: 0.0495598\ttotal: 2.01s\tremaining: 24.4s\n",
      "76:\tlearn: 0.0492247\ttotal: 2.04s\tremaining: 24.4s\n",
      "77:\tlearn: 0.0487429\ttotal: 2.07s\tremaining: 24.5s\n",
      "78:\tlearn: 0.0482206\ttotal: 2.1s\tremaining: 24.5s\n",
      "79:\tlearn: 0.0477267\ttotal: 2.13s\tremaining: 24.5s\n",
      "80:\tlearn: 0.0472875\ttotal: 2.16s\tremaining: 24.6s\n",
      "81:\tlearn: 0.0468992\ttotal: 2.2s\tremaining: 24.6s\n",
      "82:\tlearn: 0.0464969\ttotal: 2.24s\tremaining: 24.8s\n",
      "83:\tlearn: 0.0461151\ttotal: 2.28s\tremaining: 24.8s\n",
      "84:\tlearn: 0.0457815\ttotal: 2.31s\tremaining: 24.9s\n",
      "85:\tlearn: 0.0455316\ttotal: 2.34s\tremaining: 24.9s\n",
      "86:\tlearn: 0.0452117\ttotal: 2.37s\tremaining: 24.9s\n",
      "87:\tlearn: 0.0451870\ttotal: 2.38s\tremaining: 24.7s\n",
      "88:\tlearn: 0.0448752\ttotal: 2.42s\tremaining: 24.7s\n",
      "89:\tlearn: 0.0446182\ttotal: 2.45s\tremaining: 24.8s\n",
      "90:\tlearn: 0.0443614\ttotal: 2.49s\tremaining: 24.8s\n",
      "91:\tlearn: 0.0440875\ttotal: 2.52s\tremaining: 24.9s\n",
      "92:\tlearn: 0.0439547\ttotal: 2.55s\tremaining: 24.9s\n",
      "93:\tlearn: 0.0439391\ttotal: 2.56s\tremaining: 24.7s\n",
      "94:\tlearn: 0.0436374\ttotal: 2.59s\tremaining: 24.7s\n",
      "95:\tlearn: 0.0433994\ttotal: 2.62s\tremaining: 24.7s\n",
      "96:\tlearn: 0.0430801\ttotal: 2.65s\tremaining: 24.7s\n",
      "97:\tlearn: 0.0428921\ttotal: 2.69s\tremaining: 24.7s\n",
      "98:\tlearn: 0.0426621\ttotal: 2.72s\tremaining: 24.8s\n",
      "99:\tlearn: 0.0423602\ttotal: 2.75s\tremaining: 24.8s\n",
      "100:\tlearn: 0.0421546\ttotal: 2.78s\tremaining: 24.8s\n",
      "101:\tlearn: 0.0419578\ttotal: 2.81s\tremaining: 24.8s\n",
      "102:\tlearn: 0.0417890\ttotal: 2.85s\tremaining: 24.8s\n",
      "103:\tlearn: 0.0415938\ttotal: 2.88s\tremaining: 24.8s\n",
      "104:\tlearn: 0.0415058\ttotal: 2.9s\tremaining: 24.7s\n",
      "105:\tlearn: 0.0412891\ttotal: 2.93s\tremaining: 24.8s\n",
      "106:\tlearn: 0.0411221\ttotal: 2.97s\tremaining: 24.8s\n",
      "107:\tlearn: 0.0409611\ttotal: 3s\tremaining: 24.8s\n",
      "108:\tlearn: 0.0407626\ttotal: 3.03s\tremaining: 24.8s\n",
      "109:\tlearn: 0.0406370\ttotal: 3.07s\tremaining: 24.8s\n",
      "110:\tlearn: 0.0404213\ttotal: 3.1s\tremaining: 24.8s\n",
      "111:\tlearn: 0.0404192\ttotal: 3.11s\tremaining: 24.6s\n",
      "112:\tlearn: 0.0402792\ttotal: 3.14s\tremaining: 24.7s\n",
      "113:\tlearn: 0.0402710\ttotal: 3.16s\tremaining: 24.5s\n",
      "114:\tlearn: 0.0400821\ttotal: 3.19s\tremaining: 24.5s\n",
      "115:\tlearn: 0.0399915\ttotal: 3.22s\tremaining: 24.6s\n",
      "116:\tlearn: 0.0398790\ttotal: 3.25s\tremaining: 24.6s\n",
      "117:\tlearn: 0.0398439\ttotal: 3.28s\tremaining: 24.5s\n",
      "118:\tlearn: 0.0397229\ttotal: 3.32s\tremaining: 24.6s\n",
      "119:\tlearn: 0.0395359\ttotal: 3.35s\tremaining: 24.6s\n",
      "120:\tlearn: 0.0395352\ttotal: 3.36s\tremaining: 24.4s\n",
      "121:\tlearn: 0.0394617\ttotal: 3.39s\tremaining: 24.4s\n",
      "122:\tlearn: 0.0393353\ttotal: 3.43s\tremaining: 24.4s\n",
      "123:\tlearn: 0.0392084\ttotal: 3.46s\tremaining: 24.4s\n",
      "124:\tlearn: 0.0391494\ttotal: 3.5s\tremaining: 24.5s\n",
      "125:\tlearn: 0.0391200\ttotal: 3.53s\tremaining: 24.5s\n",
      "126:\tlearn: 0.0390254\ttotal: 3.56s\tremaining: 24.5s\n",
      "127:\tlearn: 0.0389031\ttotal: 3.6s\tremaining: 24.5s\n",
      "128:\tlearn: 0.0387539\ttotal: 3.63s\tremaining: 24.5s\n",
      "129:\tlearn: 0.0386235\ttotal: 3.66s\tremaining: 24.5s\n",
      "130:\tlearn: 0.0385814\ttotal: 3.69s\tremaining: 24.5s\n",
      "131:\tlearn: 0.0385332\ttotal: 3.73s\tremaining: 24.5s\n",
      "132:\tlearn: 0.0384399\ttotal: 3.76s\tremaining: 24.5s\n",
      "133:\tlearn: 0.0384385\ttotal: 3.78s\tremaining: 24.4s\n",
      "134:\tlearn: 0.0383205\ttotal: 3.81s\tremaining: 24.4s\n",
      "135:\tlearn: 0.0383198\ttotal: 3.83s\tremaining: 24.3s\n",
      "136:\tlearn: 0.0382666\ttotal: 3.86s\tremaining: 24.3s\n",
      "137:\tlearn: 0.0382192\ttotal: 3.9s\tremaining: 24.3s\n",
      "138:\tlearn: 0.0381213\ttotal: 3.93s\tremaining: 24.3s\n",
      "139:\tlearn: 0.0380983\ttotal: 3.96s\tremaining: 24.3s\n",
      "140:\tlearn: 0.0379927\ttotal: 3.99s\tremaining: 24.3s\n",
      "141:\tlearn: 0.0378938\ttotal: 4.02s\tremaining: 24.3s\n",
      "142:\tlearn: 0.0377984\ttotal: 4.05s\tremaining: 24.3s\n",
      "143:\tlearn: 0.0376838\ttotal: 4.09s\tremaining: 24.3s\n",
      "144:\tlearn: 0.0375544\ttotal: 4.12s\tremaining: 24.3s\n",
      "145:\tlearn: 0.0374994\ttotal: 4.15s\tremaining: 24.3s\n",
      "146:\tlearn: 0.0374929\ttotal: 4.17s\tremaining: 24.2s\n",
      "147:\tlearn: 0.0374619\ttotal: 4.2s\tremaining: 24.2s\n",
      "148:\tlearn: 0.0373933\ttotal: 4.23s\tremaining: 24.2s\n",
      "149:\tlearn: 0.0373577\ttotal: 4.26s\tremaining: 24.2s\n",
      "150:\tlearn: 0.0373081\ttotal: 4.29s\tremaining: 24.1s\n",
      "151:\tlearn: 0.0372279\ttotal: 4.33s\tremaining: 24.1s\n",
      "152:\tlearn: 0.0371973\ttotal: 4.36s\tremaining: 24.1s\n",
      "153:\tlearn: 0.0371451\ttotal: 4.39s\tremaining: 24.1s\n",
      "154:\tlearn: 0.0370972\ttotal: 4.42s\tremaining: 24.1s\n",
      "155:\tlearn: 0.0370601\ttotal: 4.45s\tremaining: 24.1s\n",
      "156:\tlearn: 0.0369454\ttotal: 4.48s\tremaining: 24.1s\n",
      "157:\tlearn: 0.0368898\ttotal: 4.52s\tremaining: 24.1s\n",
      "158:\tlearn: 0.0368876\ttotal: 4.53s\tremaining: 24s\n",
      "159:\tlearn: 0.0368682\ttotal: 4.57s\tremaining: 24s\n",
      "160:\tlearn: 0.0368059\ttotal: 4.6s\tremaining: 24s\n",
      "161:\tlearn: 0.0367614\ttotal: 4.63s\tremaining: 23.9s\n",
      "162:\tlearn: 0.0366759\ttotal: 4.66s\tremaining: 23.9s\n",
      "163:\tlearn: 0.0366421\ttotal: 4.69s\tremaining: 23.9s\n",
      "164:\tlearn: 0.0365187\ttotal: 4.72s\tremaining: 23.9s\n",
      "165:\tlearn: 0.0364532\ttotal: 4.76s\tremaining: 23.9s\n",
      "166:\tlearn: 0.0364203\ttotal: 4.79s\tremaining: 23.9s\n",
      "167:\tlearn: 0.0364195\ttotal: 4.8s\tremaining: 23.8s\n",
      "168:\tlearn: 0.0364161\ttotal: 4.83s\tremaining: 23.7s\n",
      "169:\tlearn: 0.0363162\ttotal: 4.86s\tremaining: 23.7s\n",
      "170:\tlearn: 0.0363040\ttotal: 4.88s\tremaining: 23.7s\n",
      "171:\tlearn: 0.0362363\ttotal: 4.91s\tremaining: 23.7s\n",
      "172:\tlearn: 0.0361968\ttotal: 4.95s\tremaining: 23.6s\n",
      "173:\tlearn: 0.0360989\ttotal: 4.98s\tremaining: 23.6s\n",
      "174:\tlearn: 0.0360801\ttotal: 5.01s\tremaining: 23.6s\n",
      "175:\tlearn: 0.0360151\ttotal: 5.04s\tremaining: 23.6s\n",
      "176:\tlearn: 0.0359474\ttotal: 5.08s\tremaining: 23.6s\n",
      "177:\tlearn: 0.0359355\ttotal: 5.1s\tremaining: 23.6s\n",
      "178:\tlearn: 0.0359167\ttotal: 5.13s\tremaining: 23.5s\n",
      "179:\tlearn: 0.0358477\ttotal: 5.17s\tremaining: 23.5s\n",
      "180:\tlearn: 0.0358428\ttotal: 5.18s\tremaining: 23.4s\n",
      "181:\tlearn: 0.0357923\ttotal: 5.21s\tremaining: 23.4s\n",
      "182:\tlearn: 0.0357920\ttotal: 5.22s\tremaining: 23.3s\n",
      "183:\tlearn: 0.0357257\ttotal: 5.25s\tremaining: 23.3s\n",
      "184:\tlearn: 0.0356415\ttotal: 5.29s\tremaining: 23.3s\n",
      "185:\tlearn: 0.0355758\ttotal: 5.32s\tremaining: 23.3s\n",
      "186:\tlearn: 0.0354451\ttotal: 5.35s\tremaining: 23.3s\n",
      "187:\tlearn: 0.0354254\ttotal: 5.38s\tremaining: 23.3s\n",
      "188:\tlearn: 0.0354204\ttotal: 5.4s\tremaining: 23.2s\n",
      "189:\tlearn: 0.0354055\ttotal: 5.43s\tremaining: 23.2s\n",
      "190:\tlearn: 0.0354051\ttotal: 5.45s\tremaining: 23.1s\n",
      "191:\tlearn: 0.0354043\ttotal: 5.46s\tremaining: 23s\n",
      "192:\tlearn: 0.0353971\ttotal: 5.48s\tremaining: 22.9s\n",
      "193:\tlearn: 0.0353942\ttotal: 5.5s\tremaining: 22.9s\n",
      "194:\tlearn: 0.0353141\ttotal: 5.54s\tremaining: 22.9s\n",
      "195:\tlearn: 0.0353105\ttotal: 5.56s\tremaining: 22.8s\n",
      "196:\tlearn: 0.0352994\ttotal: 5.59s\tremaining: 22.8s\n",
      "197:\tlearn: 0.0352348\ttotal: 5.62s\tremaining: 22.8s\n",
      "198:\tlearn: 0.0352109\ttotal: 5.66s\tremaining: 22.8s\n",
      "199:\tlearn: 0.0352076\ttotal: 5.67s\tremaining: 22.7s\n",
      "200:\tlearn: 0.0352064\ttotal: 5.68s\tremaining: 22.6s\n",
      "201:\tlearn: 0.0351351\ttotal: 5.71s\tremaining: 22.6s\n",
      "202:\tlearn: 0.0351082\ttotal: 5.75s\tremaining: 22.6s\n",
      "203:\tlearn: 0.0350547\ttotal: 5.78s\tremaining: 22.6s\n",
      "204:\tlearn: 0.0350354\ttotal: 5.82s\tremaining: 22.6s\n",
      "205:\tlearn: 0.0350161\ttotal: 5.85s\tremaining: 22.5s\n",
      "206:\tlearn: 0.0350115\ttotal: 5.87s\tremaining: 22.5s\n",
      "207:\tlearn: 0.0350089\ttotal: 5.9s\tremaining: 22.5s\n",
      "208:\tlearn: 0.0349925\ttotal: 5.94s\tremaining: 22.5s\n",
      "209:\tlearn: 0.0349919\ttotal: 5.96s\tremaining: 22.4s\n",
      "210:\tlearn: 0.0349916\ttotal: 5.96s\tremaining: 22.3s\n",
      "211:\tlearn: 0.0349260\ttotal: 6s\tremaining: 22.3s\n",
      "212:\tlearn: 0.0348872\ttotal: 6.03s\tremaining: 22.3s\n",
      "213:\tlearn: 0.0348454\ttotal: 6.06s\tremaining: 22.3s\n",
      "214:\tlearn: 0.0347770\ttotal: 6.09s\tremaining: 22.3s\n",
      "215:\tlearn: 0.0347581\ttotal: 6.13s\tremaining: 22.2s\n",
      "216:\tlearn: 0.0347333\ttotal: 6.16s\tremaining: 22.2s\n",
      "217:\tlearn: 0.0346857\ttotal: 6.2s\tremaining: 22.2s\n",
      "218:\tlearn: 0.0346702\ttotal: 6.23s\tremaining: 22.2s\n",
      "219:\tlearn: 0.0346288\ttotal: 6.26s\tremaining: 22.2s\n",
      "220:\tlearn: 0.0346285\ttotal: 6.27s\tremaining: 22.1s\n",
      "221:\tlearn: 0.0345867\ttotal: 6.3s\tremaining: 22.1s\n",
      "222:\tlearn: 0.0345865\ttotal: 6.31s\tremaining: 22s\n",
      "223:\tlearn: 0.0345835\ttotal: 6.34s\tremaining: 22s\n",
      "224:\tlearn: 0.0345483\ttotal: 6.37s\tremaining: 22s\n",
      "225:\tlearn: 0.0345308\ttotal: 6.41s\tremaining: 21.9s\n",
      "226:\tlearn: 0.0344827\ttotal: 6.44s\tremaining: 21.9s\n",
      "227:\tlearn: 0.0344571\ttotal: 6.47s\tremaining: 21.9s\n",
      "228:\tlearn: 0.0344532\ttotal: 6.51s\tremaining: 21.9s\n",
      "229:\tlearn: 0.0344530\ttotal: 6.51s\tremaining: 21.8s\n",
      "230:\tlearn: 0.0344026\ttotal: 6.55s\tremaining: 21.8s\n",
      "231:\tlearn: 0.0343352\ttotal: 6.58s\tremaining: 21.8s\n",
      "232:\tlearn: 0.0342581\ttotal: 6.61s\tremaining: 21.8s\n",
      "233:\tlearn: 0.0342101\ttotal: 6.65s\tremaining: 21.8s\n",
      "234:\tlearn: 0.0341781\ttotal: 6.68s\tremaining: 21.7s\n",
      "235:\tlearn: 0.0341687\ttotal: 6.7s\tremaining: 21.7s\n",
      "236:\tlearn: 0.0341626\ttotal: 6.73s\tremaining: 21.7s\n",
      "237:\tlearn: 0.0341420\ttotal: 6.76s\tremaining: 21.7s\n",
      "238:\tlearn: 0.0341190\ttotal: 6.8s\tremaining: 21.6s\n",
      "239:\tlearn: 0.0341146\ttotal: 6.81s\tremaining: 21.6s\n",
      "240:\tlearn: 0.0340593\ttotal: 6.84s\tremaining: 21.6s\n",
      "241:\tlearn: 0.0340414\ttotal: 6.88s\tremaining: 21.5s\n",
      "242:\tlearn: 0.0340223\ttotal: 6.91s\tremaining: 21.5s\n",
      "243:\tlearn: 0.0339654\ttotal: 6.94s\tremaining: 21.5s\n",
      "244:\tlearn: 0.0339152\ttotal: 6.97s\tremaining: 21.5s\n",
      "245:\tlearn: 0.0339150\ttotal: 6.98s\tremaining: 21.4s\n",
      "246:\tlearn: 0.0339085\ttotal: 7.01s\tremaining: 21.4s\n",
      "247:\tlearn: 0.0338979\ttotal: 7.09s\tremaining: 21.5s\n",
      "248:\tlearn: 0.0338418\ttotal: 7.15s\tremaining: 21.6s\n",
      "249:\tlearn: 0.0338115\ttotal: 7.27s\tremaining: 21.8s\n",
      "250:\tlearn: 0.0337857\ttotal: 7.31s\tremaining: 21.8s\n",
      "251:\tlearn: 0.0337854\ttotal: 7.33s\tremaining: 21.7s\n",
      "252:\tlearn: 0.0337492\ttotal: 7.4s\tremaining: 21.8s\n",
      "253:\tlearn: 0.0337481\ttotal: 7.42s\tremaining: 21.8s\n",
      "254:\tlearn: 0.0337269\ttotal: 7.46s\tremaining: 21.8s\n",
      "255:\tlearn: 0.0336482\ttotal: 7.5s\tremaining: 21.8s\n",
      "256:\tlearn: 0.0336334\ttotal: 7.53s\tremaining: 21.8s\n",
      "257:\tlearn: 0.0335328\ttotal: 7.56s\tremaining: 21.7s\n",
      "258:\tlearn: 0.0335325\ttotal: 7.57s\tremaining: 21.7s\n",
      "259:\tlearn: 0.0334755\ttotal: 7.6s\tremaining: 21.6s\n",
      "260:\tlearn: 0.0334753\ttotal: 7.61s\tremaining: 21.5s\n",
      "261:\tlearn: 0.0334243\ttotal: 7.64s\tremaining: 21.5s\n",
      "262:\tlearn: 0.0334203\ttotal: 7.65s\tremaining: 21.4s\n",
      "263:\tlearn: 0.0333959\ttotal: 7.68s\tremaining: 21.4s\n",
      "264:\tlearn: 0.0333308\ttotal: 7.72s\tremaining: 21.4s\n",
      "265:\tlearn: 0.0333305\ttotal: 7.73s\tremaining: 21.3s\n",
      "266:\tlearn: 0.0333153\ttotal: 7.76s\tremaining: 21.3s\n",
      "267:\tlearn: 0.0332970\ttotal: 7.79s\tremaining: 21.3s\n",
      "268:\tlearn: 0.0332967\ttotal: 7.8s\tremaining: 21.2s\n",
      "269:\tlearn: 0.0332809\ttotal: 7.83s\tremaining: 21.2s\n",
      "270:\tlearn: 0.0332331\ttotal: 7.86s\tremaining: 21.2s\n",
      "271:\tlearn: 0.0331899\ttotal: 7.9s\tremaining: 21.1s\n",
      "272:\tlearn: 0.0331366\ttotal: 7.93s\tremaining: 21.1s\n",
      "273:\tlearn: 0.0330898\ttotal: 7.97s\tremaining: 21.1s\n",
      "274:\tlearn: 0.0330713\ttotal: 8.02s\tremaining: 21.1s\n",
      "275:\tlearn: 0.0330281\ttotal: 8.05s\tremaining: 21.1s\n",
      "276:\tlearn: 0.0330279\ttotal: 8.06s\tremaining: 21s\n",
      "277:\tlearn: 0.0330012\ttotal: 8.09s\tremaining: 21s\n",
      "278:\tlearn: 0.0329989\ttotal: 8.11s\tremaining: 20.9s\n",
      "279:\tlearn: 0.0329987\ttotal: 8.11s\tremaining: 20.9s\n",
      "280:\tlearn: 0.0329561\ttotal: 8.15s\tremaining: 20.8s\n",
      "281:\tlearn: 0.0329556\ttotal: 8.16s\tremaining: 20.8s\n",
      "282:\tlearn: 0.0329283\ttotal: 8.19s\tremaining: 20.8s\n",
      "283:\tlearn: 0.0328799\ttotal: 8.23s\tremaining: 20.7s\n",
      "284:\tlearn: 0.0328728\ttotal: 8.25s\tremaining: 20.7s\n",
      "285:\tlearn: 0.0328726\ttotal: 8.26s\tremaining: 20.6s\n",
      "286:\tlearn: 0.0328555\ttotal: 8.29s\tremaining: 20.6s\n",
      "287:\tlearn: 0.0328404\ttotal: 8.32s\tremaining: 20.6s\n",
      "288:\tlearn: 0.0328011\ttotal: 8.36s\tremaining: 20.6s\n",
      "289:\tlearn: 0.0327886\ttotal: 8.39s\tremaining: 20.5s\n",
      "290:\tlearn: 0.0327376\ttotal: 8.42s\tremaining: 20.5s\n",
      "291:\tlearn: 0.0327369\ttotal: 8.44s\tremaining: 20.5s\n",
      "292:\tlearn: 0.0326878\ttotal: 8.48s\tremaining: 20.5s\n",
      "293:\tlearn: 0.0326784\ttotal: 8.51s\tremaining: 20.4s\n",
      "294:\tlearn: 0.0326684\ttotal: 8.54s\tremaining: 20.4s\n",
      "295:\tlearn: 0.0326087\ttotal: 8.58s\tremaining: 20.4s\n",
      "296:\tlearn: 0.0325472\ttotal: 8.61s\tremaining: 20.4s\n",
      "297:\tlearn: 0.0325293\ttotal: 8.65s\tremaining: 20.4s\n",
      "298:\tlearn: 0.0325197\ttotal: 8.68s\tremaining: 20.4s\n",
      "299:\tlearn: 0.0324639\ttotal: 8.71s\tremaining: 20.3s\n",
      "300:\tlearn: 0.0324214\ttotal: 8.74s\tremaining: 20.3s\n",
      "301:\tlearn: 0.0324212\ttotal: 8.75s\tremaining: 20.2s\n",
      "302:\tlearn: 0.0324186\ttotal: 8.79s\tremaining: 20.2s\n",
      "303:\tlearn: 0.0323980\ttotal: 8.82s\tremaining: 20.2s\n",
      "304:\tlearn: 0.0323978\ttotal: 8.83s\tremaining: 20.1s\n",
      "305:\tlearn: 0.0323827\ttotal: 8.86s\tremaining: 20.1s\n",
      "306:\tlearn: 0.0323825\ttotal: 8.87s\tremaining: 20s\n",
      "307:\tlearn: 0.0323682\ttotal: 8.91s\tremaining: 20s\n",
      "308:\tlearn: 0.0323460\ttotal: 8.94s\tremaining: 20s\n",
      "309:\tlearn: 0.0323165\ttotal: 8.98s\tremaining: 20s\n",
      "310:\tlearn: 0.0322787\ttotal: 9.01s\tremaining: 20s\n",
      "311:\tlearn: 0.0322708\ttotal: 9.03s\tremaining: 19.9s\n",
      "312:\tlearn: 0.0322621\ttotal: 9.06s\tremaining: 19.9s\n",
      "313:\tlearn: 0.0322315\ttotal: 9.1s\tremaining: 19.9s\n",
      "314:\tlearn: 0.0322293\ttotal: 9.12s\tremaining: 19.8s\n",
      "315:\tlearn: 0.0321828\ttotal: 9.15s\tremaining: 19.8s\n",
      "316:\tlearn: 0.0321827\ttotal: 9.16s\tremaining: 19.7s\n",
      "317:\tlearn: 0.0321804\ttotal: 9.19s\tremaining: 19.7s\n",
      "318:\tlearn: 0.0321458\ttotal: 9.22s\tremaining: 19.7s\n",
      "319:\tlearn: 0.0321227\ttotal: 9.26s\tremaining: 19.7s\n",
      "320:\tlearn: 0.0320801\ttotal: 9.29s\tremaining: 19.7s\n",
      "321:\tlearn: 0.0320037\ttotal: 9.33s\tremaining: 19.6s\n",
      "322:\tlearn: 0.0320028\ttotal: 9.35s\tremaining: 19.6s\n",
      "323:\tlearn: 0.0319274\ttotal: 9.4s\tremaining: 19.6s\n",
      "324:\tlearn: 0.0319126\ttotal: 9.44s\tremaining: 19.6s\n",
      "325:\tlearn: 0.0318171\ttotal: 9.48s\tremaining: 19.6s\n",
      "326:\tlearn: 0.0317573\ttotal: 9.51s\tremaining: 19.6s\n",
      "327:\tlearn: 0.0317386\ttotal: 9.54s\tremaining: 19.5s\n",
      "328:\tlearn: 0.0317295\ttotal: 9.57s\tremaining: 19.5s\n",
      "329:\tlearn: 0.0317231\ttotal: 9.61s\tremaining: 19.5s\n",
      "330:\tlearn: 0.0316817\ttotal: 9.64s\tremaining: 19.5s\n",
      "331:\tlearn: 0.0316413\ttotal: 9.68s\tremaining: 19.5s\n",
      "332:\tlearn: 0.0316411\ttotal: 9.69s\tremaining: 19.4s\n",
      "333:\tlearn: 0.0316143\ttotal: 9.72s\tremaining: 19.4s\n",
      "334:\tlearn: 0.0315873\ttotal: 9.76s\tremaining: 19.4s\n",
      "335:\tlearn: 0.0315452\ttotal: 9.79s\tremaining: 19.4s\n",
      "336:\tlearn: 0.0315387\ttotal: 9.83s\tremaining: 19.3s\n",
      "337:\tlearn: 0.0315249\ttotal: 9.86s\tremaining: 19.3s\n",
      "338:\tlearn: 0.0314817\ttotal: 9.9s\tremaining: 19.3s\n",
      "339:\tlearn: 0.0314768\ttotal: 9.91s\tremaining: 19.2s\n",
      "340:\tlearn: 0.0314728\ttotal: 9.94s\tremaining: 19.2s\n",
      "341:\tlearn: 0.0314518\ttotal: 9.98s\tremaining: 19.2s\n",
      "342:\tlearn: 0.0314415\ttotal: 10s\tremaining: 19.2s\n",
      "343:\tlearn: 0.0313880\ttotal: 10s\tremaining: 19.2s\n",
      "344:\tlearn: 0.0313743\ttotal: 10.1s\tremaining: 19.1s\n",
      "345:\tlearn: 0.0313650\ttotal: 10.1s\tremaining: 19.1s\n",
      "346:\tlearn: 0.0313586\ttotal: 10.2s\tremaining: 19.1s\n",
      "347:\tlearn: 0.0313348\ttotal: 10.2s\tremaining: 19.1s\n",
      "348:\tlearn: 0.0313116\ttotal: 10.2s\tremaining: 19.1s\n",
      "349:\tlearn: 0.0312776\ttotal: 10.3s\tremaining: 19s\n",
      "350:\tlearn: 0.0312467\ttotal: 10.3s\tremaining: 19s\n",
      "351:\tlearn: 0.0312333\ttotal: 10.3s\tremaining: 19s\n",
      "352:\tlearn: 0.0312026\ttotal: 10.4s\tremaining: 19s\n",
      "353:\tlearn: 0.0311868\ttotal: 10.4s\tremaining: 19s\n",
      "354:\tlearn: 0.0311850\ttotal: 10.4s\tremaining: 19s\n",
      "355:\tlearn: 0.0311691\ttotal: 10.5s\tremaining: 18.9s\n",
      "356:\tlearn: 0.0311643\ttotal: 10.5s\tremaining: 18.9s\n",
      "357:\tlearn: 0.0311567\ttotal: 10.5s\tremaining: 18.9s\n",
      "358:\tlearn: 0.0311399\ttotal: 10.6s\tremaining: 18.8s\n",
      "359:\tlearn: 0.0311082\ttotal: 10.6s\tremaining: 18.8s\n",
      "360:\tlearn: 0.0311004\ttotal: 10.6s\tremaining: 18.8s\n",
      "361:\tlearn: 0.0310586\ttotal: 10.7s\tremaining: 18.8s\n",
      "362:\tlearn: 0.0310448\ttotal: 10.7s\tremaining: 18.8s\n",
      "363:\tlearn: 0.0310357\ttotal: 10.7s\tremaining: 18.8s\n",
      "364:\tlearn: 0.0309750\ttotal: 10.8s\tremaining: 18.7s\n",
      "365:\tlearn: 0.0309713\ttotal: 10.8s\tremaining: 18.7s\n",
      "366:\tlearn: 0.0309635\ttotal: 10.8s\tremaining: 18.7s\n",
      "367:\tlearn: 0.0309311\ttotal: 10.8s\tremaining: 18.6s\n",
      "368:\tlearn: 0.0309168\ttotal: 10.9s\tremaining: 18.6s\n",
      "369:\tlearn: 0.0309034\ttotal: 10.9s\tremaining: 18.6s\n",
      "370:\tlearn: 0.0308942\ttotal: 10.9s\tremaining: 18.6s\n",
      "371:\tlearn: 0.0308851\ttotal: 11s\tremaining: 18.5s\n",
      "372:\tlearn: 0.0308762\ttotal: 11s\tremaining: 18.5s\n",
      "373:\tlearn: 0.0308720\ttotal: 11s\tremaining: 18.4s\n",
      "374:\tlearn: 0.0308352\ttotal: 11.1s\tremaining: 18.4s\n",
      "375:\tlearn: 0.0308256\ttotal: 11.1s\tremaining: 18.4s\n",
      "376:\tlearn: 0.0307936\ttotal: 11.1s\tremaining: 18.4s\n",
      "377:\tlearn: 0.0307489\ttotal: 11.2s\tremaining: 18.4s\n",
      "378:\tlearn: 0.0307203\ttotal: 11.2s\tremaining: 18.3s\n",
      "379:\tlearn: 0.0306758\ttotal: 11.2s\tremaining: 18.3s\n",
      "380:\tlearn: 0.0306540\ttotal: 11.3s\tremaining: 18.3s\n",
      "381:\tlearn: 0.0305946\ttotal: 11.3s\tremaining: 18.3s\n",
      "382:\tlearn: 0.0305721\ttotal: 11.3s\tremaining: 18.2s\n",
      "383:\tlearn: 0.0305535\ttotal: 11.3s\tremaining: 18.2s\n",
      "384:\tlearn: 0.0305485\ttotal: 11.4s\tremaining: 18.2s\n",
      "385:\tlearn: 0.0305236\ttotal: 11.4s\tremaining: 18.1s\n",
      "386:\tlearn: 0.0305145\ttotal: 11.5s\tremaining: 18.1s\n",
      "387:\tlearn: 0.0304800\ttotal: 11.5s\tremaining: 18.2s\n",
      "388:\tlearn: 0.0304428\ttotal: 11.6s\tremaining: 18.1s\n",
      "389:\tlearn: 0.0304020\ttotal: 11.6s\tremaining: 18.1s\n",
      "390:\tlearn: 0.0303839\ttotal: 11.6s\tremaining: 18.1s\n",
      "391:\tlearn: 0.0303272\ttotal: 11.6s\tremaining: 18.1s\n",
      "392:\tlearn: 0.0303056\ttotal: 11.7s\tremaining: 18s\n",
      "393:\tlearn: 0.0302794\ttotal: 11.7s\tremaining: 18s\n",
      "394:\tlearn: 0.0302746\ttotal: 11.7s\tremaining: 18s\n",
      "395:\tlearn: 0.0302659\ttotal: 11.8s\tremaining: 18s\n",
      "396:\tlearn: 0.0302367\ttotal: 11.8s\tremaining: 18s\n",
      "397:\tlearn: 0.0302272\ttotal: 11.9s\tremaining: 17.9s\n",
      "398:\tlearn: 0.0302146\ttotal: 11.9s\tremaining: 17.9s\n",
      "399:\tlearn: 0.0302077\ttotal: 11.9s\tremaining: 17.9s\n",
      "400:\tlearn: 0.0301597\ttotal: 12s\tremaining: 17.9s\n",
      "401:\tlearn: 0.0301145\ttotal: 12s\tremaining: 17.8s\n",
      "402:\tlearn: 0.0301066\ttotal: 12s\tremaining: 17.8s\n",
      "403:\tlearn: 0.0300764\ttotal: 12s\tremaining: 17.8s\n",
      "404:\tlearn: 0.0300431\ttotal: 12.1s\tremaining: 17.7s\n",
      "405:\tlearn: 0.0300316\ttotal: 12.1s\tremaining: 17.7s\n",
      "406:\tlearn: 0.0299923\ttotal: 12.1s\tremaining: 17.7s\n",
      "407:\tlearn: 0.0299370\ttotal: 12.2s\tremaining: 17.7s\n",
      "408:\tlearn: 0.0299214\ttotal: 12.2s\tremaining: 17.6s\n",
      "409:\tlearn: 0.0298871\ttotal: 12.2s\tremaining: 17.6s\n",
      "410:\tlearn: 0.0298769\ttotal: 12.3s\tremaining: 17.6s\n",
      "411:\tlearn: 0.0298424\ttotal: 12.3s\tremaining: 17.6s\n",
      "412:\tlearn: 0.0298160\ttotal: 12.3s\tremaining: 17.5s\n",
      "413:\tlearn: 0.0297786\ttotal: 12.4s\tremaining: 17.5s\n",
      "414:\tlearn: 0.0297660\ttotal: 12.4s\tremaining: 17.5s\n",
      "415:\tlearn: 0.0297586\ttotal: 12.4s\tremaining: 17.4s\n",
      "416:\tlearn: 0.0297471\ttotal: 12.5s\tremaining: 17.4s\n",
      "417:\tlearn: 0.0297338\ttotal: 12.5s\tremaining: 17.4s\n",
      "418:\tlearn: 0.0297177\ttotal: 12.5s\tremaining: 17.4s\n",
      "419:\tlearn: 0.0296998\ttotal: 12.6s\tremaining: 17.3s\n",
      "420:\tlearn: 0.0296908\ttotal: 12.6s\tremaining: 17.3s\n",
      "421:\tlearn: 0.0296642\ttotal: 12.6s\tremaining: 17.3s\n",
      "422:\tlearn: 0.0296531\ttotal: 12.7s\tremaining: 17.3s\n",
      "423:\tlearn: 0.0295887\ttotal: 12.7s\tremaining: 17.2s\n",
      "424:\tlearn: 0.0295776\ttotal: 12.7s\tremaining: 17.2s\n",
      "425:\tlearn: 0.0295658\ttotal: 12.8s\tremaining: 17.2s\n",
      "426:\tlearn: 0.0295592\ttotal: 12.8s\tremaining: 17.1s\n",
      "427:\tlearn: 0.0295575\ttotal: 12.8s\tremaining: 17.1s\n",
      "428:\tlearn: 0.0295491\ttotal: 12.8s\tremaining: 17.1s\n",
      "429:\tlearn: 0.0295422\ttotal: 12.9s\tremaining: 17.1s\n",
      "430:\tlearn: 0.0295343\ttotal: 12.9s\tremaining: 17s\n",
      "431:\tlearn: 0.0295238\ttotal: 12.9s\tremaining: 17s\n",
      "432:\tlearn: 0.0295025\ttotal: 13s\tremaining: 17s\n",
      "433:\tlearn: 0.0294919\ttotal: 13s\tremaining: 17s\n",
      "434:\tlearn: 0.0294746\ttotal: 13s\tremaining: 16.9s\n",
      "435:\tlearn: 0.0294461\ttotal: 13.1s\tremaining: 16.9s\n",
      "436:\tlearn: 0.0294046\ttotal: 13.1s\tremaining: 16.9s\n",
      "437:\tlearn: 0.0293830\ttotal: 13.1s\tremaining: 16.9s\n",
      "438:\tlearn: 0.0293700\ttotal: 13.2s\tremaining: 16.8s\n",
      "439:\tlearn: 0.0293597\ttotal: 13.2s\tremaining: 16.8s\n",
      "440:\tlearn: 0.0293052\ttotal: 13.2s\tremaining: 16.8s\n",
      "441:\tlearn: 0.0292442\ttotal: 13.3s\tremaining: 16.7s\n",
      "442:\tlearn: 0.0292299\ttotal: 13.3s\tremaining: 16.7s\n",
      "443:\tlearn: 0.0292166\ttotal: 13.3s\tremaining: 16.7s\n",
      "444:\tlearn: 0.0292136\ttotal: 13.4s\tremaining: 16.7s\n",
      "445:\tlearn: 0.0292047\ttotal: 13.4s\tremaining: 16.6s\n",
      "446:\tlearn: 0.0291707\ttotal: 13.4s\tremaining: 16.6s\n",
      "447:\tlearn: 0.0291650\ttotal: 13.4s\tremaining: 16.6s\n",
      "448:\tlearn: 0.0291582\ttotal: 13.5s\tremaining: 16.5s\n",
      "449:\tlearn: 0.0291076\ttotal: 13.5s\tremaining: 16.5s\n",
      "450:\tlearn: 0.0291011\ttotal: 13.5s\tremaining: 16.5s\n",
      "451:\tlearn: 0.0290917\ttotal: 13.6s\tremaining: 16.5s\n",
      "452:\tlearn: 0.0290400\ttotal: 13.6s\tremaining: 16.4s\n",
      "453:\tlearn: 0.0290317\ttotal: 13.6s\tremaining: 16.4s\n",
      "454:\tlearn: 0.0290044\ttotal: 13.7s\tremaining: 16.4s\n",
      "455:\tlearn: 0.0289848\ttotal: 13.7s\tremaining: 16.4s\n",
      "456:\tlearn: 0.0289798\ttotal: 13.7s\tremaining: 16.3s\n",
      "457:\tlearn: 0.0289746\ttotal: 13.8s\tremaining: 16.3s\n",
      "458:\tlearn: 0.0289613\ttotal: 13.8s\tremaining: 16.3s\n",
      "459:\tlearn: 0.0289542\ttotal: 13.8s\tremaining: 16.2s\n",
      "460:\tlearn: 0.0289410\ttotal: 13.9s\tremaining: 16.2s\n",
      "461:\tlearn: 0.0289347\ttotal: 13.9s\tremaining: 16.2s\n",
      "462:\tlearn: 0.0289093\ttotal: 13.9s\tremaining: 16.2s\n",
      "463:\tlearn: 0.0288636\ttotal: 14s\tremaining: 16.1s\n",
      "464:\tlearn: 0.0288512\ttotal: 14s\tremaining: 16.1s\n",
      "465:\tlearn: 0.0288466\ttotal: 14s\tremaining: 16.1s\n",
      "466:\tlearn: 0.0288422\ttotal: 14s\tremaining: 16s\n",
      "467:\tlearn: 0.0288264\ttotal: 14.1s\tremaining: 16s\n",
      "468:\tlearn: 0.0288178\ttotal: 14.1s\tremaining: 16s\n",
      "469:\tlearn: 0.0288089\ttotal: 14.1s\tremaining: 15.9s\n",
      "470:\tlearn: 0.0288002\ttotal: 14.2s\tremaining: 15.9s\n",
      "471:\tlearn: 0.0287924\ttotal: 14.2s\tremaining: 15.9s\n",
      "472:\tlearn: 0.0287771\ttotal: 14.2s\tremaining: 15.9s\n",
      "473:\tlearn: 0.0287412\ttotal: 14.3s\tremaining: 15.8s\n",
      "474:\tlearn: 0.0287324\ttotal: 14.3s\tremaining: 15.8s\n",
      "475:\tlearn: 0.0287261\ttotal: 14.3s\tremaining: 15.8s\n",
      "476:\tlearn: 0.0287182\ttotal: 14.4s\tremaining: 15.7s\n",
      "477:\tlearn: 0.0287081\ttotal: 14.4s\tremaining: 15.7s\n",
      "478:\tlearn: 0.0286772\ttotal: 14.4s\tremaining: 15.7s\n",
      "479:\tlearn: 0.0286592\ttotal: 14.4s\tremaining: 15.6s\n",
      "480:\tlearn: 0.0286456\ttotal: 14.5s\tremaining: 15.6s\n",
      "481:\tlearn: 0.0286304\ttotal: 14.5s\tremaining: 15.6s\n",
      "482:\tlearn: 0.0286111\ttotal: 14.5s\tremaining: 15.6s\n",
      "483:\tlearn: 0.0285980\ttotal: 14.6s\tremaining: 15.5s\n",
      "484:\tlearn: 0.0285754\ttotal: 14.6s\tremaining: 15.5s\n",
      "485:\tlearn: 0.0285691\ttotal: 14.6s\tremaining: 15.5s\n",
      "486:\tlearn: 0.0285480\ttotal: 14.7s\tremaining: 15.5s\n",
      "487:\tlearn: 0.0285385\ttotal: 14.8s\tremaining: 15.5s\n",
      "488:\tlearn: 0.0285165\ttotal: 14.9s\tremaining: 15.5s\n",
      "489:\tlearn: 0.0284982\ttotal: 14.9s\tremaining: 15.5s\n",
      "490:\tlearn: 0.0284795\ttotal: 15s\tremaining: 15.5s\n",
      "491:\tlearn: 0.0284720\ttotal: 15s\tremaining: 15.5s\n",
      "492:\tlearn: 0.0284663\ttotal: 15.1s\tremaining: 15.5s\n",
      "493:\tlearn: 0.0284520\ttotal: 15.1s\tremaining: 15.5s\n",
      "494:\tlearn: 0.0284436\ttotal: 15.2s\tremaining: 15.5s\n",
      "495:\tlearn: 0.0284417\ttotal: 15.2s\tremaining: 15.4s\n",
      "496:\tlearn: 0.0284264\ttotal: 15.2s\tremaining: 15.4s\n",
      "497:\tlearn: 0.0283782\ttotal: 15.3s\tremaining: 15.4s\n",
      "498:\tlearn: 0.0283482\ttotal: 15.3s\tremaining: 15.3s\n",
      "499:\tlearn: 0.0283357\ttotal: 15.3s\tremaining: 15.3s\n",
      "500:\tlearn: 0.0283219\ttotal: 15.3s\tremaining: 15.3s\n",
      "501:\tlearn: 0.0283181\ttotal: 15.4s\tremaining: 15.3s\n",
      "502:\tlearn: 0.0282882\ttotal: 15.4s\tremaining: 15.2s\n",
      "503:\tlearn: 0.0282594\ttotal: 15.5s\tremaining: 15.2s\n",
      "504:\tlearn: 0.0282282\ttotal: 15.5s\tremaining: 15.2s\n",
      "505:\tlearn: 0.0282182\ttotal: 15.5s\tremaining: 15.2s\n",
      "506:\tlearn: 0.0282062\ttotal: 15.6s\tremaining: 15.1s\n",
      "507:\tlearn: 0.0281954\ttotal: 15.6s\tremaining: 15.1s\n",
      "508:\tlearn: 0.0281903\ttotal: 15.6s\tremaining: 15.1s\n",
      "509:\tlearn: 0.0281787\ttotal: 15.7s\tremaining: 15s\n",
      "510:\tlearn: 0.0281734\ttotal: 15.7s\tremaining: 15s\n",
      "511:\tlearn: 0.0281605\ttotal: 15.7s\tremaining: 15s\n",
      "512:\tlearn: 0.0281481\ttotal: 15.8s\tremaining: 15s\n",
      "513:\tlearn: 0.0281350\ttotal: 15.8s\tremaining: 14.9s\n",
      "514:\tlearn: 0.0281204\ttotal: 15.8s\tremaining: 14.9s\n",
      "515:\tlearn: 0.0281112\ttotal: 15.9s\tremaining: 14.9s\n",
      "516:\tlearn: 0.0280985\ttotal: 15.9s\tremaining: 14.9s\n",
      "517:\tlearn: 0.0280862\ttotal: 15.9s\tremaining: 14.8s\n",
      "518:\tlearn: 0.0280707\ttotal: 16s\tremaining: 14.8s\n",
      "519:\tlearn: 0.0280382\ttotal: 16s\tremaining: 14.8s\n",
      "520:\tlearn: 0.0280315\ttotal: 16s\tremaining: 14.8s\n",
      "521:\tlearn: 0.0279972\ttotal: 16.1s\tremaining: 14.7s\n",
      "522:\tlearn: 0.0279866\ttotal: 16.1s\tremaining: 14.7s\n",
      "523:\tlearn: 0.0279790\ttotal: 16.2s\tremaining: 14.7s\n",
      "524:\tlearn: 0.0279495\ttotal: 16.2s\tremaining: 14.6s\n",
      "525:\tlearn: 0.0279453\ttotal: 16.2s\tremaining: 14.6s\n",
      "526:\tlearn: 0.0279286\ttotal: 16.3s\tremaining: 14.6s\n",
      "527:\tlearn: 0.0279267\ttotal: 16.3s\tremaining: 14.6s\n",
      "528:\tlearn: 0.0279244\ttotal: 16.3s\tremaining: 14.5s\n",
      "529:\tlearn: 0.0279158\ttotal: 16.4s\tremaining: 14.5s\n",
      "530:\tlearn: 0.0279021\ttotal: 16.4s\tremaining: 14.5s\n",
      "531:\tlearn: 0.0278981\ttotal: 16.4s\tremaining: 14.4s\n",
      "532:\tlearn: 0.0278896\ttotal: 16.5s\tremaining: 14.4s\n",
      "533:\tlearn: 0.0278604\ttotal: 16.5s\tremaining: 14.4s\n",
      "534:\tlearn: 0.0278531\ttotal: 16.5s\tremaining: 14.4s\n",
      "535:\tlearn: 0.0278201\ttotal: 16.6s\tremaining: 14.3s\n",
      "536:\tlearn: 0.0278114\ttotal: 16.6s\tremaining: 14.3s\n",
      "537:\tlearn: 0.0277823\ttotal: 16.6s\tremaining: 14.3s\n",
      "538:\tlearn: 0.0277678\ttotal: 16.6s\tremaining: 14.2s\n",
      "539:\tlearn: 0.0277401\ttotal: 16.7s\tremaining: 14.2s\n",
      "540:\tlearn: 0.0277197\ttotal: 16.7s\tremaining: 14.2s\n",
      "541:\tlearn: 0.0277099\ttotal: 16.7s\tremaining: 14.2s\n",
      "542:\tlearn: 0.0276901\ttotal: 16.8s\tremaining: 14.1s\n",
      "543:\tlearn: 0.0276707\ttotal: 16.8s\tremaining: 14.1s\n",
      "544:\tlearn: 0.0276683\ttotal: 16.8s\tremaining: 14.1s\n",
      "545:\tlearn: 0.0276542\ttotal: 16.9s\tremaining: 14s\n",
      "546:\tlearn: 0.0276442\ttotal: 16.9s\tremaining: 14s\n",
      "547:\tlearn: 0.0276410\ttotal: 16.9s\tremaining: 14s\n",
      "548:\tlearn: 0.0276093\ttotal: 17s\tremaining: 13.9s\n",
      "549:\tlearn: 0.0275810\ttotal: 17s\tremaining: 13.9s\n",
      "550:\tlearn: 0.0275660\ttotal: 17s\tremaining: 13.9s\n",
      "551:\tlearn: 0.0275156\ttotal: 17.1s\tremaining: 13.9s\n",
      "552:\tlearn: 0.0274848\ttotal: 17.1s\tremaining: 13.8s\n",
      "553:\tlearn: 0.0274653\ttotal: 17.1s\tremaining: 13.8s\n",
      "554:\tlearn: 0.0274521\ttotal: 17.2s\tremaining: 13.8s\n",
      "555:\tlearn: 0.0274265\ttotal: 17.2s\tremaining: 13.7s\n",
      "556:\tlearn: 0.0274155\ttotal: 17.2s\tremaining: 13.7s\n",
      "557:\tlearn: 0.0274118\ttotal: 17.3s\tremaining: 13.7s\n",
      "558:\tlearn: 0.0273931\ttotal: 17.3s\tremaining: 13.7s\n",
      "559:\tlearn: 0.0273794\ttotal: 17.3s\tremaining: 13.6s\n",
      "560:\tlearn: 0.0273731\ttotal: 17.4s\tremaining: 13.6s\n",
      "561:\tlearn: 0.0273640\ttotal: 17.4s\tremaining: 13.6s\n",
      "562:\tlearn: 0.0273577\ttotal: 17.4s\tremaining: 13.5s\n",
      "563:\tlearn: 0.0273487\ttotal: 17.5s\tremaining: 13.5s\n",
      "564:\tlearn: 0.0273426\ttotal: 17.5s\tremaining: 13.5s\n",
      "565:\tlearn: 0.0273399\ttotal: 17.5s\tremaining: 13.5s\n",
      "566:\tlearn: 0.0273311\ttotal: 17.6s\tremaining: 13.4s\n",
      "567:\tlearn: 0.0273286\ttotal: 17.6s\tremaining: 13.4s\n",
      "568:\tlearn: 0.0272999\ttotal: 17.6s\tremaining: 13.4s\n",
      "569:\tlearn: 0.0272619\ttotal: 17.7s\tremaining: 13.3s\n",
      "570:\tlearn: 0.0272312\ttotal: 17.7s\tremaining: 13.3s\n",
      "571:\tlearn: 0.0272226\ttotal: 17.7s\tremaining: 13.3s\n",
      "572:\tlearn: 0.0272167\ttotal: 17.8s\tremaining: 13.2s\n",
      "573:\tlearn: 0.0272082\ttotal: 17.8s\tremaining: 13.2s\n",
      "574:\tlearn: 0.0271583\ttotal: 17.8s\tremaining: 13.2s\n",
      "575:\tlearn: 0.0271498\ttotal: 17.9s\tremaining: 13.2s\n",
      "576:\tlearn: 0.0271410\ttotal: 17.9s\tremaining: 13.1s\n",
      "577:\tlearn: 0.0271348\ttotal: 17.9s\tremaining: 13.1s\n",
      "578:\tlearn: 0.0270895\ttotal: 18s\tremaining: 13.1s\n",
      "579:\tlearn: 0.0270449\ttotal: 18s\tremaining: 13.1s\n",
      "580:\tlearn: 0.0270383\ttotal: 18.1s\tremaining: 13s\n",
      "581:\tlearn: 0.0270109\ttotal: 18.1s\tremaining: 13s\n",
      "582:\tlearn: 0.0269696\ttotal: 18.1s\tremaining: 13s\n",
      "583:\tlearn: 0.0269660\ttotal: 18.2s\tremaining: 12.9s\n",
      "584:\tlearn: 0.0269595\ttotal: 18.2s\tremaining: 12.9s\n",
      "585:\tlearn: 0.0269417\ttotal: 18.2s\tremaining: 12.9s\n",
      "586:\tlearn: 0.0269292\ttotal: 18.3s\tremaining: 12.9s\n",
      "587:\tlearn: 0.0269159\ttotal: 18.3s\tremaining: 12.8s\n",
      "588:\tlearn: 0.0268751\ttotal: 18.3s\tremaining: 12.8s\n",
      "589:\tlearn: 0.0268678\ttotal: 18.4s\tremaining: 12.8s\n",
      "590:\tlearn: 0.0268622\ttotal: 18.4s\tremaining: 12.7s\n",
      "591:\tlearn: 0.0268504\ttotal: 18.4s\tremaining: 12.7s\n",
      "592:\tlearn: 0.0268460\ttotal: 18.5s\tremaining: 12.7s\n",
      "593:\tlearn: 0.0268370\ttotal: 18.5s\tremaining: 12.6s\n",
      "594:\tlearn: 0.0268336\ttotal: 18.5s\tremaining: 12.6s\n",
      "595:\tlearn: 0.0268290\ttotal: 18.6s\tremaining: 12.6s\n",
      "596:\tlearn: 0.0267901\ttotal: 18.6s\tremaining: 12.6s\n",
      "597:\tlearn: 0.0267637\ttotal: 18.6s\tremaining: 12.5s\n",
      "598:\tlearn: 0.0267624\ttotal: 18.7s\tremaining: 12.5s\n",
      "599:\tlearn: 0.0267569\ttotal: 18.7s\tremaining: 12.5s\n",
      "600:\tlearn: 0.0267482\ttotal: 18.7s\tremaining: 12.4s\n",
      "601:\tlearn: 0.0267426\ttotal: 18.8s\tremaining: 12.4s\n",
      "602:\tlearn: 0.0267394\ttotal: 18.8s\tremaining: 12.4s\n",
      "603:\tlearn: 0.0267348\ttotal: 18.8s\tremaining: 12.3s\n",
      "604:\tlearn: 0.0267184\ttotal: 18.9s\tremaining: 12.3s\n",
      "605:\tlearn: 0.0266987\ttotal: 18.9s\tremaining: 12.3s\n",
      "606:\tlearn: 0.0266929\ttotal: 18.9s\tremaining: 12.3s\n",
      "607:\tlearn: 0.0266889\ttotal: 19s\tremaining: 12.2s\n",
      "608:\tlearn: 0.0266863\ttotal: 19s\tremaining: 12.2s\n",
      "609:\tlearn: 0.0266627\ttotal: 19s\tremaining: 12.2s\n",
      "610:\tlearn: 0.0266575\ttotal: 19.1s\tremaining: 12.1s\n",
      "611:\tlearn: 0.0266541\ttotal: 19.1s\tremaining: 12.1s\n",
      "612:\tlearn: 0.0266284\ttotal: 19.1s\tremaining: 12.1s\n",
      "613:\tlearn: 0.0266215\ttotal: 19.2s\tremaining: 12s\n",
      "614:\tlearn: 0.0265957\ttotal: 19.2s\tremaining: 12s\n",
      "615:\tlearn: 0.0265878\ttotal: 19.2s\tremaining: 12s\n",
      "616:\tlearn: 0.0265449\ttotal: 19.3s\tremaining: 12s\n",
      "617:\tlearn: 0.0265076\ttotal: 19.3s\tremaining: 11.9s\n",
      "618:\tlearn: 0.0265055\ttotal: 19.3s\tremaining: 11.9s\n",
      "619:\tlearn: 0.0264497\ttotal: 19.4s\tremaining: 11.9s\n",
      "620:\tlearn: 0.0264476\ttotal: 19.4s\tremaining: 11.8s\n",
      "621:\tlearn: 0.0264256\ttotal: 19.4s\tremaining: 11.8s\n",
      "622:\tlearn: 0.0264171\ttotal: 19.5s\tremaining: 11.8s\n",
      "623:\tlearn: 0.0264143\ttotal: 19.5s\tremaining: 11.8s\n",
      "624:\tlearn: 0.0264091\ttotal: 19.5s\tremaining: 11.7s\n",
      "625:\tlearn: 0.0264078\ttotal: 19.6s\tremaining: 11.7s\n",
      "626:\tlearn: 0.0264063\ttotal: 19.6s\tremaining: 11.7s\n",
      "627:\tlearn: 0.0264025\ttotal: 19.6s\tremaining: 11.6s\n",
      "628:\tlearn: 0.0263916\ttotal: 19.7s\tremaining: 11.6s\n",
      "629:\tlearn: 0.0263865\ttotal: 19.7s\tremaining: 11.6s\n",
      "630:\tlearn: 0.0263752\ttotal: 19.7s\tremaining: 11.5s\n",
      "631:\tlearn: 0.0263487\ttotal: 19.8s\tremaining: 11.5s\n",
      "632:\tlearn: 0.0263326\ttotal: 19.8s\tremaining: 11.5s\n",
      "633:\tlearn: 0.0262950\ttotal: 19.8s\tremaining: 11.4s\n",
      "634:\tlearn: 0.0262415\ttotal: 19.9s\tremaining: 11.4s\n",
      "635:\tlearn: 0.0262369\ttotal: 19.9s\tremaining: 11.4s\n",
      "636:\tlearn: 0.0262332\ttotal: 19.9s\tremaining: 11.3s\n",
      "637:\tlearn: 0.0261913\ttotal: 20s\tremaining: 11.3s\n",
      "638:\tlearn: 0.0261877\ttotal: 20s\tremaining: 11.3s\n",
      "639:\tlearn: 0.0261472\ttotal: 20s\tremaining: 11.3s\n",
      "640:\tlearn: 0.0261194\ttotal: 20s\tremaining: 11.2s\n",
      "641:\tlearn: 0.0260926\ttotal: 20.1s\tremaining: 11.2s\n",
      "642:\tlearn: 0.0260909\ttotal: 20.1s\tremaining: 11.2s\n",
      "643:\tlearn: 0.0260881\ttotal: 20.1s\tremaining: 11.1s\n",
      "644:\tlearn: 0.0260840\ttotal: 20.2s\tremaining: 11.1s\n",
      "645:\tlearn: 0.0260818\ttotal: 20.2s\tremaining: 11.1s\n",
      "646:\tlearn: 0.0260741\ttotal: 20.2s\tremaining: 11s\n",
      "647:\tlearn: 0.0260666\ttotal: 20.3s\tremaining: 11s\n",
      "648:\tlearn: 0.0260316\ttotal: 20.3s\tremaining: 11s\n",
      "649:\tlearn: 0.0260107\ttotal: 20.4s\tremaining: 11s\n",
      "650:\tlearn: 0.0259903\ttotal: 20.4s\tremaining: 10.9s\n",
      "651:\tlearn: 0.0259851\ttotal: 20.4s\tremaining: 10.9s\n",
      "652:\tlearn: 0.0259808\ttotal: 20.5s\tremaining: 10.9s\n",
      "653:\tlearn: 0.0259308\ttotal: 20.5s\tremaining: 10.8s\n",
      "654:\tlearn: 0.0259215\ttotal: 20.5s\tremaining: 10.8s\n",
      "655:\tlearn: 0.0259199\ttotal: 20.6s\tremaining: 10.8s\n",
      "656:\tlearn: 0.0259187\ttotal: 20.6s\tremaining: 10.7s\n",
      "657:\tlearn: 0.0259140\ttotal: 20.6s\tremaining: 10.7s\n",
      "658:\tlearn: 0.0259082\ttotal: 20.6s\tremaining: 10.7s\n",
      "659:\tlearn: 0.0258980\ttotal: 20.7s\tremaining: 10.7s\n",
      "660:\tlearn: 0.0258944\ttotal: 20.7s\tremaining: 10.6s\n",
      "661:\tlearn: 0.0258793\ttotal: 20.7s\tremaining: 10.6s\n",
      "662:\tlearn: 0.0258687\ttotal: 20.8s\tremaining: 10.6s\n",
      "663:\tlearn: 0.0258658\ttotal: 20.8s\tremaining: 10.5s\n",
      "664:\tlearn: 0.0258519\ttotal: 20.8s\tremaining: 10.5s\n",
      "665:\tlearn: 0.0258136\ttotal: 20.9s\tremaining: 10.5s\n",
      "666:\tlearn: 0.0258011\ttotal: 20.9s\tremaining: 10.4s\n",
      "667:\tlearn: 0.0257977\ttotal: 20.9s\tremaining: 10.4s\n",
      "668:\tlearn: 0.0257904\ttotal: 21s\tremaining: 10.4s\n",
      "669:\tlearn: 0.0257653\ttotal: 21s\tremaining: 10.3s\n",
      "670:\tlearn: 0.0257583\ttotal: 21s\tremaining: 10.3s\n",
      "671:\tlearn: 0.0257534\ttotal: 21.1s\tremaining: 10.3s\n",
      "672:\tlearn: 0.0257519\ttotal: 21.1s\tremaining: 10.3s\n",
      "673:\tlearn: 0.0257463\ttotal: 21.1s\tremaining: 10.2s\n",
      "674:\tlearn: 0.0257092\ttotal: 21.2s\tremaining: 10.2s\n",
      "675:\tlearn: 0.0257076\ttotal: 21.2s\tremaining: 10.2s\n",
      "676:\tlearn: 0.0257065\ttotal: 21.2s\tremaining: 10.1s\n",
      "677:\tlearn: 0.0256994\ttotal: 21.3s\tremaining: 10.1s\n",
      "678:\tlearn: 0.0256981\ttotal: 21.3s\tremaining: 10.1s\n",
      "679:\tlearn: 0.0256746\ttotal: 21.3s\tremaining: 10s\n",
      "680:\tlearn: 0.0256679\ttotal: 21.4s\tremaining: 10s\n",
      "681:\tlearn: 0.0256632\ttotal: 21.4s\tremaining: 9.98s\n",
      "682:\tlearn: 0.0256599\ttotal: 21.4s\tremaining: 9.95s\n",
      "683:\tlearn: 0.0256523\ttotal: 21.5s\tremaining: 9.94s\n",
      "684:\tlearn: 0.0256207\ttotal: 21.6s\tremaining: 9.94s\n",
      "685:\tlearn: 0.0255900\ttotal: 21.7s\tremaining: 9.93s\n",
      "686:\tlearn: 0.0255854\ttotal: 21.7s\tremaining: 9.9s\n",
      "687:\tlearn: 0.0255592\ttotal: 21.8s\tremaining: 9.87s\n",
      "688:\tlearn: 0.0255519\ttotal: 21.8s\tremaining: 9.86s\n",
      "689:\tlearn: 0.0255388\ttotal: 21.9s\tremaining: 9.83s\n",
      "690:\tlearn: 0.0255091\ttotal: 21.9s\tremaining: 9.8s\n",
      "691:\tlearn: 0.0255036\ttotal: 22s\tremaining: 9.77s\n",
      "692:\tlearn: 0.0254998\ttotal: 22s\tremaining: 9.74s\n",
      "693:\tlearn: 0.0254952\ttotal: 22s\tremaining: 9.71s\n",
      "694:\tlearn: 0.0254887\ttotal: 22.1s\tremaining: 9.68s\n",
      "695:\tlearn: 0.0254749\ttotal: 22.1s\tremaining: 9.64s\n",
      "696:\tlearn: 0.0254709\ttotal: 22.1s\tremaining: 9.61s\n",
      "697:\tlearn: 0.0254673\ttotal: 22.1s\tremaining: 9.58s\n",
      "698:\tlearn: 0.0254609\ttotal: 22.2s\tremaining: 9.55s\n",
      "699:\tlearn: 0.0254574\ttotal: 22.2s\tremaining: 9.52s\n",
      "700:\tlearn: 0.0254320\ttotal: 22.2s\tremaining: 9.49s\n",
      "701:\tlearn: 0.0254286\ttotal: 22.3s\tremaining: 9.46s\n",
      "702:\tlearn: 0.0254241\ttotal: 22.3s\tremaining: 9.42s\n",
      "703:\tlearn: 0.0254190\ttotal: 22.3s\tremaining: 9.39s\n",
      "704:\tlearn: 0.0253866\ttotal: 22.4s\tremaining: 9.36s\n",
      "705:\tlearn: 0.0253584\ttotal: 22.4s\tremaining: 9.33s\n",
      "706:\tlearn: 0.0253552\ttotal: 22.4s\tremaining: 9.3s\n",
      "707:\tlearn: 0.0253537\ttotal: 22.5s\tremaining: 9.27s\n",
      "708:\tlearn: 0.0253513\ttotal: 22.5s\tremaining: 9.23s\n",
      "709:\tlearn: 0.0253503\ttotal: 22.5s\tremaining: 9.2s\n",
      "710:\tlearn: 0.0253459\ttotal: 22.6s\tremaining: 9.17s\n",
      "711:\tlearn: 0.0253237\ttotal: 22.6s\tremaining: 9.14s\n",
      "712:\tlearn: 0.0252921\ttotal: 22.6s\tremaining: 9.11s\n",
      "713:\tlearn: 0.0252681\ttotal: 22.7s\tremaining: 9.08s\n",
      "714:\tlearn: 0.0252653\ttotal: 22.7s\tremaining: 9.05s\n",
      "715:\tlearn: 0.0252610\ttotal: 22.7s\tremaining: 9.02s\n",
      "716:\tlearn: 0.0252478\ttotal: 22.8s\tremaining: 8.98s\n",
      "717:\tlearn: 0.0252246\ttotal: 22.8s\tremaining: 8.95s\n",
      "718:\tlearn: 0.0252231\ttotal: 22.8s\tremaining: 8.92s\n",
      "719:\tlearn: 0.0252151\ttotal: 22.9s\tremaining: 8.89s\n",
      "720:\tlearn: 0.0252125\ttotal: 22.9s\tremaining: 8.86s\n",
      "721:\tlearn: 0.0252037\ttotal: 22.9s\tremaining: 8.83s\n",
      "722:\tlearn: 0.0251773\ttotal: 23s\tremaining: 8.79s\n",
      "723:\tlearn: 0.0251547\ttotal: 23s\tremaining: 8.76s\n",
      "724:\tlearn: 0.0251485\ttotal: 23s\tremaining: 8.73s\n",
      "725:\tlearn: 0.0251247\ttotal: 23s\tremaining: 8.7s\n",
      "726:\tlearn: 0.0250991\ttotal: 23.1s\tremaining: 8.67s\n",
      "727:\tlearn: 0.0250978\ttotal: 23.1s\tremaining: 8.64s\n",
      "728:\tlearn: 0.0250930\ttotal: 23.1s\tremaining: 8.6s\n",
      "729:\tlearn: 0.0250899\ttotal: 23.2s\tremaining: 8.57s\n",
      "730:\tlearn: 0.0250858\ttotal: 23.2s\tremaining: 8.54s\n",
      "731:\tlearn: 0.0250659\ttotal: 23.2s\tremaining: 8.51s\n",
      "732:\tlearn: 0.0250557\ttotal: 23.3s\tremaining: 8.48s\n",
      "733:\tlearn: 0.0250330\ttotal: 23.3s\tremaining: 8.44s\n",
      "734:\tlearn: 0.0250285\ttotal: 23.3s\tremaining: 8.41s\n",
      "735:\tlearn: 0.0250069\ttotal: 23.4s\tremaining: 8.38s\n",
      "736:\tlearn: 0.0250056\ttotal: 23.4s\tremaining: 8.35s\n",
      "737:\tlearn: 0.0249715\ttotal: 23.4s\tremaining: 8.32s\n",
      "738:\tlearn: 0.0249654\ttotal: 23.5s\tremaining: 8.29s\n",
      "739:\tlearn: 0.0249408\ttotal: 23.5s\tremaining: 8.26s\n",
      "740:\tlearn: 0.0249232\ttotal: 23.5s\tremaining: 8.22s\n",
      "741:\tlearn: 0.0249153\ttotal: 23.6s\tremaining: 8.19s\n",
      "742:\tlearn: 0.0249111\ttotal: 23.6s\tremaining: 8.16s\n",
      "743:\tlearn: 0.0249085\ttotal: 23.6s\tremaining: 8.13s\n",
      "744:\tlearn: 0.0249029\ttotal: 23.7s\tremaining: 8.1s\n",
      "745:\tlearn: 0.0248989\ttotal: 23.7s\tremaining: 8.07s\n",
      "746:\tlearn: 0.0248949\ttotal: 23.7s\tremaining: 8.04s\n",
      "747:\tlearn: 0.0248742\ttotal: 23.8s\tremaining: 8.01s\n",
      "748:\tlearn: 0.0248729\ttotal: 23.8s\tremaining: 7.97s\n",
      "749:\tlearn: 0.0248722\ttotal: 23.8s\tremaining: 7.94s\n",
      "750:\tlearn: 0.0248692\ttotal: 23.9s\tremaining: 7.92s\n",
      "751:\tlearn: 0.0248453\ttotal: 23.9s\tremaining: 7.89s\n",
      "752:\tlearn: 0.0248255\ttotal: 24s\tremaining: 7.86s\n",
      "753:\tlearn: 0.0248216\ttotal: 24s\tremaining: 7.83s\n",
      "754:\tlearn: 0.0248003\ttotal: 24s\tremaining: 7.8s\n",
      "755:\tlearn: 0.0247991\ttotal: 24.1s\tremaining: 7.77s\n",
      "756:\tlearn: 0.0247979\ttotal: 24.1s\tremaining: 7.74s\n",
      "757:\tlearn: 0.0247926\ttotal: 24.1s\tremaining: 7.71s\n",
      "758:\tlearn: 0.0247688\ttotal: 24.2s\tremaining: 7.68s\n",
      "759:\tlearn: 0.0247659\ttotal: 24.2s\tremaining: 7.65s\n",
      "760:\tlearn: 0.0247622\ttotal: 24.2s\tremaining: 7.62s\n",
      "761:\tlearn: 0.0247447\ttotal: 24.3s\tremaining: 7.58s\n",
      "762:\tlearn: 0.0247437\ttotal: 24.3s\tremaining: 7.55s\n",
      "763:\tlearn: 0.0247023\ttotal: 24.3s\tremaining: 7.52s\n",
      "764:\tlearn: 0.0246899\ttotal: 24.4s\tremaining: 7.49s\n",
      "765:\tlearn: 0.0246710\ttotal: 24.4s\tremaining: 7.46s\n",
      "766:\tlearn: 0.0246667\ttotal: 24.4s\tremaining: 7.43s\n",
      "767:\tlearn: 0.0246643\ttotal: 24.5s\tremaining: 7.4s\n",
      "768:\tlearn: 0.0246586\ttotal: 24.5s\tremaining: 7.36s\n",
      "769:\tlearn: 0.0246536\ttotal: 24.5s\tremaining: 7.33s\n",
      "770:\tlearn: 0.0246459\ttotal: 24.6s\tremaining: 7.3s\n",
      "771:\tlearn: 0.0246346\ttotal: 24.6s\tremaining: 7.27s\n",
      "772:\tlearn: 0.0245990\ttotal: 24.7s\tremaining: 7.24s\n",
      "773:\tlearn: 0.0245637\ttotal: 24.7s\tremaining: 7.21s\n",
      "774:\tlearn: 0.0245626\ttotal: 24.7s\tremaining: 7.18s\n",
      "775:\tlearn: 0.0245604\ttotal: 24.8s\tremaining: 7.14s\n",
      "776:\tlearn: 0.0245400\ttotal: 24.8s\tremaining: 7.12s\n",
      "777:\tlearn: 0.0245324\ttotal: 24.8s\tremaining: 7.08s\n",
      "778:\tlearn: 0.0244980\ttotal: 24.9s\tremaining: 7.05s\n",
      "779:\tlearn: 0.0244969\ttotal: 24.9s\tremaining: 7.02s\n",
      "780:\tlearn: 0.0244887\ttotal: 24.9s\tremaining: 6.99s\n",
      "781:\tlearn: 0.0244865\ttotal: 25s\tremaining: 6.96s\n",
      "782:\tlearn: 0.0244635\ttotal: 25s\tremaining: 6.93s\n",
      "783:\tlearn: 0.0244472\ttotal: 25s\tremaining: 6.9s\n",
      "784:\tlearn: 0.0244452\ttotal: 25.1s\tremaining: 6.87s\n",
      "785:\tlearn: 0.0244442\ttotal: 25.1s\tremaining: 6.83s\n",
      "786:\tlearn: 0.0244433\ttotal: 25.1s\tremaining: 6.8s\n",
      "787:\tlearn: 0.0244092\ttotal: 25.2s\tremaining: 6.77s\n",
      "788:\tlearn: 0.0243870\ttotal: 25.2s\tremaining: 6.74s\n",
      "789:\tlearn: 0.0243798\ttotal: 25.2s\tremaining: 6.71s\n",
      "790:\tlearn: 0.0243618\ttotal: 25.3s\tremaining: 6.68s\n",
      "791:\tlearn: 0.0243291\ttotal: 25.3s\tremaining: 6.65s\n",
      "792:\tlearn: 0.0243127\ttotal: 25.3s\tremaining: 6.62s\n",
      "793:\tlearn: 0.0242789\ttotal: 25.4s\tremaining: 6.58s\n",
      "794:\tlearn: 0.0242738\ttotal: 25.4s\tremaining: 6.55s\n",
      "795:\tlearn: 0.0242542\ttotal: 25.4s\tremaining: 6.52s\n",
      "796:\tlearn: 0.0242371\ttotal: 25.5s\tremaining: 6.49s\n",
      "797:\tlearn: 0.0242340\ttotal: 25.5s\tremaining: 6.46s\n",
      "798:\tlearn: 0.0242149\ttotal: 25.5s\tremaining: 6.43s\n",
      "799:\tlearn: 0.0242141\ttotal: 25.6s\tremaining: 6.39s\n",
      "800:\tlearn: 0.0242121\ttotal: 25.6s\tremaining: 6.36s\n",
      "801:\tlearn: 0.0242111\ttotal: 25.7s\tremaining: 6.33s\n",
      "802:\tlearn: 0.0241924\ttotal: 25.7s\tremaining: 6.3s\n",
      "803:\tlearn: 0.0241760\ttotal: 25.7s\tremaining: 6.27s\n",
      "804:\tlearn: 0.0241449\ttotal: 25.8s\tremaining: 6.24s\n",
      "805:\tlearn: 0.0241166\ttotal: 25.8s\tremaining: 6.21s\n",
      "806:\tlearn: 0.0240985\ttotal: 25.8s\tremaining: 6.17s\n",
      "807:\tlearn: 0.0240976\ttotal: 25.8s\tremaining: 6.14s\n",
      "808:\tlearn: 0.0240930\ttotal: 25.9s\tremaining: 6.11s\n",
      "809:\tlearn: 0.0240895\ttotal: 25.9s\tremaining: 6.08s\n",
      "810:\tlearn: 0.0240842\ttotal: 26s\tremaining: 6.05s\n",
      "811:\tlearn: 0.0240798\ttotal: 26s\tremaining: 6.02s\n",
      "812:\tlearn: 0.0240495\ttotal: 26s\tremaining: 5.99s\n",
      "813:\tlearn: 0.0240454\ttotal: 26.1s\tremaining: 5.95s\n",
      "814:\tlearn: 0.0240422\ttotal: 26.1s\tremaining: 5.92s\n",
      "815:\tlearn: 0.0240363\ttotal: 26.1s\tremaining: 5.89s\n",
      "816:\tlearn: 0.0240054\ttotal: 26.2s\tremaining: 5.86s\n",
      "817:\tlearn: 0.0240045\ttotal: 26.2s\tremaining: 5.83s\n",
      "818:\tlearn: 0.0239884\ttotal: 26.2s\tremaining: 5.79s\n",
      "819:\tlearn: 0.0239875\ttotal: 26.3s\tremaining: 5.76s\n",
      "820:\tlearn: 0.0239566\ttotal: 26.3s\tremaining: 5.73s\n",
      "821:\tlearn: 0.0239272\ttotal: 26.3s\tremaining: 5.7s\n",
      "822:\tlearn: 0.0239117\ttotal: 26.4s\tremaining: 5.67s\n",
      "823:\tlearn: 0.0239084\ttotal: 26.4s\tremaining: 5.64s\n",
      "824:\tlearn: 0.0239026\ttotal: 26.4s\tremaining: 5.61s\n",
      "825:\tlearn: 0.0238905\ttotal: 26.5s\tremaining: 5.58s\n",
      "826:\tlearn: 0.0238854\ttotal: 26.5s\tremaining: 5.54s\n",
      "827:\tlearn: 0.0238845\ttotal: 26.5s\tremaining: 5.51s\n",
      "828:\tlearn: 0.0238827\ttotal: 26.6s\tremaining: 5.48s\n",
      "829:\tlearn: 0.0238758\ttotal: 26.6s\tremaining: 5.45s\n",
      "830:\tlearn: 0.0238582\ttotal: 26.7s\tremaining: 5.42s\n",
      "831:\tlearn: 0.0238310\ttotal: 26.7s\tremaining: 5.39s\n",
      "832:\tlearn: 0.0238162\ttotal: 26.7s\tremaining: 5.36s\n",
      "833:\tlearn: 0.0238111\ttotal: 26.8s\tremaining: 5.33s\n",
      "834:\tlearn: 0.0238067\ttotal: 26.8s\tremaining: 5.29s\n",
      "835:\tlearn: 0.0237853\ttotal: 26.8s\tremaining: 5.26s\n",
      "836:\tlearn: 0.0237671\ttotal: 26.9s\tremaining: 5.23s\n",
      "837:\tlearn: 0.0237503\ttotal: 26.9s\tremaining: 5.2s\n",
      "838:\tlearn: 0.0237336\ttotal: 26.9s\tremaining: 5.17s\n",
      "839:\tlearn: 0.0237074\ttotal: 27s\tremaining: 5.13s\n",
      "840:\tlearn: 0.0237039\ttotal: 27s\tremaining: 5.1s\n",
      "841:\tlearn: 0.0236770\ttotal: 27s\tremaining: 5.07s\n",
      "842:\tlearn: 0.0236739\ttotal: 27.1s\tremaining: 5.04s\n",
      "843:\tlearn: 0.0236414\ttotal: 27.1s\tremaining: 5.01s\n",
      "844:\tlearn: 0.0236262\ttotal: 27.1s\tremaining: 4.97s\n",
      "845:\tlearn: 0.0236206\ttotal: 27.2s\tremaining: 4.94s\n",
      "846:\tlearn: 0.0236095\ttotal: 27.2s\tremaining: 4.91s\n",
      "847:\tlearn: 0.0235924\ttotal: 27.2s\tremaining: 4.88s\n",
      "848:\tlearn: 0.0235667\ttotal: 27.3s\tremaining: 4.85s\n",
      "849:\tlearn: 0.0235448\ttotal: 27.3s\tremaining: 4.81s\n",
      "850:\tlearn: 0.0235309\ttotal: 27.3s\tremaining: 4.78s\n",
      "851:\tlearn: 0.0235287\ttotal: 27.4s\tremaining: 4.75s\n",
      "852:\tlearn: 0.0235268\ttotal: 27.4s\tremaining: 4.72s\n",
      "853:\tlearn: 0.0235250\ttotal: 27.4s\tremaining: 4.69s\n",
      "854:\tlearn: 0.0235093\ttotal: 27.4s\tremaining: 4.65s\n",
      "855:\tlearn: 0.0235084\ttotal: 27.5s\tremaining: 4.62s\n",
      "856:\tlearn: 0.0235016\ttotal: 27.5s\tremaining: 4.59s\n",
      "857:\tlearn: 0.0235007\ttotal: 27.6s\tremaining: 4.56s\n",
      "858:\tlearn: 0.0234999\ttotal: 27.6s\tremaining: 4.54s\n",
      "859:\tlearn: 0.0234641\ttotal: 27.7s\tremaining: 4.51s\n",
      "860:\tlearn: 0.0234368\ttotal: 27.8s\tremaining: 4.49s\n",
      "861:\tlearn: 0.0234317\ttotal: 27.9s\tremaining: 4.46s\n",
      "862:\tlearn: 0.0234262\ttotal: 27.9s\tremaining: 4.43s\n",
      "863:\tlearn: 0.0234222\ttotal: 28s\tremaining: 4.4s\n",
      "864:\tlearn: 0.0234204\ttotal: 28s\tremaining: 4.37s\n",
      "865:\tlearn: 0.0234052\ttotal: 28s\tremaining: 4.34s\n",
      "866:\tlearn: 0.0233734\ttotal: 28.1s\tremaining: 4.3s\n",
      "867:\tlearn: 0.0233386\ttotal: 28.1s\tremaining: 4.27s\n",
      "868:\tlearn: 0.0233122\ttotal: 28.1s\tremaining: 4.24s\n",
      "869:\tlearn: 0.0232916\ttotal: 28.2s\tremaining: 4.21s\n",
      "870:\tlearn: 0.0232852\ttotal: 28.2s\tremaining: 4.17s\n",
      "871:\tlearn: 0.0232469\ttotal: 28.2s\tremaining: 4.14s\n",
      "872:\tlearn: 0.0232238\ttotal: 28.3s\tremaining: 4.11s\n",
      "873:\tlearn: 0.0232210\ttotal: 28.3s\tremaining: 4.08s\n",
      "874:\tlearn: 0.0232200\ttotal: 28.3s\tremaining: 4.05s\n",
      "875:\tlearn: 0.0232183\ttotal: 28.4s\tremaining: 4.01s\n",
      "876:\tlearn: 0.0232051\ttotal: 28.4s\tremaining: 3.98s\n",
      "877:\tlearn: 0.0232043\ttotal: 28.4s\tremaining: 3.95s\n",
      "878:\tlearn: 0.0231951\ttotal: 28.5s\tremaining: 3.92s\n",
      "879:\tlearn: 0.0231824\ttotal: 28.5s\tremaining: 3.89s\n",
      "880:\tlearn: 0.0231591\ttotal: 28.5s\tremaining: 3.85s\n",
      "881:\tlearn: 0.0231392\ttotal: 28.6s\tremaining: 3.82s\n",
      "882:\tlearn: 0.0231200\ttotal: 28.6s\tremaining: 3.79s\n",
      "883:\tlearn: 0.0231165\ttotal: 28.6s\tremaining: 3.76s\n",
      "884:\tlearn: 0.0231043\ttotal: 28.7s\tremaining: 3.73s\n",
      "885:\tlearn: 0.0230818\ttotal: 28.7s\tremaining: 3.69s\n",
      "886:\tlearn: 0.0230773\ttotal: 28.7s\tremaining: 3.66s\n",
      "887:\tlearn: 0.0230469\ttotal: 28.8s\tremaining: 3.63s\n",
      "888:\tlearn: 0.0230162\ttotal: 28.8s\tremaining: 3.6s\n",
      "889:\tlearn: 0.0229946\ttotal: 28.8s\tremaining: 3.56s\n",
      "890:\tlearn: 0.0229849\ttotal: 28.9s\tremaining: 3.53s\n",
      "891:\tlearn: 0.0229521\ttotal: 28.9s\tremaining: 3.5s\n",
      "892:\tlearn: 0.0229505\ttotal: 28.9s\tremaining: 3.47s\n",
      "893:\tlearn: 0.0229345\ttotal: 29s\tremaining: 3.44s\n",
      "894:\tlearn: 0.0229325\ttotal: 29s\tremaining: 3.4s\n",
      "895:\tlearn: 0.0229296\ttotal: 29s\tremaining: 3.37s\n",
      "896:\tlearn: 0.0229287\ttotal: 29.1s\tremaining: 3.34s\n",
      "897:\tlearn: 0.0228903\ttotal: 29.1s\tremaining: 3.31s\n",
      "898:\tlearn: 0.0228717\ttotal: 29.1s\tremaining: 3.27s\n",
      "899:\tlearn: 0.0228688\ttotal: 29.2s\tremaining: 3.24s\n",
      "900:\tlearn: 0.0228618\ttotal: 29.2s\tremaining: 3.21s\n",
      "901:\tlearn: 0.0228463\ttotal: 29.2s\tremaining: 3.18s\n",
      "902:\tlearn: 0.0228315\ttotal: 29.3s\tremaining: 3.14s\n",
      "903:\tlearn: 0.0227948\ttotal: 29.3s\tremaining: 3.11s\n",
      "904:\tlearn: 0.0227921\ttotal: 29.3s\tremaining: 3.08s\n",
      "905:\tlearn: 0.0227540\ttotal: 29.4s\tremaining: 3.05s\n",
      "906:\tlearn: 0.0227401\ttotal: 29.4s\tremaining: 3.02s\n",
      "907:\tlearn: 0.0227135\ttotal: 29.4s\tremaining: 2.98s\n",
      "908:\tlearn: 0.0226737\ttotal: 29.5s\tremaining: 2.95s\n",
      "909:\tlearn: 0.0226710\ttotal: 29.5s\tremaining: 2.92s\n",
      "910:\tlearn: 0.0226682\ttotal: 29.5s\tremaining: 2.88s\n",
      "911:\tlearn: 0.0226649\ttotal: 29.6s\tremaining: 2.85s\n",
      "912:\tlearn: 0.0226623\ttotal: 29.6s\tremaining: 2.82s\n",
      "913:\tlearn: 0.0226362\ttotal: 29.6s\tremaining: 2.79s\n",
      "914:\tlearn: 0.0226313\ttotal: 29.7s\tremaining: 2.75s\n",
      "915:\tlearn: 0.0226305\ttotal: 29.7s\tremaining: 2.72s\n",
      "916:\tlearn: 0.0226280\ttotal: 29.7s\tremaining: 2.69s\n",
      "917:\tlearn: 0.0226261\ttotal: 29.8s\tremaining: 2.66s\n",
      "918:\tlearn: 0.0225855\ttotal: 29.8s\tremaining: 2.63s\n",
      "919:\tlearn: 0.0225609\ttotal: 29.8s\tremaining: 2.59s\n",
      "920:\tlearn: 0.0225224\ttotal: 29.9s\tremaining: 2.56s\n",
      "921:\tlearn: 0.0225099\ttotal: 29.9s\tremaining: 2.53s\n",
      "922:\tlearn: 0.0225090\ttotal: 29.9s\tremaining: 2.5s\n",
      "923:\tlearn: 0.0225017\ttotal: 30s\tremaining: 2.46s\n",
      "924:\tlearn: 0.0224633\ttotal: 30s\tremaining: 2.43s\n",
      "925:\tlearn: 0.0224371\ttotal: 30s\tremaining: 2.4s\n",
      "926:\tlearn: 0.0224124\ttotal: 30.1s\tremaining: 2.37s\n",
      "927:\tlearn: 0.0224097\ttotal: 30.1s\tremaining: 2.33s\n",
      "928:\tlearn: 0.0224090\ttotal: 30.1s\tremaining: 2.3s\n",
      "929:\tlearn: 0.0223975\ttotal: 30.2s\tremaining: 2.27s\n",
      "930:\tlearn: 0.0223684\ttotal: 30.2s\tremaining: 2.24s\n",
      "931:\tlearn: 0.0223317\ttotal: 30.2s\tremaining: 2.21s\n",
      "932:\tlearn: 0.0223005\ttotal: 30.3s\tremaining: 2.17s\n",
      "933:\tlearn: 0.0222979\ttotal: 30.3s\tremaining: 2.14s\n",
      "934:\tlearn: 0.0222971\ttotal: 30.3s\tremaining: 2.11s\n",
      "935:\tlearn: 0.0222953\ttotal: 30.4s\tremaining: 2.08s\n",
      "936:\tlearn: 0.0222641\ttotal: 30.4s\tremaining: 2.04s\n",
      "937:\tlearn: 0.0222423\ttotal: 30.4s\tremaining: 2.01s\n",
      "938:\tlearn: 0.0222314\ttotal: 30.5s\tremaining: 1.98s\n",
      "939:\tlearn: 0.0222058\ttotal: 30.5s\tremaining: 1.95s\n",
      "940:\tlearn: 0.0221771\ttotal: 30.5s\tremaining: 1.91s\n",
      "941:\tlearn: 0.0221457\ttotal: 30.5s\tremaining: 1.88s\n",
      "942:\tlearn: 0.0221191\ttotal: 30.6s\tremaining: 1.85s\n",
      "943:\tlearn: 0.0221175\ttotal: 30.6s\tremaining: 1.82s\n",
      "944:\tlearn: 0.0220888\ttotal: 30.6s\tremaining: 1.78s\n",
      "945:\tlearn: 0.0220719\ttotal: 30.7s\tremaining: 1.75s\n",
      "946:\tlearn: 0.0220517\ttotal: 30.7s\tremaining: 1.72s\n",
      "947:\tlearn: 0.0220508\ttotal: 30.7s\tremaining: 1.69s\n",
      "948:\tlearn: 0.0220404\ttotal: 30.8s\tremaining: 1.65s\n",
      "949:\tlearn: 0.0220070\ttotal: 30.8s\tremaining: 1.62s\n",
      "950:\tlearn: 0.0219906\ttotal: 30.9s\tremaining: 1.59s\n",
      "951:\tlearn: 0.0219897\ttotal: 30.9s\tremaining: 1.56s\n",
      "952:\tlearn: 0.0219739\ttotal: 30.9s\tremaining: 1.52s\n",
      "953:\tlearn: 0.0219595\ttotal: 31s\tremaining: 1.49s\n",
      "954:\tlearn: 0.0219443\ttotal: 31s\tremaining: 1.46s\n",
      "955:\tlearn: 0.0219194\ttotal: 31s\tremaining: 1.43s\n",
      "956:\tlearn: 0.0218864\ttotal: 31.1s\tremaining: 1.4s\n",
      "957:\tlearn: 0.0218681\ttotal: 31.1s\tremaining: 1.36s\n",
      "958:\tlearn: 0.0218433\ttotal: 31.1s\tremaining: 1.33s\n",
      "959:\tlearn: 0.0218425\ttotal: 31.2s\tremaining: 1.3s\n",
      "960:\tlearn: 0.0218394\ttotal: 31.2s\tremaining: 1.26s\n",
      "961:\tlearn: 0.0218242\ttotal: 31.2s\tremaining: 1.23s\n",
      "962:\tlearn: 0.0218233\ttotal: 31.3s\tremaining: 1.2s\n",
      "963:\tlearn: 0.0218226\ttotal: 31.3s\tremaining: 1.17s\n",
      "964:\tlearn: 0.0218084\ttotal: 31.3s\tremaining: 1.14s\n",
      "965:\tlearn: 0.0217841\ttotal: 31.4s\tremaining: 1.1s\n",
      "966:\tlearn: 0.0217566\ttotal: 31.4s\tremaining: 1.07s\n",
      "967:\tlearn: 0.0217465\ttotal: 31.4s\tremaining: 1.04s\n",
      "968:\tlearn: 0.0217256\ttotal: 31.4s\tremaining: 1.01s\n",
      "969:\tlearn: 0.0216999\ttotal: 31.5s\tremaining: 974ms\n",
      "970:\tlearn: 0.0216859\ttotal: 31.5s\tremaining: 941ms\n",
      "971:\tlearn: 0.0216671\ttotal: 31.6s\tremaining: 909ms\n",
      "972:\tlearn: 0.0216532\ttotal: 31.6s\tremaining: 876ms\n",
      "973:\tlearn: 0.0216390\ttotal: 31.6s\tremaining: 844ms\n",
      "974:\tlearn: 0.0216122\ttotal: 31.6s\tremaining: 811ms\n",
      "975:\tlearn: 0.0215985\ttotal: 31.7s\tremaining: 779ms\n",
      "976:\tlearn: 0.0215887\ttotal: 31.7s\tremaining: 747ms\n",
      "977:\tlearn: 0.0215759\ttotal: 31.7s\tremaining: 714ms\n",
      "978:\tlearn: 0.0215582\ttotal: 31.8s\tremaining: 682ms\n",
      "979:\tlearn: 0.0215259\ttotal: 31.8s\tremaining: 649ms\n",
      "980:\tlearn: 0.0215178\ttotal: 31.8s\tremaining: 617ms\n",
      "981:\tlearn: 0.0215045\ttotal: 31.9s\tremaining: 584ms\n",
      "982:\tlearn: 0.0214875\ttotal: 31.9s\tremaining: 552ms\n",
      "983:\tlearn: 0.0214742\ttotal: 31.9s\tremaining: 519ms\n",
      "984:\tlearn: 0.0214611\ttotal: 32s\tremaining: 487ms\n",
      "985:\tlearn: 0.0214569\ttotal: 32s\tremaining: 454ms\n",
      "986:\tlearn: 0.0214381\ttotal: 32s\tremaining: 422ms\n",
      "987:\tlearn: 0.0214231\ttotal: 32.1s\tremaining: 390ms\n",
      "988:\tlearn: 0.0214222\ttotal: 32.1s\tremaining: 357ms\n",
      "989:\tlearn: 0.0214079\ttotal: 32.2s\tremaining: 325ms\n",
      "990:\tlearn: 0.0213997\ttotal: 32.2s\tremaining: 292ms\n",
      "991:\tlearn: 0.0213968\ttotal: 32.2s\tremaining: 260ms\n",
      "992:\tlearn: 0.0213791\ttotal: 32.3s\tremaining: 227ms\n",
      "993:\tlearn: 0.0213666\ttotal: 32.3s\tremaining: 195ms\n",
      "994:\tlearn: 0.0213660\ttotal: 32.3s\tremaining: 162ms\n",
      "995:\tlearn: 0.0213530\ttotal: 32.4s\tremaining: 130ms\n",
      "996:\tlearn: 0.0213410\ttotal: 32.4s\tremaining: 97.5ms\n",
      "997:\tlearn: 0.0213367\ttotal: 32.4s\tremaining: 65ms\n",
      "998:\tlearn: 0.0213332\ttotal: 32.5s\tremaining: 32.5ms\n",
      "999:\tlearn: 0.0213192\ttotal: 32.5s\tremaining: 0us\n",
      "Model Performance for CatBoost_Custom\n",
      "Train Gini prob is 96.77687198067633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8004\n",
      "           1       0.96      0.50      0.66        96\n",
      "\n",
      "    accuracy                           0.99      8100\n",
      "   macro avg       0.98      0.75      0.83      8100\n",
      "weighted avg       0.99      0.99      0.99      8100\n",
      "\n",
      "[[8002    2]\n",
      " [  48   48]]\n",
      "Model Performance for CatBoost_Custom\n",
      "Test Gini prob is 51.86311441928018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2003\n",
      "           1       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       0.92      0.64      0.70      2025\n",
      "weighted avg       0.99      0.99      0.99      2025\n",
      "\n",
      "[[2002    1]\n",
      " [  16    6]]\n",
      "Model Performance for RandomForest\n",
      "Train Gini prob is 100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8004\n",
      "           1       1.00      1.00      1.00        96\n",
      "\n",
      "    accuracy                           1.00      8100\n",
      "   macro avg       1.00      1.00      1.00      8100\n",
      "weighted avg       1.00      1.00      1.00      8100\n",
      "\n",
      "[[8004    0]\n",
      " [   0   96]]\n",
      "Model Performance for RandomForest\n",
      "Test Gini prob is 60.11210457041707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2003\n",
      "           1       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       1.00      0.57      0.62      2025\n",
      "weighted avg       0.99      0.99      0.99      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  19    3]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Gini</th>\n",
       "      <th>Test Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.989266</td>\n",
       "      <td>0.568783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_Custom</td>\n",
       "      <td>0.967769</td>\n",
       "      <td>0.518631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Train Gini  Test Gini\n",
       "0          XGBoost    1.000000   0.658875\n",
       "1         LightGBM    1.000000   0.656152\n",
       "4     RandomForest    1.000000   0.601121\n",
       "2         CatBoost    0.989266   0.568783\n",
       "3  CatBoost_Custom    0.967769   0.518631"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_df = pd.DataFrame(columns=['Model', 'Train Gini', 'Test Gini'])\n",
    "\n",
    "for model_name, model in models:\n",
    "    if model_name == 'CatBoost_Custom':\n",
    "        gini_prob = train_and_evaluate_model(model_name, model, X_train_cat, y_train_cat, X_test_cat, y_test_cat)\n",
    "    else:\n",
    "        gini_prob = train_and_evaluate_model(model_name, model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    if gini_prob is not None:\n",
    "        gini_df = pd.concat([gini_df, pd.DataFrame({'Model': [model_name], 'Train Gini': [gini_prob[0]], 'Test Gini': [gini_prob[1]]})], ignore_index=True)\n",
    "\n",
    "gini_df_sorted = gini_df.sort_values(by='Test Gini', ascending=False)\n",
    "\n",
    "gini_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "0741c8a7-7f22-4556-9c98-ec82d2f635ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Gini</th>\n",
       "      <th>Test Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.989266</td>\n",
       "      <td>0.568783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_Custom</td>\n",
       "      <td>0.967769</td>\n",
       "      <td>0.518631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Train Gini  Test Gini\n",
       "0          XGBoost    1.000000   0.658875\n",
       "1         LightGBM    1.000000   0.656152\n",
       "4     RandomForest    1.000000   0.601121\n",
       "2         CatBoost    0.989266   0.568783\n",
       "3  CatBoost_Custom    0.967769   0.518631"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504596a-46b6-407c-8e91-652d3e48d675",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "2ceb4815-ee5e-49c6-b1b8-5737d7cb7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "e027333f-7d8b-4608-bb87-5c989de61fb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 15:30:03,425] A new study created in memory with name: no-name-eb5c6a73-2835-4911-95f3-31e5d91bc1d2\n",
      "[I 2025-09-07 15:30:11,297] Trial 0 finished with value: 0.8086327929785108 and parameters: {'n_estimators': 332, 'learning_rate': 0.041210947491682415, 'max_depth': 1, 'num_leaves': 54}. Best is trial 0 with value: 0.8086327929785108.\n",
      "[I 2025-09-07 15:30:16,549] Trial 1 finished with value: 0.8088026299350325 and parameters: {'n_estimators': 789, 'learning_rate': 0.03667941585457774, 'max_depth': 2, 'num_leaves': 177}. Best is trial 1 with value: 0.8088026299350325.\n",
      "[I 2025-09-07 15:30:20,912] Trial 2 finished with value: 0.7774804004247876 and parameters: {'n_estimators': 210, 'learning_rate': 0.013738370665815904, 'max_depth': 1, 'num_leaves': 216}. Best is trial 1 with value: 0.8088026299350325.\n",
      "[I 2025-09-07 15:30:21,264] Trial 3 finished with value: 0.8153930847076462 and parameters: {'n_estimators': 623, 'learning_rate': 0.014154833653548193, 'max_depth': 2, 'num_leaves': 208}. Best is trial 3 with value: 0.8153930847076462.\n",
      "[I 2025-09-07 15:30:21,779] Trial 4 finished with value: 0.8092321026986506 and parameters: {'n_estimators': 955, 'learning_rate': 0.01919286491071217, 'max_depth': 2, 'num_leaves': 144}. Best is trial 3 with value: 0.8153930847076462.\n",
      "[I 2025-09-07 15:30:22,095] Trial 5 finished with value: 0.8140500062468766 and parameters: {'n_estimators': 572, 'learning_rate': 0.017586345638215078, 'max_depth': 2, 'num_leaves': 150}. Best is trial 3 with value: 0.8153930847076462.\n",
      "[I 2025-09-07 15:30:22,393] Trial 6 finished with value: 0.8099817278860569 and parameters: {'n_estimators': 632, 'learning_rate': 0.02680593725910695, 'max_depth': 2, 'num_leaves': 113}. Best is trial 3 with value: 0.8153930847076462.\n",
      "[I 2025-09-07 15:30:22,729] Trial 7 finished with value: 0.7994440279860071 and parameters: {'n_estimators': 731, 'learning_rate': 0.013251414198809491, 'max_depth': 1, 'num_leaves': 181}. Best is trial 3 with value: 0.8153930847076462.\n",
      "[I 2025-09-07 15:30:22,874] Trial 8 finished with value: 0.7892342891054472 and parameters: {'n_estimators': 207, 'learning_rate': 0.024531155559728887, 'max_depth': 1, 'num_leaves': 50}. Best is trial 3 with value: 0.8153930847076462.\n",
      "[I 2025-09-07 15:30:23,403] Trial 9 finished with value: 0.7953913668165917 and parameters: {'n_estimators': 760, 'learning_rate': 0.0063319239834585105, 'max_depth': 3, 'num_leaves': 145}. Best is trial 3 with value: 0.8153930847076462.\n",
      "[I 2025-09-07 15:30:23,786] Trial 10 finished with value: 0.7963791541729135 and parameters: {'n_estimators': 397, 'learning_rate': 0.06715117615452104, 'max_depth': 3, 'num_leaves': 94}. Best is trial 3 with value: 0.8153930847076462.\n",
      "[I 2025-09-07 15:30:24,066] Trial 11 finished with value: 0.8179933470764618 and parameters: {'n_estimators': 546, 'learning_rate': 0.00769649892302727, 'max_depth': 2, 'num_leaves': 216}. Best is trial 11 with value: 0.8179933470764618.\n",
      "[I 2025-09-07 15:30:24,376] Trial 12 finished with value: 0.8008476230634681 and parameters: {'n_estimators': 448, 'learning_rate': 0.006880226575858143, 'max_depth': 3, 'num_leaves': 217}. Best is trial 11 with value: 0.8179933470764618.\n",
      "[I 2025-09-07 15:30:24,719] Trial 13 finished with value: 0.8176907639930034 and parameters: {'n_estimators': 497, 'learning_rate': 0.008899596292602497, 'max_depth': 2, 'num_leaves': 191}. Best is trial 11 with value: 0.8179933470764618.\n",
      "[I 2025-09-07 15:30:25,070] Trial 14 finished with value: 0.8176224387806097 and parameters: {'n_estimators': 488, 'learning_rate': 0.008278610555189398, 'max_depth': 2, 'num_leaves': 182}. Best is trial 11 with value: 0.8179933470764618.\n",
      "[I 2025-09-07 15:30:25,354] Trial 15 finished with value: 0.8020774768865567 and parameters: {'n_estimators': 320, 'learning_rate': 0.009206368016828921, 'max_depth': 3, 'num_leaves': 191}. Best is trial 11 with value: 0.8179933470764618.\n",
      "[I 2025-09-07 15:30:25,818] Trial 16 finished with value: 0.8180616722888555 and parameters: {'n_estimators': 902, 'learning_rate': 0.0052107063237832795, 'max_depth': 2, 'num_leaves': 162}. Best is trial 16 with value: 0.8180616722888555.\n",
      "[I 2025-09-07 15:30:26,644] Trial 17 finished with value: 0.7970877842328835 and parameters: {'n_estimators': 944, 'learning_rate': 0.005477840041903634, 'max_depth': 3, 'num_leaves': 160}. Best is trial 16 with value: 0.8180616722888555.\n",
      "[I 2025-09-07 15:30:27,056] Trial 18 finished with value: 0.7841157546226887 and parameters: {'n_estimators': 860, 'learning_rate': 0.005116347942398399, 'max_depth': 1, 'num_leaves': 116}. Best is trial 16 with value: 0.8180616722888555.\n",
      "[I 2025-09-07 15:30:27,506] Trial 19 finished with value: 0.8190416510494752 and parameters: {'n_estimators': 651, 'learning_rate': 0.009660260165109838, 'max_depth': 2, 'num_leaves': 76}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:28,033] Trial 20 finished with value: 0.8160685282358822 and parameters: {'n_estimators': 869, 'learning_rate': 0.010347507033434417, 'max_depth': 2, 'num_leaves': 82}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:28,491] Trial 21 finished with value: 0.8183662075212395 and parameters: {'n_estimators': 683, 'learning_rate': 0.007190947939059858, 'max_depth': 2, 'num_leaves': 33}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:28,961] Trial 22 finished with value: 0.8182217485007496 and parameters: {'n_estimators': 681, 'learning_rate': 0.005032914876871258, 'max_depth': 2, 'num_leaves': 33}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:29,342] Trial 23 finished with value: 0.818317403798101 and parameters: {'n_estimators': 671, 'learning_rate': 0.011515382542804674, 'max_depth': 2, 'num_leaves': 33}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:29,797] Trial 24 finished with value: 0.8177590892053974 and parameters: {'n_estimators': 674, 'learning_rate': 0.011180129647363372, 'max_depth': 2, 'num_leaves': 31}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:30,111] Trial 25 finished with value: 0.7974255059970013 and parameters: {'n_estimators': 812, 'learning_rate': 0.011257977938777615, 'max_depth': 1, 'num_leaves': 69}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:30,567] Trial 26 finished with value: 0.8068251030734633 and parameters: {'n_estimators': 717, 'learning_rate': 0.018127561513801453, 'max_depth': 3, 'num_leaves': 49}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:30,876] Trial 27 finished with value: 0.8174994533983009 and parameters: {'n_estimators': 576, 'learning_rate': 0.006895900931621129, 'max_depth': 2, 'num_leaves': 69}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:31,176] Trial 28 finished with value: 0.8144716704147926 and parameters: {'n_estimators': 645, 'learning_rate': 0.01494344430544756, 'max_depth': 2, 'num_leaves': 94}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:31,334] Trial 29 finished with value: 0.8088729072963519 and parameters: {'n_estimators': 371, 'learning_rate': 0.09965026649088267, 'max_depth': 1, 'num_leaves': 60}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:31,695] Trial 30 finished with value: 0.8162227480009995 and parameters: {'n_estimators': 822, 'learning_rate': 0.01076180656772226, 'max_depth': 2, 'num_leaves': 47}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:32,062] Trial 31 finished with value: 0.8181983227136431 and parameters: {'n_estimators': 693, 'learning_rate': 0.006026727494020738, 'max_depth': 2, 'num_leaves': 37}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:32,437] Trial 32 finished with value: 0.8175619221639181 and parameters: {'n_estimators': 608, 'learning_rate': 0.007653660919587125, 'max_depth': 2, 'num_leaves': 30}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:32,795] Trial 33 finished with value: 0.8065069027986006 and parameters: {'n_estimators': 754, 'learning_rate': 0.03975993103181098, 'max_depth': 2, 'num_leaves': 60}. Best is trial 19 with value: 0.8190416510494752.\n",
      "[I 2025-09-07 15:30:33,181] Trial 34 finished with value: 0.8196897644927535 and parameters: {'n_estimators': 701, 'learning_rate': 0.009062507658059594, 'max_depth': 2, 'num_leaves': 41}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:33,291] Trial 35 finished with value: 0.8037250905797101 and parameters: {'n_estimators': 125, 'learning_rate': 0.01314190726535084, 'max_depth': 2, 'num_leaves': 42}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:33,736] Trial 36 finished with value: 0.8108445777111445 and parameters: {'n_estimators': 785, 'learning_rate': 0.016649338043002206, 'max_depth': 2, 'num_leaves': 75}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:33,997] Trial 37 finished with value: 0.7900483352073965 and parameters: {'n_estimators': 572, 'learning_rate': 0.009081790533889276, 'max_depth': 1, 'num_leaves': 87}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:34,287] Trial 38 finished with value: 0.8105732290104948 and parameters: {'n_estimators': 524, 'learning_rate': 0.022306995177138703, 'max_depth': 2, 'num_leaves': 60}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:34,619] Trial 39 finished with value: 0.8111237350074963 and parameters: {'n_estimators': 640, 'learning_rate': 0.032154595822546234, 'max_depth': 2, 'num_leaves': 42}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:35,155] Trial 40 finished with value: 0.8121329960019991 and parameters: {'n_estimators': 715, 'learning_rate': 0.01241154453961455, 'max_depth': 3, 'num_leaves': 129}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:35,499] Trial 41 finished with value: 0.8180362943528237 and parameters: {'n_estimators': 688, 'learning_rate': 0.006110075209046071, 'max_depth': 2, 'num_leaves': 30}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:35,844] Trial 42 finished with value: 0.8178469359070464 and parameters: {'n_estimators': 605, 'learning_rate': 0.007186031462124936, 'max_depth': 2, 'num_leaves': 51}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:36,193] Trial 43 finished with value: 0.8191724450274863 and parameters: {'n_estimators': 662, 'learning_rate': 0.009562851763210561, 'max_depth': 2, 'num_leaves': 37}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:36,588] Trial 44 finished with value: 0.8176556253123439 and parameters: {'n_estimators': 758, 'learning_rate': 0.00964031069065284, 'max_depth': 2, 'num_leaves': 57}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:36,966] Trial 45 finished with value: 0.8175677786106946 and parameters: {'n_estimators': 656, 'learning_rate': 0.011896961028388432, 'max_depth': 2, 'num_leaves': 42}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:37,316] Trial 46 finished with value: 0.8158928348325837 and parameters: {'n_estimators': 600, 'learning_rate': 0.014748718792244627, 'max_depth': 2, 'num_leaves': 67}. Best is trial 34 with value: 0.8196897644927535.\n",
      "[I 2025-09-07 15:30:37,685] Trial 47 finished with value: 0.8197190467266365 and parameters: {'n_estimators': 736, 'learning_rate': 0.008476825439544016, 'max_depth': 2, 'num_leaves': 43}. Best is trial 47 with value: 0.8197190467266365.\n",
      "[I 2025-09-07 15:30:38,075] Trial 48 finished with value: 0.7946964017991004 and parameters: {'n_estimators': 993, 'learning_rate': 0.008458064302127238, 'max_depth': 1, 'num_leaves': 109}. Best is trial 47 with value: 0.8197190467266365.\n",
      "[I 2025-09-07 15:30:38,527] Trial 49 finished with value: 0.8195082146426786 and parameters: {'n_estimators': 745, 'learning_rate': 0.007732282610632909, 'max_depth': 2, 'num_leaves': 78}. Best is trial 47 with value: 0.8197190467266365.\n",
      "[I 2025-09-07 15:30:38,978] Trial 50 finished with value: 0.805835363568216 and parameters: {'n_estimators': 778, 'learning_rate': 0.05722122096071233, 'max_depth': 2, 'num_leaves': 99}. Best is trial 47 with value: 0.8197190467266365.\n",
      "[I 2025-09-07 15:30:39,405] Trial 51 finished with value: 0.8202597919790104 and parameters: {'n_estimators': 731, 'learning_rate': 0.008093954841346498, 'max_depth': 2, 'num_leaves': 81}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:39,817] Trial 52 finished with value: 0.8192681003248375 and parameters: {'n_estimators': 824, 'learning_rate': 0.008059208449200909, 'max_depth': 2, 'num_leaves': 80}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:40,284] Trial 53 finished with value: 0.8180831459270363 and parameters: {'n_estimators': 842, 'learning_rate': 0.00798972734542564, 'max_depth': 2, 'num_leaves': 128}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:40,775] Trial 54 finished with value: 0.8193012868565717 and parameters: {'n_estimators': 891, 'learning_rate': 0.006188146894708756, 'max_depth': 2, 'num_leaves': 88}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:41,288] Trial 55 finished with value: 0.818891335582209 and parameters: {'n_estimators': 896, 'learning_rate': 0.005989570349331909, 'max_depth': 2, 'num_leaves': 105}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:41,771] Trial 56 finished with value: 0.8201446151924038 and parameters: {'n_estimators': 917, 'learning_rate': 0.006478612046341223, 'max_depth': 2, 'num_leaves': 90}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:42,596] Trial 57 finished with value: 0.799309329710145 and parameters: {'n_estimators': 936, 'learning_rate': 0.006612443447664434, 'max_depth': 3, 'num_leaves': 122}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:43,254] Trial 58 finished with value: 0.8182237006496752 and parameters: {'n_estimators': 901, 'learning_rate': 0.005605815809067848, 'max_depth': 2, 'num_leaves': 91}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:43,840] Trial 59 finished with value: 0.8195335925787107 and parameters: {'n_estimators': 988, 'learning_rate': 0.0065523001122931735, 'max_depth': 2, 'num_leaves': 84}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:44,533] Trial 60 finished with value: 0.8179679691404299 and parameters: {'n_estimators': 975, 'learning_rate': 0.0074516027772731025, 'max_depth': 2, 'num_leaves': 75}. Best is trial 51 with value: 0.8202597919790104.\n",
      "[I 2025-09-07 15:30:45,097] Trial 61 finished with value: 0.8202676005747126 and parameters: {'n_estimators': 933, 'learning_rate': 0.0064172914655382125, 'max_depth': 2, 'num_leaves': 101}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:45,744] Trial 62 finished with value: 0.8198596014492754 and parameters: {'n_estimators': 934, 'learning_rate': 0.006567148588082919, 'max_depth': 2, 'num_leaves': 102}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:46,384] Trial 63 finished with value: 0.8192876218140929 and parameters: {'n_estimators': 957, 'learning_rate': 0.005499518455891035, 'max_depth': 2, 'num_leaves': 104}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:46,942] Trial 64 finished with value: 0.819215392303848 and parameters: {'n_estimators': 936, 'learning_rate': 0.006799460301628394, 'max_depth': 2, 'num_leaves': 140}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:47,481] Trial 65 finished with value: 0.8169782296351823 and parameters: {'n_estimators': 923, 'learning_rate': 0.00865231301350578, 'max_depth': 2, 'num_leaves': 116}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:48,024] Trial 66 finished with value: 0.8153891804097951 and parameters: {'n_estimators': 865, 'learning_rate': 0.010364360736037677, 'max_depth': 2, 'num_leaves': 98}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:48,564] Trial 67 finished with value: 0.8190631246876562 and parameters: {'n_estimators': 983, 'learning_rate': 0.0065736143746549045, 'max_depth': 2, 'num_leaves': 84}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:49,060] Trial 68 finished with value: 0.8197502811094451 and parameters: {'n_estimators': 998, 'learning_rate': 0.005801018330255169, 'max_depth': 2, 'num_leaves': 98}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:49,518] Trial 69 finished with value: 0.8179133089705147 and parameters: {'n_estimators': 795, 'learning_rate': 0.00503806087645323, 'max_depth': 2, 'num_leaves': 121}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:49,984] Trial 70 finished with value: 0.8199064530234882 and parameters: {'n_estimators': 959, 'learning_rate': 0.005729058302742242, 'max_depth': 2, 'num_leaves': 98}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:50,522] Trial 71 finished with value: 0.8198088455772115 and parameters: {'n_estimators': 953, 'learning_rate': 0.005888357191206563, 'max_depth': 2, 'num_leaves': 101}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:51,040] Trial 72 finished with value: 0.819186110069965 and parameters: {'n_estimators': 956, 'learning_rate': 0.00564205155531417, 'max_depth': 2, 'num_leaves': 98}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:51,506] Trial 73 finished with value: 0.8194711238130935 and parameters: {'n_estimators': 929, 'learning_rate': 0.005847241631725832, 'max_depth': 2, 'num_leaves': 109}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:51,991] Trial 74 finished with value: 0.8190826461769115 and parameters: {'n_estimators': 1000, 'learning_rate': 0.00526675425220997, 'max_depth': 2, 'num_leaves': 104}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:52,517] Trial 75 finished with value: 0.8201368065967016 and parameters: {'n_estimators': 874, 'learning_rate': 0.007059740705543135, 'max_depth': 2, 'num_leaves': 93}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:52,982] Trial 76 finished with value: 0.8202168447026487 and parameters: {'n_estimators': 873, 'learning_rate': 0.007181751727114112, 'max_depth': 2, 'num_leaves': 92}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:53,431] Trial 77 finished with value: 0.819262243878061 and parameters: {'n_estimators': 851, 'learning_rate': 0.00741316273505492, 'max_depth': 2, 'num_leaves': 110}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:53,885] Trial 78 finished with value: 0.8201641366816591 and parameters: {'n_estimators': 881, 'learning_rate': 0.006982336128979242, 'max_depth': 2, 'num_leaves': 90}. Best is trial 61 with value: 0.8202676005747126.\n",
      "[I 2025-09-07 15:30:54,366] Trial 79 finished with value: 0.8206131309345327 and parameters: {'n_estimators': 876, 'learning_rate': 0.0071254706981211, 'max_depth': 2, 'num_leaves': 92}. Best is trial 79 with value: 0.8206131309345327.\n",
      "[I 2025-09-07 15:30:54,800] Trial 80 finished with value: 0.8195101667916042 and parameters: {'n_estimators': 878, 'learning_rate': 0.007466284884303844, 'max_depth': 2, 'num_leaves': 93}. Best is trial 79 with value: 0.8206131309345327.\n",
      "[I 2025-09-07 15:30:55,316] Trial 81 finished with value: 0.8200391991504249 and parameters: {'n_estimators': 915, 'learning_rate': 0.0069742262557133125, 'max_depth': 2, 'num_leaves': 88}. Best is trial 79 with value: 0.8206131309345327.\n",
      "[I 2025-09-07 15:30:55,734] Trial 82 finished with value: 0.8196175349825087 and parameters: {'n_estimators': 834, 'learning_rate': 0.006914609296906667, 'max_depth': 2, 'num_leaves': 90}. Best is trial 79 with value: 0.8206131309345327.\n",
      "[I 2025-09-07 15:30:56,214] Trial 83 finished with value: 0.8207478292103948 and parameters: {'n_estimators': 875, 'learning_rate': 0.007102410877176618, 'max_depth': 2, 'num_leaves': 74}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:30:56,648] Trial 84 finished with value: 0.8191197370064968 and parameters: {'n_estimators': 806, 'learning_rate': 0.00822196929339677, 'max_depth': 2, 'num_leaves': 69}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:30:57,087] Trial 85 finished with value: 0.8154770271114443 and parameters: {'n_estimators': 911, 'learning_rate': 0.010121877868967843, 'max_depth': 2, 'num_leaves': 73}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:30:57,507] Trial 86 finished with value: 0.820017725512244 and parameters: {'n_estimators': 877, 'learning_rate': 0.007206589532404376, 'max_depth': 2, 'num_leaves': 65}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:30:58,068] Trial 87 finished with value: 0.8192232008995503 and parameters: {'n_estimators': 850, 'learning_rate': 0.006372871521591726, 'max_depth': 2, 'num_leaves': 83}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:30:58,619] Trial 88 finished with value: 0.8168650049975014 and parameters: {'n_estimators': 887, 'learning_rate': 0.009097101946661666, 'max_depth': 2, 'num_leaves': 87}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:30:59,084] Trial 89 finished with value: 0.8186824556471765 and parameters: {'n_estimators': 829, 'learning_rate': 0.007990573293707148, 'max_depth': 2, 'num_leaves': 94}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:30:59,632] Trial 90 finished with value: 0.8105517553723138 and parameters: {'n_estimators': 912, 'learning_rate': 0.0313918793455856, 'max_depth': 2, 'num_leaves': 79}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:31:00,212] Trial 91 finished with value: 0.8203164042978511 and parameters: {'n_estimators': 884, 'learning_rate': 0.007025204990421917, 'max_depth': 2, 'num_leaves': 72}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:31:00,693] Trial 92 finished with value: 0.8196897644927535 and parameters: {'n_estimators': 775, 'learning_rate': 0.007191936637108684, 'max_depth': 2, 'num_leaves': 73}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:31:01,302] Trial 93 finished with value: 0.8201914667666168 and parameters: {'n_estimators': 866, 'learning_rate': 0.00700117169513066, 'max_depth': 2, 'num_leaves': 83}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:31:02,199] Trial 94 finished with value: 0.8191451149425287 and parameters: {'n_estimators': 863, 'learning_rate': 0.0062847195395022695, 'max_depth': 2, 'num_leaves': 82}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:31:02,791] Trial 95 finished with value: 0.8085566591704149 and parameters: {'n_estimators': 807, 'learning_rate': 0.02066793683331465, 'max_depth': 2, 'num_leaves': 71}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:31:03,257] Trial 96 finished with value: 0.8189167135182408 and parameters: {'n_estimators': 880, 'learning_rate': 0.007795388116652922, 'max_depth': 2, 'num_leaves': 64}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:31:03,699] Trial 97 finished with value: 0.8171714923788106 and parameters: {'n_estimators': 844, 'learning_rate': 0.008835707867832313, 'max_depth': 2, 'num_leaves': 78}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:31:04,167] Trial 98 finished with value: 0.8059056409295352 and parameters: {'n_estimators': 969, 'learning_rate': 0.04998275135855697, 'max_depth': 2, 'num_leaves': 94}. Best is trial 83 with value: 0.8207478292103948.\n",
      "[I 2025-09-07 15:31:04,631] Trial 99 finished with value: 0.8180323900549725 and parameters: {'n_estimators': 822, 'learning_rate': 0.005383850642535924, 'max_depth': 2, 'num_leaves': 86}. Best is trial 83 with value: 0.8207478292103948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.821\n",
      "  Params:  {'n_estimators': 875, 'learning_rate': 0.007102410877176618, 'max_depth': 2, 'num_leaves': 74}\n"
     ]
    }
   ],
   "source": [
    "def best_params_for_model(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth',1, 3),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 30, 220)\n",
    "    }\n",
    "\n",
    "    lgb_clf = LGBMClassifier(**param)\n",
    "\n",
    "    auc = cross_val_score(lgb_clf, X_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(best_params_for_model, n_trials=100)\n",
    "\n",
    "print('Best trial:')\n",
    "best_params = study.best_params\n",
    "print('  Value: {:.3f}'.format(study.best_value))\n",
    "print('  Params: ', best_params)\n",
    "\n",
    "best_lgb_model = LGBMClassifier(**best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "feb112f8-bbc7-4fe5-bc45-3e2be190a901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 15:31:08,243] A new study created in memory with name: no-name-3468bb25-1a58-4976-a76c-22e8bcd3a639\n",
      "[I 2025-09-07 15:31:08,702] Trial 0 finished with value: 0.8163281640429786 and parameters: {'n_estimators': 471, 'learning_rate': 0.0056582592987636186, 'max_depth': 2, 'subsample': 0.9988373596071604, 'colsample_bytree': 0.9332827219134441, 'gamma': 1}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:08,927] Trial 1 finished with value: 0.7911669165417292 and parameters: {'n_estimators': 279, 'learning_rate': 0.04360424207352464, 'max_depth': 1, 'subsample': 0.9866472560560013, 'colsample_bytree': 0.8056926653687853, 'gamma': 5}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:09,128] Trial 2 finished with value: 0.8015562531234384 and parameters: {'n_estimators': 198, 'learning_rate': 0.018057128101059357, 'max_depth': 2, 'subsample': 0.823018298745743, 'colsample_bytree': 0.9077573667909857, 'gamma': 5}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:09,393] Trial 3 finished with value: 0.770214502123938 and parameters: {'n_estimators': 384, 'learning_rate': 0.005633692266514143, 'max_depth': 1, 'subsample': 0.8392653032247581, 'colsample_bytree': 0.9245337448653648, 'gamma': 1}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:09,709] Trial 4 finished with value: 0.8040764773863068 and parameters: {'n_estimators': 421, 'learning_rate': 0.005328961842081407, 'max_depth': 2, 'subsample': 0.7115738525991564, 'colsample_bytree': 0.9285835832971824, 'gamma': 1}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:09,914] Trial 5 finished with value: 0.8072506715392304 and parameters: {'n_estimators': 277, 'learning_rate': 0.019618017564382476, 'max_depth': 2, 'subsample': 0.7924094771463991, 'colsample_bytree': 0.8035890263999343, 'gamma': 5}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:10,044] Trial 6 finished with value: 0.8111256871564217 and parameters: {'n_estimators': 116, 'learning_rate': 0.066282761130872, 'max_depth': 3, 'subsample': 0.7999935713614891, 'colsample_bytree': 0.649859830683306, 'gamma': 0}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:10,257] Trial 7 finished with value: 0.7875710582208896 and parameters: {'n_estimators': 318, 'learning_rate': 0.013345095170991068, 'max_depth': 1, 'subsample': 0.6049582674081853, 'colsample_bytree': 0.8144066878397785, 'gamma': 3}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:10,542] Trial 8 finished with value: 0.8056167228885558 and parameters: {'n_estimators': 463, 'learning_rate': 0.06639622256928997, 'max_depth': 3, 'subsample': 0.9427982926952378, 'colsample_bytree': 0.8839107452840952, 'gamma': 3}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:10,890] Trial 9 finished with value: 0.8100422445027485 and parameters: {'n_estimators': 485, 'learning_rate': 0.0066025053574862574, 'max_depth': 3, 'subsample': 0.9483424092454569, 'colsample_bytree': 0.7766917335088973, 'gamma': 3}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:11,171] Trial 10 finished with value: 0.8139972982258871 and parameters: {'n_estimators': 363, 'learning_rate': 0.012086534538721142, 'max_depth': 2, 'subsample': 0.8896562998787183, 'colsample_bytree': 0.9981914618016151, 'gamma': 1}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:11,466] Trial 11 finished with value: 0.8147762056471765 and parameters: {'n_estimators': 381, 'learning_rate': 0.01063086840668054, 'max_depth': 2, 'subsample': 0.9028446133841984, 'colsample_bytree': 0.9999139072708869, 'gamma': 1}. Best is trial 0 with value: 0.8163281640429786.\n",
      "[I 2025-09-07 15:31:11,857] Trial 12 finished with value: 0.8171285451024488 and parameters: {'n_estimators': 497, 'learning_rate': 0.009782721815780028, 'max_depth': 2, 'subsample': 0.9061155502924217, 'colsample_bytree': 0.9876598527489537, 'gamma': 0}. Best is trial 12 with value: 0.8171285451024488.\n",
      "[I 2025-09-07 15:31:12,230] Trial 13 finished with value: 0.8179172132683658 and parameters: {'n_estimators': 500, 'learning_rate': 0.008484801964789292, 'max_depth': 2, 'subsample': 0.9822782574399952, 'colsample_bytree': 0.9611312668138258, 'gamma': 0}. Best is trial 13 with value: 0.8179172132683658.\n",
      "[I 2025-09-07 15:31:12,551] Trial 14 finished with value: 0.7921195652173912 and parameters: {'n_estimators': 500, 'learning_rate': 0.00889734304116385, 'max_depth': 1, 'subsample': 0.8914429327114568, 'colsample_bytree': 0.6933194303676856, 'gamma': 0}. Best is trial 13 with value: 0.8179172132683658.\n",
      "[I 2025-09-07 15:31:12,919] Trial 15 finished with value: 0.8090993565717142 and parameters: {'n_estimators': 418, 'learning_rate': 0.03693025869463425, 'max_depth': 3, 'subsample': 0.7284270957865453, 'colsample_bytree': 0.8748586131717149, 'gamma': 0}. Best is trial 13 with value: 0.8179172132683658.\n",
      "[I 2025-09-07 15:31:13,209] Trial 16 finished with value: 0.8208942403798102 and parameters: {'n_estimators': 438, 'learning_rate': 0.02841816432632205, 'max_depth': 2, 'subsample': 0.9405394511364399, 'colsample_bytree': 0.9678566591203742, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:13,483] Trial 17 finished with value: 0.8046230790854573 and parameters: {'n_estimators': 416, 'learning_rate': 0.03149518163223491, 'max_depth': 1, 'subsample': 0.9575019543677626, 'colsample_bytree': 0.7530845165139766, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:13,736] Trial 18 finished with value: 0.8071921070714643 and parameters: {'n_estimators': 334, 'learning_rate': 0.024629516923960967, 'max_depth': 2, 'subsample': 0.8589972600833597, 'colsample_bytree': 0.8500066355776359, 'gamma': 4}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:13,942] Trial 19 finished with value: 0.8129079991254372 and parameters: {'n_estimators': 226, 'learning_rate': 0.09819733863201216, 'max_depth': 3, 'subsample': 0.7644300050519901, 'colsample_bytree': 0.9567729214137094, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:14,323] Trial 20 finished with value: 0.8144287231384307 and parameters: {'n_estimators': 447, 'learning_rate': 0.015202716396819903, 'max_depth': 2, 'subsample': 0.666717242642308, 'colsample_bytree': 0.7284429550992938, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:14,702] Trial 21 finished with value: 0.8130466016991503 and parameters: {'n_estimators': 443, 'learning_rate': 0.008290683136887167, 'max_depth': 2, 'subsample': 0.9176589766945119, 'colsample_bytree': 0.9656179529071999, 'gamma': 0}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:15,101] Trial 22 finished with value: 0.8174194152923538 and parameters: {'n_estimators': 493, 'learning_rate': 0.025778550994101805, 'max_depth': 2, 'subsample': 0.9690262261876624, 'colsample_bytree': 0.9659826382704926, 'gamma': 0}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:15,428] Trial 23 finished with value: 0.8088787637431286 and parameters: {'n_estimators': 441, 'learning_rate': 0.02518254373759202, 'max_depth': 2, 'subsample': 0.9704051500044241, 'colsample_bytree': 0.9572012363133253, 'gamma': 4}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:15,759] Trial 24 finished with value: 0.8190592203898049 and parameters: {'n_estimators': 406, 'learning_rate': 0.030912176729324673, 'max_depth': 2, 'subsample': 0.9396589569897406, 'colsample_bytree': 0.8443371999365693, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:16,070] Trial 25 finished with value: 0.810167182033983 and parameters: {'n_estimators': 392, 'learning_rate': 0.047017616438346094, 'max_depth': 3, 'subsample': 0.866801982047896, 'colsample_bytree': 0.8414147241349476, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:16,359] Trial 26 finished with value: 0.798946230009995 and parameters: {'n_estimators': 359, 'learning_rate': 0.030157174057258682, 'max_depth': 1, 'subsample': 0.9325249993233474, 'colsample_bytree': 0.8928489482999014, 'gamma': 4}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:16,697] Trial 27 finished with value: 0.8208532452523739 and parameters: {'n_estimators': 401, 'learning_rate': 0.01781946279899159, 'max_depth': 2, 'subsample': 0.9924048694127026, 'colsample_bytree': 0.857467641151737, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:16,973] Trial 28 finished with value: 0.8159962987256373 and parameters: {'n_estimators': 344, 'learning_rate': 0.018148459428758375, 'max_depth': 2, 'subsample': 0.8674441815791774, 'colsample_bytree': 0.8468344883447859, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:17,193] Trial 29 finished with value: 0.8001741316841579 and parameters: {'n_estimators': 300, 'learning_rate': 0.046582255365522546, 'max_depth': 1, 'subsample': 0.9905792820020165, 'colsample_bytree': 0.7710592049548147, 'gamma': 3}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:17,538] Trial 30 finished with value: 0.8108172476261869 and parameters: {'n_estimators': 399, 'learning_rate': 0.020810358723318566, 'max_depth': 3, 'subsample': 0.9282132188875446, 'colsample_bytree': 0.8699956690622814, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:17,896] Trial 31 finished with value: 0.8198635057471265 and parameters: {'n_estimators': 464, 'learning_rate': 0.015581754701025937, 'max_depth': 2, 'subsample': 0.9669405867819845, 'colsample_bytree': 0.9199323337284862, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:18,256] Trial 32 finished with value: 0.8165468047226386 and parameters: {'n_estimators': 465, 'learning_rate': 0.015744911370539655, 'max_depth': 2, 'subsample': 0.9976559137328943, 'colsample_bytree': 0.9093106619066887, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:18,540] Trial 33 finished with value: 0.8203632558720639 and parameters: {'n_estimators': 433, 'learning_rate': 0.03670353016339492, 'max_depth': 2, 'subsample': 0.9569451029429168, 'colsample_bytree': 0.8317025289969111, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:18,849] Trial 34 finished with value: 0.8178547445027485 and parameters: {'n_estimators': 436, 'learning_rate': 0.039497031421623384, 'max_depth': 2, 'subsample': 0.9588673341079106, 'colsample_bytree': 0.8198879644706463, 'gamma': 3}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:19,198] Trial 35 finished with value: 0.8184579585207397 and parameters: {'n_estimators': 450, 'learning_rate': 0.015740216100785565, 'max_depth': 2, 'subsample': 0.9776980086734738, 'colsample_bytree': 0.922789567862101, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:19,540] Trial 36 finished with value: 0.8167205459770114 and parameters: {'n_estimators': 468, 'learning_rate': 0.05697800622239706, 'max_depth': 2, 'subsample': 0.8313244992911109, 'colsample_bytree': 0.6012601922181189, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:19,820] Trial 37 finished with value: 0.804607461894053 and parameters: {'n_estimators': 371, 'learning_rate': 0.022061264042570833, 'max_depth': 2, 'subsample': 0.9989929703823691, 'colsample_bytree': 0.9029030451277871, 'gamma': 3}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:20,052] Trial 38 finished with value: 0.8192700524737632 and parameters: {'n_estimators': 261, 'learning_rate': 0.034708704124496816, 'max_depth': 2, 'subsample': 0.9180486697646143, 'colsample_bytree': 0.9283155263861572, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:20,164] Trial 39 finished with value: 0.7562878716891553 and parameters: {'n_estimators': 107, 'learning_rate': 0.013528615424163469, 'max_depth': 1, 'subsample': 0.95872015880829, 'colsample_bytree': 0.9424862111418543, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:20,492] Trial 40 finished with value: 0.8184599106696652 and parameters: {'n_estimators': 427, 'learning_rate': 0.018377650482761933, 'max_depth': 2, 'subsample': 0.8773568390437195, 'colsample_bytree': 0.8677740154813641, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:20,740] Trial 41 finished with value: 0.8197951805347327 and parameters: {'n_estimators': 263, 'learning_rate': 0.03463185990900857, 'max_depth': 2, 'subsample': 0.9176439644060727, 'colsample_bytree': 0.930933174533172, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:20,962] Trial 42 finished with value: 0.8195589705147427 and parameters: {'n_estimators': 267, 'learning_rate': 0.027114058864027308, 'max_depth': 2, 'subsample': 0.9409966328031001, 'colsample_bytree': 0.8220823616337909, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:21,118] Trial 43 finished with value: 0.8185379966266867 and parameters: {'n_estimators': 166, 'learning_rate': 0.04444190348359486, 'max_depth': 2, 'subsample': 0.9225382828187575, 'colsample_bytree': 0.9033519877446251, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:21,337] Trial 44 finished with value: 0.8183525424787605 and parameters: {'n_estimators': 303, 'learning_rate': 0.0561564781494983, 'max_depth': 2, 'subsample': 0.9758851769734997, 'colsample_bytree': 0.9395450946375413, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:21,533] Trial 45 finished with value: 0.8112994284107945 and parameters: {'n_estimators': 240, 'learning_rate': 0.023418282000162313, 'max_depth': 2, 'subsample': 0.9528620651552283, 'colsample_bytree': 0.7900332407590099, 'gamma': 3}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:21,917] Trial 46 finished with value: 0.8187605416041978 and parameters: {'n_estimators': 476, 'learning_rate': 0.01174492639270056, 'max_depth': 2, 'subsample': 0.8854524097694085, 'colsample_bytree': 0.9792664676346718, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:22,051] Trial 47 finished with value: 0.8099719671414293 and parameters: {'n_estimators': 156, 'learning_rate': 0.04006334284897735, 'max_depth': 2, 'subsample': 0.8494356637134166, 'colsample_bytree': 0.9180048282856031, 'gamma': 3}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:22,264] Trial 48 finished with value: 0.8143662543728136 and parameters: {'n_estimators': 215, 'learning_rate': 0.028364364539510502, 'max_depth': 2, 'subsample': 0.8096370198055283, 'colsample_bytree': 0.8927862712744032, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:22,581] Trial 49 finished with value: 0.8190162731134434 and parameters: {'n_estimators': 458, 'learning_rate': 0.035195756349268414, 'max_depth': 2, 'subsample': 0.9036912369930793, 'colsample_bytree': 0.9446829567518762, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:22,832] Trial 50 finished with value: 0.8062589798850573 and parameters: {'n_estimators': 333, 'learning_rate': 0.020084646737132745, 'max_depth': 3, 'subsample': 0.9831899705252675, 'colsample_bytree': 0.8584689827818076, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:23,072] Trial 51 finished with value: 0.8198264149175413 and parameters: {'n_estimators': 275, 'learning_rate': 0.02822687610986368, 'max_depth': 2, 'subsample': 0.9476301268325338, 'colsample_bytree': 0.824740985853032, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:23,322] Trial 52 finished with value: 0.8201582802348826 and parameters: {'n_estimators': 279, 'learning_rate': 0.0222437992651042, 'max_depth': 2, 'subsample': 0.9468823766600101, 'colsample_bytree': 0.8297575719871895, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:23,570] Trial 53 finished with value: 0.8153481852823589 and parameters: {'n_estimators': 284, 'learning_rate': 0.01672243349594201, 'max_depth': 2, 'subsample': 0.9459977102823739, 'colsample_bytree': 0.8315390320061237, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:23,830] Trial 54 finished with value: 0.8164413886806597 and parameters: {'n_estimators': 316, 'learning_rate': 0.013929181385366656, 'max_depth': 2, 'subsample': 0.9584214615168376, 'colsample_bytree': 0.7986118461304317, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:24,039] Trial 55 finished with value: 0.8117249968765617 and parameters: {'n_estimators': 246, 'learning_rate': 0.022399889289045908, 'max_depth': 2, 'subsample': 0.7768053486138784, 'colsample_bytree': 0.7480259095871757, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:24,374] Trial 56 finished with value: 0.8147840142428785 and parameters: {'n_estimators': 413, 'learning_rate': 0.01948602704089328, 'max_depth': 2, 'subsample': 0.67676674054057, 'colsample_bytree': 0.8054389706660416, 'gamma': 2}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:24,705] Trial 57 finished with value: 0.8173628029735132 and parameters: {'n_estimators': 482, 'learning_rate': 0.02794615547963884, 'max_depth': 2, 'subsample': 0.9690363028549694, 'colsample_bytree': 0.7791103067180967, 'gamma': 3}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:24,998] Trial 58 finished with value: 0.813811844077961 and parameters: {'n_estimators': 383, 'learning_rate': 0.011061808636630286, 'max_depth': 2, 'subsample': 0.9050686640629637, 'colsample_bytree': 0.8327042524872773, 'gamma': 1}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:25,356] Trial 59 finished with value: 0.8176731946526736 and parameters: {'n_estimators': 430, 'learning_rate': 0.03218572533309555, 'max_depth': 2, 'subsample': 0.6080960455241888, 'colsample_bytree': 0.855962505471585, 'gamma': 0}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:25,587] Trial 60 finished with value: 0.8027607290104948 and parameters: {'n_estimators': 305, 'learning_rate': 0.025312460210062008, 'max_depth': 2, 'subsample': 0.9865260475723194, 'colsample_bytree': 0.9816590980320659, 'gamma': 5}. Best is trial 16 with value: 0.8208942403798102.\n",
      "[I 2025-09-07 15:31:25,827] Trial 61 finished with value: 0.8216223919290355 and parameters: {'n_estimators': 280, 'learning_rate': 0.033897107080338114, 'max_depth': 2, 'subsample': 0.934203081558376, 'colsample_bytree': 0.8801534718497721, 'gamma': 1}. Best is trial 61 with value: 0.8216223919290355.\n",
      "[I 2025-09-07 15:31:26,044] Trial 62 finished with value: 0.8196624344077961 and parameters: {'n_estimators': 280, 'learning_rate': 0.03858403312779356, 'max_depth': 2, 'subsample': 0.9465868326987262, 'colsample_bytree': 0.8812191799438589, 'gamma': 2}. Best is trial 61 with value: 0.8216223919290355.\n",
      "[I 2025-09-07 15:31:26,274] Trial 63 finished with value: 0.8152720514742628 and parameters: {'n_estimators': 243, 'learning_rate': 0.04967668454456869, 'max_depth': 2, 'subsample': 0.9362732511163555, 'colsample_bytree': 0.832279060144566, 'gamma': 1}. Best is trial 61 with value: 0.8216223919290355.\n",
      "[I 2025-09-07 15:31:26,470] Trial 64 finished with value: 0.8190514117941029 and parameters: {'n_estimators': 203, 'learning_rate': 0.01761707134754459, 'max_depth': 2, 'subsample': 0.968878765328188, 'colsample_bytree': 0.8651322730485635, 'gamma': 0}. Best is trial 61 with value: 0.8216223919290355.\n",
      "[I 2025-09-07 15:31:26,732] Trial 65 finished with value: 0.8221670414792603 and parameters: {'n_estimators': 350, 'learning_rate': 0.03204230453768705, 'max_depth': 2, 'subsample': 0.9252598698328814, 'colsample_bytree': 0.8918315720920318, 'gamma': 2}. Best is trial 65 with value: 0.8221670414792603.\n",
      "[I 2025-09-07 15:31:27,008] Trial 66 finished with value: 0.8070886431784109 and parameters: {'n_estimators': 345, 'learning_rate': 0.006595038754608407, 'max_depth': 2, 'subsample': 0.9283327232500939, 'colsample_bytree': 0.8900292393909446, 'gamma': 2}. Best is trial 65 with value: 0.8221670414792603.\n",
      "[I 2025-09-07 15:31:27,314] Trial 67 finished with value: 0.8071393990504747 and parameters: {'n_estimators': 408, 'learning_rate': 0.03224071402050866, 'max_depth': 1, 'subsample': 0.8916142995953493, 'colsample_bytree': 0.8784290569990255, 'gamma': 2}. Best is trial 65 with value: 0.8221670414792603.\n",
      "[I 2025-09-07 15:31:27,598] Trial 68 finished with value: 0.8176478167166416 and parameters: {'n_estimators': 392, 'learning_rate': 0.022059177460301477, 'max_depth': 2, 'subsample': 0.9105163957861374, 'colsample_bytree': 0.9095631647434921, 'gamma': 3}. Best is trial 65 with value: 0.8221670414792603.\n",
      "[I 2025-09-07 15:31:27,851] Trial 69 finished with value: 0.8231723981759119 and parameters: {'n_estimators': 368, 'learning_rate': 0.05102926838605229, 'max_depth': 2, 'subsample': 0.9656635766191839, 'colsample_bytree': 0.8450852900521333, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:28,116] Trial 70 finished with value: 0.8162383651924038 and parameters: {'n_estimators': 366, 'learning_rate': 0.09516100611960354, 'max_depth': 2, 'subsample': 0.9904093884880524, 'colsample_bytree': 0.8422188811067037, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:28,366] Trial 71 finished with value: 0.8218195589705148 and parameters: {'n_estimators': 349, 'learning_rate': 0.06905278054373633, 'max_depth': 2, 'subsample': 0.9697251792768734, 'colsample_bytree': 0.8146848001305946, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:28,623] Trial 72 finished with value: 0.8170836456771614 and parameters: {'n_estimators': 354, 'learning_rate': 0.06986483195394055, 'max_depth': 2, 'subsample': 0.9342078254068632, 'colsample_bytree': 0.8161661298359607, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:28,864] Trial 73 finished with value: 0.8220733383308346 and parameters: {'n_estimators': 333, 'learning_rate': 0.052679908915795375, 'max_depth': 2, 'subsample': 0.9605068743484348, 'colsample_bytree': 0.7875298432111387, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:29,111] Trial 74 finished with value: 0.8204589111694154 and parameters: {'n_estimators': 326, 'learning_rate': 0.07541252245442218, 'max_depth': 2, 'subsample': 0.9804739999720948, 'colsample_bytree': 0.7921689429478401, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:29,352] Trial 75 finished with value: 0.8137923225887057 and parameters: {'n_estimators': 330, 'learning_rate': 0.07796447202477125, 'max_depth': 2, 'subsample': 0.9957560435157632, 'colsample_bytree': 0.7550001200166743, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:29,611] Trial 76 finished with value: 0.8135639211644179 and parameters: {'n_estimators': 373, 'learning_rate': 0.057548130395151484, 'max_depth': 2, 'subsample': 0.9808870803253615, 'colsample_bytree': 0.7898586254031857, 'gamma': 3}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:29,840] Trial 77 finished with value: 0.8228132027736134 and parameters: {'n_estimators': 320, 'learning_rate': 0.08044564778476372, 'max_depth': 2, 'subsample': 0.9641243116943256, 'colsample_bytree': 0.7656688266949201, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:30,112] Trial 78 finished with value: 0.8181143803098451 and parameters: {'n_estimators': 318, 'learning_rate': 0.08566028787868475, 'max_depth': 2, 'subsample': 0.9633202630488844, 'colsample_bytree': 0.7212719458930983, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:30,408] Trial 79 finished with value: 0.8202676005747126 and parameters: {'n_estimators': 346, 'learning_rate': 0.06462142115015888, 'max_depth': 2, 'subsample': 0.7279309257630799, 'colsample_bytree': 0.7654523777395542, 'gamma': 3}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:30,672] Trial 80 finished with value: 0.8145341391804098 and parameters: {'n_estimators': 295, 'learning_rate': 0.06313511593689919, 'max_depth': 2, 'subsample': 0.9278728800220221, 'colsample_bytree': 0.8091403932142779, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:30,922] Trial 81 finished with value: 0.8230337956021989 and parameters: {'n_estimators': 317, 'learning_rate': 0.07677702186734477, 'max_depth': 2, 'subsample': 0.9757376925356573, 'colsample_bytree': 0.7842676854807649, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:31,213] Trial 82 finished with value: 0.8194145114942529 and parameters: {'n_estimators': 353, 'learning_rate': 0.08236329577679508, 'max_depth': 2, 'subsample': 0.9739695025687137, 'colsample_bytree': 0.7399833443559696, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:31,458] Trial 83 finished with value: 0.8199435438530734 and parameters: {'n_estimators': 313, 'learning_rate': 0.08675502744751556, 'max_depth': 2, 'subsample': 0.9622754024546251, 'colsample_bytree': 0.7792851766631692, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:31,778] Trial 84 finished with value: 0.8189147613693152 and parameters: {'n_estimators': 391, 'learning_rate': 0.052187826263450934, 'max_depth': 2, 'subsample': 0.9875986922607618, 'colsample_bytree': 0.8532311403459046, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:32,036] Trial 85 finished with value: 0.8195062624937531 and parameters: {'n_estimators': 291, 'learning_rate': 0.06980549780614233, 'max_depth': 2, 'subsample': 0.9537977664589902, 'colsample_bytree': 0.7159689233918555, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:32,296] Trial 86 finished with value: 0.8181241410544727 and parameters: {'n_estimators': 340, 'learning_rate': 0.05976514740758917, 'max_depth': 2, 'subsample': 0.9982740424863049, 'colsample_bytree': 0.7687188444128372, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:32,608] Trial 87 finished with value: 0.8145575649675162 and parameters: {'n_estimators': 374, 'learning_rate': 0.04261704740108258, 'max_depth': 2, 'subsample': 0.9132069910740266, 'colsample_bytree': 0.759606270474884, 'gamma': 3}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:32,915] Trial 88 finished with value: 0.8208864317841079 and parameters: {'n_estimators': 361, 'learning_rate': 0.05139974950095891, 'max_depth': 2, 'subsample': 0.9745105880820072, 'colsample_bytree': 0.7971288692376163, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:33,199] Trial 89 finished with value: 0.8207985850824587 and parameters: {'n_estimators': 357, 'learning_rate': 0.05122957432343379, 'max_depth': 2, 'subsample': 0.9335258786572774, 'colsample_bytree': 0.7968092344490058, 'gamma': 2}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:33,421] Trial 90 finished with value: 0.810745018115942 and parameters: {'n_estimators': 322, 'learning_rate': 0.07111880481416948, 'max_depth': 2, 'subsample': 0.9428069506423906, 'colsample_bytree': 0.7829196244959906, 'gamma': 4}. Best is trial 69 with value: 0.8231723981759119.\n",
      "[I 2025-09-07 15:31:33,639] Trial 91 finished with value: 0.8235491629185407 and parameters: {'n_estimators': 306, 'learning_rate': 0.04793111022955771, 'max_depth': 2, 'subsample': 0.9639463529879456, 'colsample_bytree': 0.8155118033358583, 'gamma': 2}. Best is trial 91 with value: 0.8235491629185407.\n",
      "[I 2025-09-07 15:31:33,870] Trial 92 finished with value: 0.8198459364067966 and parameters: {'n_estimators': 308, 'learning_rate': 0.05457135843851844, 'max_depth': 2, 'subsample': 0.9716698522102146, 'colsample_bytree': 0.8120587321264418, 'gamma': 2}. Best is trial 91 with value: 0.8235491629185407.\n",
      "[I 2025-09-07 15:31:34,111] Trial 93 finished with value: 0.8210699337831086 and parameters: {'n_estimators': 334, 'learning_rate': 0.04680565028190561, 'max_depth': 2, 'subsample': 0.954017947545068, 'colsample_bytree': 0.8019448597281227, 'gamma': 2}. Best is trial 91 with value: 0.8235491629185407.\n",
      "[I 2025-09-07 15:31:34,365] Trial 94 finished with value: 0.8195472576211894 and parameters: {'n_estimators': 339, 'learning_rate': 0.04169254339664883, 'max_depth': 2, 'subsample': 0.9550416751188803, 'colsample_bytree': 0.8114387506093119, 'gamma': 2}. Best is trial 91 with value: 0.8235491629185407.\n",
      "[I 2025-09-07 15:31:34,614] Trial 95 finished with value: 0.8181495189905048 and parameters: {'n_estimators': 328, 'learning_rate': 0.04613142996716451, 'max_depth': 2, 'subsample': 0.8962623389505937, 'colsample_bytree': 0.8420709538948375, 'gamma': 2}. Best is trial 91 with value: 0.8235491629185407.\n",
      "[I 2025-09-07 15:31:34,833] Trial 96 finished with value: 0.8173374250374813 and parameters: {'n_estimators': 293, 'learning_rate': 0.06146957732721153, 'max_depth': 2, 'subsample': 0.9382524880395231, 'colsample_bytree': 0.785540914965921, 'gamma': 2}. Best is trial 91 with value: 0.8235491629185407.\n",
      "[I 2025-09-07 15:31:35,033] Trial 97 finished with value: 0.8163652548725638 and parameters: {'n_estimators': 254, 'learning_rate': 0.0955856908616689, 'max_depth': 2, 'subsample': 0.9233382851592459, 'colsample_bytree': 0.7434174795043627, 'gamma': 2}. Best is trial 91 with value: 0.8235491629185407.\n",
      "[I 2025-09-07 15:31:35,286] Trial 98 finished with value: 0.8234925505997001 and parameters: {'n_estimators': 310, 'learning_rate': 0.04654606907910136, 'max_depth': 2, 'subsample': 0.9631603812753642, 'colsample_bytree': 0.8017638915508324, 'gamma': 2}. Best is trial 91 with value: 0.8235491629185407.\n",
      "[I 2025-09-07 15:31:35,524] Trial 99 finished with value: 0.8147898706896552 and parameters: {'n_estimators': 311, 'learning_rate': 0.048303075122188184, 'max_depth': 2, 'subsample': 0.9633783273728671, 'colsample_bytree': 0.7716436976559344, 'gamma': 3}. Best is trial 91 with value: 0.8235491629185407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.824\n",
      "  Params:  {'n_estimators': 306, 'learning_rate': 0.04793111022955771, 'max_depth': 2, 'subsample': 0.9639463529879456, 'colsample_bytree': 0.8155118033358583, 'gamma': 2}\n"
     ]
    }
   ],
   "source": [
    "def best_params_for_model(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_int('gamma', 0.1, 5),\n",
    "            }\n",
    "\n",
    "    xgb_clf = XGBClassifier(**param)\n",
    "    auc = cross_val_score(xgb_clf, X_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(best_params_for_model, n_trials=100)\n",
    "\n",
    "print('Best trial:')\n",
    "best_params = study.best_params\n",
    "print('  Value: {:.3f}'.format(study.best_value))\n",
    "print('  Params: ', best_params)\n",
    "\n",
    "best_xgb_model = XGBClassifier(**best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "ee1d30cf-7008-42cb-a773-3f9273f03486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 15:36:23,413] A new study created in memory with name: no-name-e31186f6-92fb-41f0-91ff-2f9336c06d6b\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\915533000.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\915533000.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.1, 10), # Regularization term that prevents overfitting by penalizing large parameter values.\n",
      "[I 2025-09-07 15:36:23,673] Trial 0 finished with value: 0.7929108362485424 and parameters: {'iterations': 155, 'learning_rate': 0.011930076676187189, 'depth': 4, 'l2_leaf_reg': 0.4289693207742859, 'loss_function': 'Logloss'}. Best is trial 0 with value: 0.7929108362485424.\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\915533000.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\915533000.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.1, 10), # Regularization term that prevents overfitting by penalizing large parameter values.\n",
      "[I 2025-09-07 15:36:23,920] Trial 1 finished with value: 0.8033613401632518 and parameters: {'iterations': 180, 'learning_rate': 0.06642537661121779, 'depth': 3, 'l2_leaf_reg': 2.676111206448673, 'loss_function': 'Logloss'}. Best is trial 1 with value: 0.8033613401632518.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.803\n",
      "  Params:  {'iterations': 180, 'learning_rate': 0.06642537661121779, 'depth': 3, 'l2_leaf_reg': 2.676111206448673, 'loss_function': 'Logloss'}\n"
     ]
    }
   ],
   "source": [
    "def best_params_for_model(trial):\n",
    "\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 400),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'depth': trial.suggest_int('depth', 3, 5),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.1, 10), # Regularization term that prevents overfitting by penalizing large parameter values.\n",
    "        # 'cat_features': [],  # Handle categorical features separately\n",
    "        'loss_function': trial.suggest_categorical('loss_function', ['Logloss']) # For regression tasks, use ‘RMSE,’ while for classification, use ‘Logloss’.\n",
    "    }\n",
    "\n",
    "    cb_clf = CatBoostClassifier(**param)\n",
    "\n",
    "    auc = cross_val_score(cb_clf, X_train, y_train, cv=2, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    return auc\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(best_params_for_model, n_trials=2)\n",
    "\n",
    "print('Best trial:')\n",
    "best_params = study.best_params\n",
    "print('  Value: {:.3f}'.format(study.best_value))\n",
    "print('  Params: ', best_params)\n",
    "\n",
    "best_cb_model = CatBoostClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "8b698cf4-2453-4b8a-9090-bc9a8f910457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 15:31:51,395] A new study created in memory with name: no-name-142036f4-f9e5-4372-9240-85ae314570e5\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\1892126152.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\1892126152.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.2, 10),\n",
      "[I 2025-09-07 15:32:15,155] Trial 0 finished with value: 0.7622022322172247 and parameters: {'iterations': 775, 'learning_rate': 0.037311246633832895, 'depth': 5, 'l2_leaf_reg': 0.8077949981177832, 'loss_function': 'Logloss'}. Best is trial 0 with value: 0.7622022322172247.\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\1892126152.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\1892126152.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.2, 10),\n",
      "[I 2025-09-07 15:32:34,565] Trial 1 finished with value: 0.7680092245543895 and parameters: {'iterations': 834, 'learning_rate': 0.011242334158440845, 'depth': 4, 'l2_leaf_reg': 0.33022375619167543, 'loss_function': 'Logloss'}. Best is trial 1 with value: 0.7680092245543895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.768\n",
      "  Params:  {'iterations': 834, 'learning_rate': 0.011242334158440845, 'depth': 4, 'l2_leaf_reg': 0.33022375619167543, 'loss_function': 'Logloss'}\n"
     ]
    }
   ],
   "source": [
    "def best_params_for_model(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 300, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
    "        'depth': trial.suggest_int('depth', 4, 6),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.2, 10),\n",
    "        'cat_features': cols,\n",
    "        'loss_function': trial.suggest_categorical('loss_function', ['Logloss'])\n",
    "    }\n",
    "\n",
    "    cb__customer_clf = CatBoostClassifier(**param, verbose=0)\n",
    "    auc = cross_val_score(cb__customer_clf, X_train_cat, y_train_cat, cv=2, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(best_params_for_model, n_trials=2)\n",
    "\n",
    "print('Best trial:')\n",
    "best_params = study.best_params\n",
    "print('  Value: {:.3f}'.format(study.best_value))\n",
    "print('  Params: ', best_params)\n",
    "\n",
    "best_cb_custom_model = CatBoostClassifier(**best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "d092cdd2-cf26-42dd-84e6-9d1e2d38b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 15:32:40,340] A new study created in memory with name: no-name-326e5740-ad6c-4252-82ae-f4be95c701c3\n",
      "[I 2025-09-07 15:32:41,772] Trial 0 finished with value: 0.7851679628935532 and parameters: {'n_estimators': 165, 'max_features': 'sqrt', 'max_depth': 21, 'min_samples_split': 42}. Best is trial 0 with value: 0.7851679628935532.\n",
      "[I 2025-09-07 15:32:43,171] Trial 1 finished with value: 0.7953796539230384 and parameters: {'n_estimators': 180, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 30}. Best is trial 1 with value: 0.7953796539230384.\n",
      "[I 2025-09-07 15:32:45,168] Trial 2 finished with value: 0.7861986975262368 and parameters: {'n_estimators': 289, 'max_features': 'sqrt', 'max_depth': 23, 'min_samples_split': 26}. Best is trial 1 with value: 0.7953796539230384.\n",
      "[I 2025-09-07 15:32:46,369] Trial 3 finished with value: 0.7899800099950025 and parameters: {'n_estimators': 206, 'max_features': 'sqrt', 'max_depth': 29, 'min_samples_split': 31}. Best is trial 1 with value: 0.7953796539230384.\n",
      "[I 2025-09-07 15:32:47,541] Trial 4 finished with value: 0.7823353948025987 and parameters: {'n_estimators': 204, 'max_features': 'sqrt', 'max_depth': 22, 'min_samples_split': 50}. Best is trial 1 with value: 0.7953796539230384.\n",
      "[I 2025-09-07 15:32:49,230] Trial 5 finished with value: 0.7969647988505746 and parameters: {'n_estimators': 295, 'max_features': 'sqrt', 'max_depth': 27, 'min_samples_split': 30}. Best is trial 5 with value: 0.7969647988505746.\n",
      "[I 2025-09-07 15:32:51,779] Trial 6 finished with value: 0.79674811031984 and parameters: {'n_estimators': 428, 'max_features': 'sqrt', 'max_depth': 23, 'min_samples_split': 18}. Best is trial 5 with value: 0.7969647988505746.\n",
      "[I 2025-09-07 15:32:53,593] Trial 7 finished with value: 0.7647816716641679 and parameters: {'n_estimators': 300, 'max_features': 'log2', 'max_depth': 27, 'min_samples_split': 4}. Best is trial 5 with value: 0.7969647988505746.\n",
      "[I 2025-09-07 15:32:54,987] Trial 8 finished with value: 0.7927286356821589 and parameters: {'n_estimators': 239, 'max_features': 'log2', 'max_depth': 28, 'min_samples_split': 4}. Best is trial 5 with value: 0.7969647988505746.\n",
      "[I 2025-09-07 15:32:57,342] Trial 9 finished with value: 0.7841645583458271 and parameters: {'n_estimators': 412, 'max_features': 'sqrt', 'max_depth': 22, 'min_samples_split': 50}. Best is trial 5 with value: 0.7969647988505746.\n",
      "[I 2025-09-07 15:32:58,028] Trial 10 finished with value: 0.8096420539730135 and parameters: {'n_estimators': 107, 'max_features': 'log2', 'max_depth': 26, 'min_samples_split': 19}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:32:58,688] Trial 11 finished with value: 0.7746029329085458 and parameters: {'n_estimators': 112, 'max_features': 'log2', 'max_depth': 26, 'min_samples_split': 17}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:01,523] Trial 12 finished with value: 0.7833739380309845 and parameters: {'n_estimators': 490, 'max_features': 'log2', 'max_depth': 25, 'min_samples_split': 18}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:02,150] Trial 13 finished with value: 0.7940795227386307 and parameters: {'n_estimators': 101, 'max_features': 'log2', 'max_depth': 25, 'min_samples_split': 36}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:04,461] Trial 14 finished with value: 0.7827453460769614 and parameters: {'n_estimators': 398, 'max_features': 'log2', 'max_depth': 27, 'min_samples_split': 23}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:06,587] Trial 15 finished with value: 0.7786887806096953 and parameters: {'n_estimators': 353, 'max_features': 'log2', 'max_depth': 24, 'min_samples_split': 10}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:08,244] Trial 16 finished with value: 0.8070261744127936 and parameters: {'n_estimators': 247, 'max_features': 'sqrt', 'max_depth': 27, 'min_samples_split': 12}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:09,886] Trial 17 finished with value: 0.7749504154172914 and parameters: {'n_estimators': 247, 'max_features': 'log2', 'max_depth': 29, 'min_samples_split': 11}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:10,784] Trial 18 finished with value: 0.7942630247376311 and parameters: {'n_estimators': 144, 'max_features': 'sqrt', 'max_depth': 26, 'min_samples_split': 10}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:12,855] Trial 19 finished with value: 0.7907413480759621 and parameters: {'n_estimators': 352, 'max_features': 'log2', 'max_depth': 28, 'min_samples_split': 15}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:13,722] Trial 20 finished with value: 0.7833368472013994 and parameters: {'n_estimators': 141, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 23}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:15,246] Trial 21 finished with value: 0.7840415729635183 and parameters: {'n_estimators': 261, 'max_features': 'sqrt', 'max_depth': 26, 'min_samples_split': 36}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:17,354] Trial 22 finished with value: 0.7907569652673664 and parameters: {'n_estimators': 351, 'max_features': 'sqrt', 'max_depth': 27, 'min_samples_split': 23}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:19,108] Trial 23 finished with value: 0.7848126717891054 and parameters: {'n_estimators': 301, 'max_features': 'sqrt', 'max_depth': 28, 'min_samples_split': 13}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:20,347] Trial 24 finished with value: 0.7861694152923538 and parameters: {'n_estimators': 215, 'max_features': 'sqrt', 'max_depth': 24, 'min_samples_split': 28}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:22,225] Trial 25 finished with value: 0.7818297882308846 and parameters: {'n_estimators': 325, 'max_features': 'sqrt', 'max_depth': 26, 'min_samples_split': 34}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:24,098] Trial 26 finished with value: 0.7967930097451275 and parameters: {'n_estimators': 280, 'max_features': 'log2', 'max_depth': 29, 'min_samples_split': 7}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:26,457] Trial 27 finished with value: 0.7802739255372314 and parameters: {'n_estimators': 383, 'max_features': 'sqrt', 'max_depth': 27, 'min_samples_split': 21}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:29,095] Trial 28 finished with value: 0.7864251468015991 and parameters: {'n_estimators': 447, 'max_features': 'log2', 'max_depth': 30, 'min_samples_split': 41}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:30,124] Trial 29 finished with value: 0.7929746064467765 and parameters: {'n_estimators': 173, 'max_features': 'sqrt', 'max_depth': 24, 'min_samples_split': 41}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:31,133] Trial 30 finished with value: 0.7777048975512244 and parameters: {'n_estimators': 136, 'max_features': 'sqrt', 'max_depth': 25, 'min_samples_split': 7}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:32,990] Trial 31 finished with value: 0.785814124187906 and parameters: {'n_estimators': 260, 'max_features': 'log2', 'max_depth': 29, 'min_samples_split': 7}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:35,004] Trial 32 finished with value: 0.7844827586206896 and parameters: {'n_estimators': 321, 'max_features': 'log2', 'max_depth': 28, 'min_samples_split': 2}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:36,646] Trial 33 finished with value: 0.7822046008245876 and parameters: {'n_estimators': 277, 'max_features': 'log2', 'max_depth': 30, 'min_samples_split': 14}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:38,082] Trial 34 finished with value: 0.7871415854572713 and parameters: {'n_estimators': 233, 'max_features': 'log2', 'max_depth': 29, 'min_samples_split': 7}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:39,349] Trial 35 finished with value: 0.7941263743128436 and parameters: {'n_estimators': 191, 'max_features': 'log2', 'max_depth': 27, 'min_samples_split': 30}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:41,439] Trial 36 finished with value: 0.7885861756621688 and parameters: {'n_estimators': 322, 'max_features': 'sqrt', 'max_depth': 28, 'min_samples_split': 20}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:43,048] Trial 37 finished with value: 0.7929101855322339 and parameters: {'n_estimators': 277, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 28}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:44,411] Trial 38 finished with value: 0.7846779735132435 and parameters: {'n_estimators': 229, 'max_features': 'log2', 'max_depth': 29, 'min_samples_split': 26}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:45,611] Trial 39 finished with value: 0.7878287418790606 and parameters: {'n_estimators': 204, 'max_features': 'sqrt', 'max_depth': 26, 'min_samples_split': 16}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:46,586] Trial 40 finished with value: 0.7735741504247877 and parameters: {'n_estimators': 159, 'max_features': 'log2', 'max_depth': 27, 'min_samples_split': 5}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:49,456] Trial 41 finished with value: 0.7837018990504747 and parameters: {'n_estimators': 490, 'max_features': 'sqrt', 'max_depth': 22, 'min_samples_split': 19}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:52,117] Trial 42 finished with value: 0.7901225168665666 and parameters: {'n_estimators': 450, 'max_features': 'sqrt', 'max_depth': 21, 'min_samples_split': 12}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:53,865] Trial 43 finished with value: 0.7932713330834583 and parameters: {'n_estimators': 293, 'max_features': 'sqrt', 'max_depth': 23, 'min_samples_split': 17}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:56,252] Trial 44 finished with value: 0.7946690717141429 and parameters: {'n_estimators': 378, 'max_features': 'sqrt', 'max_depth': 25, 'min_samples_split': 25}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:33:58,906] Trial 45 finished with value: 0.7896344796351823 and parameters: {'n_estimators': 437, 'max_features': 'sqrt', 'max_depth': 23, 'min_samples_split': 9}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:34:00,920] Trial 46 finished with value: 0.787459785732134 and parameters: {'n_estimators': 337, 'max_features': 'log2', 'max_depth': 26, 'min_samples_split': 33}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:34:02,652] Trial 47 finished with value: 0.7807248719390305 and parameters: {'n_estimators': 302, 'max_features': 'sqrt', 'max_depth': 25, 'min_samples_split': 15}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:34:04,310] Trial 48 finished with value: 0.7837292291354322 and parameters: {'n_estimators': 272, 'max_features': 'log2', 'max_depth': 28, 'min_samples_split': 2}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:34:05,046] Trial 49 finished with value: 0.7751885775862069 and parameters: {'n_estimators': 120, 'max_features': 'sqrt', 'max_depth': 24, 'min_samples_split': 21}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:34:07,996] Trial 50 finished with value: 0.7859976261869065 and parameters: {'n_estimators': 473, 'max_features': 'log2', 'max_depth': 26, 'min_samples_split': 18}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:34:09,092] Trial 51 finished with value: 0.7852382402548725 and parameters: {'n_estimators': 185, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 30}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:34:10,678] Trial 52 finished with value: 0.79153392053973 and parameters: {'n_estimators': 251, 'max_features': 'sqrt', 'max_depth': 29, 'min_samples_split': 37}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:34:12,124] Trial 53 finished with value: 0.7901966985257372 and parameters: {'n_estimators': 218, 'max_features': 'sqrt', 'max_depth': 28, 'min_samples_split': 24}. Best is trial 10 with value: 0.8096420539730135.\n",
      "[I 2025-09-07 15:34:12,856] Trial 54 finished with value: 0.7880727604947526 and parameters: {'n_estimators': 102, 'max_features': 'sqrt', 'max_depth': 27, 'min_samples_split': 33}. Best is trial 10 with value: 0.8096420539730135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.810\n",
      "  Params:  {'n_estimators': 107, 'max_features': 'log2', 'max_depth': 26, 'min_samples_split': 19}\n"
     ]
    }
   ],
   "source": [
    "def best_params_for_model(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 20, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "    }\n",
    "\n",
    "    rf_clf = RandomForestClassifier(**param)\n",
    "    accuracy = cross_val_score(rf_clf, X_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(best_params_for_model, n_trials=55)\n",
    "\n",
    "print('Best trial:')\n",
    "best_params = study.best_params\n",
    "print('  Value: {:.3f}'.format(study.best_value))\n",
    "print('  Params: ', best_params)\n",
    "\n",
    "best_rf_model = RandomForestClassifier(**best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "bf90ada5-8cd3-446d-9fb6-e777e6b999ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_optimized = []\n",
    "\n",
    "models_optimized.extend([\n",
    "    ('XGBoost Optuna', best_xgb_model),\n",
    "    ('LightGBM Optuna', best_lgb_model),\n",
    "    ('CatBoost Optuna', best_cb_model), \n",
    "    ('CatBoost Categoric Optuna', best_cb_custom_model),\n",
    "    ('RandomForest Optuna', best_rf_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "f10ae4ac-6b2d-4750-8d7e-43b6eaaa6260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for XGBoost Optuna\n",
      "Train Gini prob is 78.14530234882557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8004\n",
      "           1       0.95      0.21      0.34        96\n",
      "\n",
      "    accuracy                           0.99      8100\n",
      "   macro avg       0.97      0.60      0.67      8100\n",
      "weighted avg       0.99      0.99      0.99      8100\n",
      "\n",
      "[[8003    1]\n",
      " [  76   20]]\n",
      "Model Performance for XGBoost Optuna\n",
      "Test Gini prob is 51.724685698724635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2003\n",
      "           1       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       1.00      0.57      0.62      2025\n",
      "weighted avg       0.99      0.99      0.99      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  19    3]]\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 96, number of negative: 8004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 8100, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011852 -> initscore=-4.423349\n",
      "[LightGBM] [Info] Start training from score -4.423349\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\2609667454.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  gini_df_optuna = pd.concat([gini_df_optuna, pd.DataFrame({'Model': [model_name], 'Train Gini': [gini_prob[0]], 'Test Gini': [gini_prob[1]]})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for LightGBM Optuna\n",
      "Train Gini prob is 79.68060240712977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8004\n",
      "           1       0.96      0.23      0.37        96\n",
      "\n",
      "    accuracy                           0.99      8100\n",
      "   macro avg       0.97      0.61      0.68      8100\n",
      "weighted avg       0.99      0.99      0.99      8100\n",
      "\n",
      "[[8003    1]\n",
      " [  74   22]]\n",
      "Model Performance for LightGBM Optuna\n",
      "Test Gini prob is 51.543139835701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2003\n",
      "           1       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       1.00      0.55      0.58      2025\n",
      "weighted avg       0.99      0.99      0.99      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  20    2]]\n",
      "0:\tlearn: 0.6324659\ttotal: 1.17ms\tremaining: 210ms\n",
      "1:\tlearn: 0.5793251\ttotal: 2.31ms\tremaining: 205ms\n",
      "2:\tlearn: 0.5324158\ttotal: 3.42ms\tremaining: 202ms\n",
      "3:\tlearn: 0.4904135\ttotal: 4.81ms\tremaining: 212ms\n",
      "4:\tlearn: 0.4531658\ttotal: 6.19ms\tremaining: 217ms\n",
      "5:\tlearn: 0.4195557\ttotal: 7.9ms\tremaining: 229ms\n",
      "6:\tlearn: 0.3894437\ttotal: 9.29ms\tremaining: 230ms\n",
      "7:\tlearn: 0.3622100\ttotal: 10.7ms\tremaining: 230ms\n",
      "8:\tlearn: 0.3373717\ttotal: 12.1ms\tremaining: 229ms\n",
      "9:\tlearn: 0.3148844\ttotal: 13.5ms\tremaining: 230ms\n",
      "10:\tlearn: 0.2943634\ttotal: 14.9ms\tremaining: 229ms\n",
      "11:\tlearn: 0.2756599\ttotal: 16.1ms\tremaining: 225ms\n",
      "12:\tlearn: 0.2585546\ttotal: 17.3ms\tremaining: 222ms\n",
      "13:\tlearn: 0.2428741\ttotal: 19ms\tremaining: 226ms\n",
      "14:\tlearn: 0.2285601\ttotal: 20.4ms\tremaining: 224ms\n",
      "15:\tlearn: 0.2154096\ttotal: 21.8ms\tremaining: 223ms\n",
      "16:\tlearn: 0.2033066\ttotal: 24.9ms\tremaining: 239ms\n",
      "17:\tlearn: 0.1922217\ttotal: 26.2ms\tremaining: 236ms\n",
      "18:\tlearn: 0.1820360\ttotal: 27.8ms\tremaining: 236ms\n",
      "19:\tlearn: 0.1724713\ttotal: 29ms\tremaining: 232ms\n",
      "20:\tlearn: 0.1637707\ttotal: 30.2ms\tremaining: 229ms\n",
      "21:\tlearn: 0.1556582\ttotal: 31.5ms\tremaining: 226ms\n",
      "22:\tlearn: 0.1483239\ttotal: 32.7ms\tremaining: 223ms\n",
      "23:\tlearn: 0.1413974\ttotal: 34ms\tremaining: 221ms\n",
      "24:\tlearn: 0.1349995\ttotal: 35.2ms\tremaining: 218ms\n",
      "25:\tlearn: 0.1290856\ttotal: 36.5ms\tremaining: 216ms\n",
      "26:\tlearn: 0.1235096\ttotal: 37.7ms\tremaining: 214ms\n",
      "27:\tlearn: 0.1184697\ttotal: 39.2ms\tremaining: 213ms\n",
      "28:\tlearn: 0.1138254\ttotal: 40.5ms\tremaining: 211ms\n",
      "29:\tlearn: 0.1093329\ttotal: 41.7ms\tremaining: 209ms\n",
      "30:\tlearn: 0.1053776\ttotal: 43ms\tremaining: 207ms\n",
      "31:\tlearn: 0.1017097\ttotal: 44.1ms\tremaining: 204ms\n",
      "32:\tlearn: 0.0984245\ttotal: 45.3ms\tremaining: 202ms\n",
      "33:\tlearn: 0.0952628\ttotal: 46.6ms\tremaining: 200ms\n",
      "34:\tlearn: 0.0921643\ttotal: 47.8ms\tremaining: 198ms\n",
      "35:\tlearn: 0.0894512\ttotal: 49ms\tremaining: 196ms\n",
      "36:\tlearn: 0.0868034\ttotal: 50.2ms\tremaining: 194ms\n",
      "37:\tlearn: 0.0845633\ttotal: 51.5ms\tremaining: 192ms\n",
      "38:\tlearn: 0.0824861\ttotal: 52.6ms\tremaining: 190ms\n",
      "39:\tlearn: 0.0803774\ttotal: 53.8ms\tremaining: 188ms\n",
      "40:\tlearn: 0.0783016\ttotal: 55ms\tremaining: 186ms\n",
      "41:\tlearn: 0.0763426\ttotal: 56.1ms\tremaining: 184ms\n",
      "42:\tlearn: 0.0748858\ttotal: 57.3ms\tremaining: 183ms\n",
      "43:\tlearn: 0.0734699\ttotal: 58.5ms\tremaining: 181ms\n",
      "44:\tlearn: 0.0721617\ttotal: 59.7ms\tremaining: 179ms\n",
      "45:\tlearn: 0.0708579\ttotal: 60.9ms\tremaining: 177ms\n",
      "46:\tlearn: 0.0696343\ttotal: 62.1ms\tremaining: 176ms\n",
      "47:\tlearn: 0.0677992\ttotal: 63.2ms\tremaining: 174ms\n",
      "48:\tlearn: 0.0667343\ttotal: 64.5ms\tremaining: 173ms\n",
      "49:\tlearn: 0.0658381\ttotal: 65.7ms\tremaining: 171ms\n",
      "50:\tlearn: 0.0651076\ttotal: 66.8ms\tremaining: 169ms\n",
      "51:\tlearn: 0.0643256\ttotal: 67.9ms\tremaining: 167ms\n",
      "52:\tlearn: 0.0636494\ttotal: 69.1ms\tremaining: 166ms\n",
      "53:\tlearn: 0.0629389\ttotal: 70.2ms\tremaining: 164ms\n",
      "54:\tlearn: 0.0622889\ttotal: 71.4ms\tremaining: 162ms\n",
      "55:\tlearn: 0.0617643\ttotal: 72.6ms\tremaining: 161ms\n",
      "56:\tlearn: 0.0610133\ttotal: 73.7ms\tremaining: 159ms\n",
      "57:\tlearn: 0.0605766\ttotal: 74.8ms\tremaining: 157ms\n",
      "58:\tlearn: 0.0602289\ttotal: 76ms\tremaining: 156ms\n",
      "59:\tlearn: 0.0597576\ttotal: 77.2ms\tremaining: 154ms\n",
      "60:\tlearn: 0.0594787\ttotal: 78.3ms\tremaining: 153ms\n",
      "61:\tlearn: 0.0591051\ttotal: 79.4ms\tremaining: 151ms\n",
      "62:\tlearn: 0.0588479\ttotal: 80.9ms\tremaining: 150ms\n",
      "63:\tlearn: 0.0586423\ttotal: 82ms\tremaining: 149ms\n",
      "64:\tlearn: 0.0581401\ttotal: 83.2ms\tremaining: 147ms\n",
      "65:\tlearn: 0.0579020\ttotal: 84.4ms\tremaining: 146ms\n",
      "66:\tlearn: 0.0574816\ttotal: 85.5ms\tremaining: 144ms\n",
      "67:\tlearn: 0.0571651\ttotal: 86.6ms\tremaining: 143ms\n",
      "68:\tlearn: 0.0569447\ttotal: 87.6ms\tremaining: 141ms\n",
      "69:\tlearn: 0.0567539\ttotal: 88.7ms\tremaining: 139ms\n",
      "70:\tlearn: 0.0566597\ttotal: 89.8ms\tremaining: 138ms\n",
      "71:\tlearn: 0.0565747\ttotal: 90.9ms\tremaining: 136ms\n",
      "72:\tlearn: 0.0563507\ttotal: 92ms\tremaining: 135ms\n",
      "73:\tlearn: 0.0561937\ttotal: 93.1ms\tremaining: 133ms\n",
      "74:\tlearn: 0.0559437\ttotal: 94.4ms\tremaining: 132ms\n",
      "75:\tlearn: 0.0558900\ttotal: 95.5ms\tremaining: 131ms\n",
      "76:\tlearn: 0.0551246\ttotal: 96.6ms\tremaining: 129ms\n",
      "77:\tlearn: 0.0549846\ttotal: 97.7ms\tremaining: 128ms\n",
      "78:\tlearn: 0.0548621\ttotal: 98.7ms\tremaining: 126ms\n",
      "79:\tlearn: 0.0546674\ttotal: 99.8ms\tremaining: 125ms\n",
      "80:\tlearn: 0.0545978\ttotal: 101ms\tremaining: 123ms\n",
      "81:\tlearn: 0.0542762\ttotal: 102ms\tremaining: 122ms\n",
      "82:\tlearn: 0.0540284\ttotal: 103ms\tremaining: 120ms\n",
      "83:\tlearn: 0.0538978\ttotal: 104ms\tremaining: 119ms\n",
      "84:\tlearn: 0.0532985\ttotal: 105ms\tremaining: 117ms\n",
      "85:\tlearn: 0.0531041\ttotal: 106ms\tremaining: 116ms\n",
      "86:\tlearn: 0.0529150\ttotal: 107ms\tremaining: 114ms\n",
      "87:\tlearn: 0.0525065\ttotal: 108ms\tremaining: 113ms\n",
      "88:\tlearn: 0.0521147\ttotal: 110ms\tremaining: 112ms\n",
      "89:\tlearn: 0.0519695\ttotal: 111ms\tremaining: 111ms\n",
      "90:\tlearn: 0.0515619\ttotal: 112ms\tremaining: 109ms\n",
      "91:\tlearn: 0.0514389\ttotal: 113ms\tremaining: 108ms\n",
      "92:\tlearn: 0.0512995\ttotal: 114ms\tremaining: 106ms\n",
      "93:\tlearn: 0.0510252\ttotal: 115ms\tremaining: 105ms\n",
      "94:\tlearn: 0.0509095\ttotal: 116ms\tremaining: 104ms\n",
      "95:\tlearn: 0.0507635\ttotal: 117ms\tremaining: 102ms\n",
      "96:\tlearn: 0.0506925\ttotal: 118ms\tremaining: 101ms\n",
      "97:\tlearn: 0.0504076\ttotal: 119ms\tremaining: 99.6ms\n",
      "98:\tlearn: 0.0503441\ttotal: 120ms\tremaining: 98.2ms\n",
      "99:\tlearn: 0.0500508\ttotal: 121ms\tremaining: 96.9ms\n",
      "100:\tlearn: 0.0499375\ttotal: 122ms\tremaining: 95.8ms\n",
      "101:\tlearn: 0.0497490\ttotal: 124ms\tremaining: 94.5ms\n",
      "102:\tlearn: 0.0496903\ttotal: 125ms\tremaining: 93.2ms\n",
      "103:\tlearn: 0.0496375\ttotal: 126ms\tremaining: 91.9ms\n",
      "104:\tlearn: 0.0496041\ttotal: 127ms\tremaining: 90.7ms\n",
      "105:\tlearn: 0.0495717\ttotal: 129ms\tremaining: 89.7ms\n",
      "106:\tlearn: 0.0494615\ttotal: 130ms\tremaining: 88.8ms\n",
      "107:\tlearn: 0.0492238\ttotal: 131ms\tremaining: 87.6ms\n",
      "108:\tlearn: 0.0491639\ttotal: 133ms\tremaining: 86.4ms\n",
      "109:\tlearn: 0.0490800\ttotal: 134ms\tremaining: 85.2ms\n",
      "110:\tlearn: 0.0488401\ttotal: 135ms\tremaining: 84.1ms\n",
      "111:\tlearn: 0.0487933\ttotal: 136ms\tremaining: 82.8ms\n",
      "112:\tlearn: 0.0486158\ttotal: 138ms\tremaining: 81.6ms\n",
      "113:\tlearn: 0.0485533\ttotal: 139ms\tremaining: 80.5ms\n",
      "114:\tlearn: 0.0483771\ttotal: 140ms\tremaining: 79.3ms\n",
      "115:\tlearn: 0.0482938\ttotal: 142ms\tremaining: 78.1ms\n",
      "116:\tlearn: 0.0481333\ttotal: 143ms\tremaining: 76.8ms\n",
      "117:\tlearn: 0.0480826\ttotal: 144ms\tremaining: 75.7ms\n",
      "118:\tlearn: 0.0478544\ttotal: 145ms\tremaining: 74.5ms\n",
      "119:\tlearn: 0.0474536\ttotal: 146ms\tremaining: 73.2ms\n",
      "120:\tlearn: 0.0473000\ttotal: 148ms\tremaining: 72ms\n",
      "121:\tlearn: 0.0471741\ttotal: 149ms\tremaining: 70.8ms\n",
      "122:\tlearn: 0.0470424\ttotal: 150ms\tremaining: 69.7ms\n",
      "123:\tlearn: 0.0468364\ttotal: 152ms\tremaining: 68.5ms\n",
      "124:\tlearn: 0.0467229\ttotal: 153ms\tremaining: 67.4ms\n",
      "125:\tlearn: 0.0463435\ttotal: 154ms\tremaining: 66.2ms\n",
      "126:\tlearn: 0.0462721\ttotal: 156ms\tremaining: 64.9ms\n",
      "127:\tlearn: 0.0461017\ttotal: 157ms\tremaining: 63.7ms\n",
      "128:\tlearn: 0.0459710\ttotal: 158ms\tremaining: 62.4ms\n",
      "129:\tlearn: 0.0458204\ttotal: 159ms\tremaining: 61.2ms\n",
      "130:\tlearn: 0.0457384\ttotal: 160ms\tremaining: 59.9ms\n",
      "131:\tlearn: 0.0454792\ttotal: 162ms\tremaining: 58.7ms\n",
      "132:\tlearn: 0.0454154\ttotal: 163ms\tremaining: 57.5ms\n",
      "133:\tlearn: 0.0453269\ttotal: 164ms\tremaining: 56.3ms\n",
      "134:\tlearn: 0.0452677\ttotal: 165ms\tremaining: 55ms\n",
      "135:\tlearn: 0.0451712\ttotal: 166ms\tremaining: 53.8ms\n",
      "136:\tlearn: 0.0450903\ttotal: 168ms\tremaining: 52.7ms\n",
      "137:\tlearn: 0.0450156\ttotal: 169ms\tremaining: 51.5ms\n",
      "138:\tlearn: 0.0449186\ttotal: 171ms\tremaining: 50.3ms\n",
      "139:\tlearn: 0.0446978\ttotal: 172ms\tremaining: 49.1ms\n",
      "140:\tlearn: 0.0446344\ttotal: 173ms\tremaining: 47.9ms\n",
      "141:\tlearn: 0.0445931\ttotal: 174ms\tremaining: 46.6ms\n",
      "142:\tlearn: 0.0444935\ttotal: 176ms\tremaining: 45.4ms\n",
      "143:\tlearn: 0.0444663\ttotal: 177ms\tremaining: 44.2ms\n",
      "144:\tlearn: 0.0443903\ttotal: 178ms\tremaining: 43ms\n",
      "145:\tlearn: 0.0442861\ttotal: 179ms\tremaining: 41.7ms\n",
      "146:\tlearn: 0.0441953\ttotal: 181ms\tremaining: 40.6ms\n",
      "147:\tlearn: 0.0441482\ttotal: 182ms\tremaining: 39.3ms\n",
      "148:\tlearn: 0.0440974\ttotal: 183ms\tremaining: 38.1ms\n",
      "149:\tlearn: 0.0440006\ttotal: 185ms\tremaining: 37ms\n",
      "150:\tlearn: 0.0439562\ttotal: 186ms\tremaining: 35.7ms\n",
      "151:\tlearn: 0.0438755\ttotal: 187ms\tremaining: 34.5ms\n",
      "152:\tlearn: 0.0436568\ttotal: 188ms\tremaining: 33.2ms\n",
      "153:\tlearn: 0.0436140\ttotal: 189ms\tremaining: 32ms\n",
      "154:\tlearn: 0.0435437\ttotal: 191ms\tremaining: 30.8ms\n",
      "155:\tlearn: 0.0434778\ttotal: 192ms\tremaining: 29.6ms\n",
      "156:\tlearn: 0.0434373\ttotal: 194ms\tremaining: 28.4ms\n",
      "157:\tlearn: 0.0433862\ttotal: 195ms\tremaining: 27.1ms\n",
      "158:\tlearn: 0.0433007\ttotal: 196ms\tremaining: 25.9ms\n",
      "159:\tlearn: 0.0431720\ttotal: 198ms\tremaining: 24.7ms\n",
      "160:\tlearn: 0.0431520\ttotal: 199ms\tremaining: 23.4ms\n",
      "161:\tlearn: 0.0431340\ttotal: 200ms\tremaining: 22.2ms\n",
      "162:\tlearn: 0.0430178\ttotal: 201ms\tremaining: 21ms\n",
      "163:\tlearn: 0.0429262\ttotal: 202ms\tremaining: 19.7ms\n",
      "164:\tlearn: 0.0428848\ttotal: 204ms\tremaining: 18.5ms\n",
      "165:\tlearn: 0.0428670\ttotal: 205ms\tremaining: 17.3ms\n",
      "166:\tlearn: 0.0428331\ttotal: 206ms\tremaining: 16.1ms\n",
      "167:\tlearn: 0.0427761\ttotal: 208ms\tremaining: 14.8ms\n",
      "168:\tlearn: 0.0427215\ttotal: 210ms\tremaining: 13.6ms\n",
      "169:\tlearn: 0.0426360\ttotal: 211ms\tremaining: 12.4ms\n",
      "170:\tlearn: 0.0425669\ttotal: 213ms\tremaining: 11.2ms\n",
      "171:\tlearn: 0.0425024\ttotal: 215ms\tremaining: 9.99ms\n",
      "172:\tlearn: 0.0423478\ttotal: 216ms\tremaining: 8.76ms\n",
      "173:\tlearn: 0.0423248\ttotal: 218ms\tremaining: 7.52ms\n",
      "174:\tlearn: 0.0422932\ttotal: 220ms\tremaining: 6.28ms\n",
      "175:\tlearn: 0.0422561\ttotal: 221ms\tremaining: 5.02ms\n",
      "176:\tlearn: 0.0422033\ttotal: 222ms\tremaining: 3.77ms\n",
      "177:\tlearn: 0.0421900\ttotal: 224ms\tremaining: 2.51ms\n",
      "178:\tlearn: 0.0421600\ttotal: 225ms\tremaining: 1.26ms\n",
      "179:\tlearn: 0.0421324\ttotal: 227ms\tremaining: 0us\n",
      "Model Performance for CatBoost Optuna\n",
      "Train Gini prob is 69.72815675495585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8004\n",
      "           1       1.00      0.21      0.34        96\n",
      "\n",
      "    accuracy                           0.99      8100\n",
      "   macro avg       1.00      0.60      0.67      8100\n",
      "weighted avg       0.99      0.99      0.99      8100\n",
      "\n",
      "[[8004    0]\n",
      " [  76   20]]\n",
      "Model Performance for CatBoost Optuna\n",
      "Test Gini prob is 58.888939318295286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2003\n",
      "           1       1.00      0.05      0.09        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       0.99      0.52      0.54      2025\n",
      "weighted avg       0.99      0.99      0.98      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  21    1]]\n",
      "0:\tlearn: 0.6682193\ttotal: 3.46ms\tremaining: 2.88s\n",
      "1:\tlearn: 0.6442019\ttotal: 6.22ms\tremaining: 2.59s\n",
      "2:\tlearn: 0.6220110\ttotal: 8.33ms\tremaining: 2.31s\n",
      "3:\tlearn: 0.5986123\ttotal: 10.9ms\tremaining: 2.25s\n",
      "4:\tlearn: 0.5772579\ttotal: 13.4ms\tremaining: 2.22s\n",
      "5:\tlearn: 0.5575083\ttotal: 16ms\tremaining: 2.21s\n",
      "6:\tlearn: 0.5372944\ttotal: 18.9ms\tremaining: 2.23s\n",
      "7:\tlearn: 0.5179063\ttotal: 21.6ms\tremaining: 2.23s\n",
      "8:\tlearn: 0.4992838\ttotal: 24.3ms\tremaining: 2.23s\n",
      "9:\tlearn: 0.4826206\ttotal: 26.5ms\tremaining: 2.18s\n",
      "10:\tlearn: 0.4659197\ttotal: 29.1ms\tremaining: 2.18s\n",
      "11:\tlearn: 0.4488745\ttotal: 32.5ms\tremaining: 2.22s\n",
      "12:\tlearn: 0.4331711\ttotal: 35.2ms\tremaining: 2.23s\n",
      "13:\tlearn: 0.4181989\ttotal: 37.9ms\tremaining: 2.22s\n",
      "14:\tlearn: 0.4043643\ttotal: 40.7ms\tremaining: 2.22s\n",
      "15:\tlearn: 0.3913823\ttotal: 43.5ms\tremaining: 2.22s\n",
      "16:\tlearn: 0.3784971\ttotal: 46.3ms\tremaining: 2.23s\n",
      "17:\tlearn: 0.3654201\ttotal: 48.9ms\tremaining: 2.22s\n",
      "18:\tlearn: 0.3536440\ttotal: 51.4ms\tremaining: 2.2s\n",
      "19:\tlearn: 0.3420535\ttotal: 53.9ms\tremaining: 2.19s\n",
      "20:\tlearn: 0.3303617\ttotal: 56.4ms\tremaining: 2.18s\n",
      "21:\tlearn: 0.3198223\ttotal: 59ms\tremaining: 2.18s\n",
      "22:\tlearn: 0.3097953\ttotal: 61.6ms\tremaining: 2.17s\n",
      "23:\tlearn: 0.3004178\ttotal: 64.1ms\tremaining: 2.16s\n",
      "24:\tlearn: 0.2909058\ttotal: 66.7ms\tremaining: 2.16s\n",
      "25:\tlearn: 0.2816429\ttotal: 69.2ms\tremaining: 2.15s\n",
      "26:\tlearn: 0.2729937\ttotal: 71.7ms\tremaining: 2.14s\n",
      "27:\tlearn: 0.2652222\ttotal: 74.3ms\tremaining: 2.14s\n",
      "28:\tlearn: 0.2572632\ttotal: 76.8ms\tremaining: 2.13s\n",
      "29:\tlearn: 0.2499607\ttotal: 79.3ms\tremaining: 2.12s\n",
      "30:\tlearn: 0.2422919\ttotal: 81.7ms\tremaining: 2.12s\n",
      "31:\tlearn: 0.2352360\ttotal: 84.5ms\tremaining: 2.12s\n",
      "32:\tlearn: 0.2284334\ttotal: 87ms\tremaining: 2.11s\n",
      "33:\tlearn: 0.2221741\ttotal: 89.5ms\tremaining: 2.1s\n",
      "34:\tlearn: 0.2159396\ttotal: 92ms\tremaining: 2.1s\n",
      "35:\tlearn: 0.2100750\ttotal: 94.5ms\tremaining: 2.1s\n",
      "36:\tlearn: 0.2046628\ttotal: 96.9ms\tremaining: 2.09s\n",
      "37:\tlearn: 0.1995188\ttotal: 99.6ms\tremaining: 2.08s\n",
      "38:\tlearn: 0.1942703\ttotal: 102ms\tremaining: 2.08s\n",
      "39:\tlearn: 0.1886214\ttotal: 105ms\tremaining: 2.07s\n",
      "40:\tlearn: 0.1839803\ttotal: 107ms\tremaining: 2.07s\n",
      "41:\tlearn: 0.1794636\ttotal: 110ms\tremaining: 2.07s\n",
      "42:\tlearn: 0.1752308\ttotal: 112ms\tremaining: 2.06s\n",
      "43:\tlearn: 0.1711814\ttotal: 115ms\tremaining: 2.07s\n",
      "44:\tlearn: 0.1673897\ttotal: 118ms\tremaining: 2.06s\n",
      "45:\tlearn: 0.1632860\ttotal: 120ms\tremaining: 2.06s\n",
      "46:\tlearn: 0.1593844\ttotal: 123ms\tremaining: 2.05s\n",
      "47:\tlearn: 0.1556866\ttotal: 126ms\tremaining: 2.06s\n",
      "48:\tlearn: 0.1523915\ttotal: 128ms\tremaining: 2.05s\n",
      "49:\tlearn: 0.1487822\ttotal: 131ms\tremaining: 2.05s\n",
      "50:\tlearn: 0.1458478\ttotal: 133ms\tremaining: 2.04s\n",
      "51:\tlearn: 0.1424771\ttotal: 135ms\tremaining: 2.03s\n",
      "52:\tlearn: 0.1391877\ttotal: 137ms\tremaining: 2.02s\n",
      "53:\tlearn: 0.1364057\ttotal: 140ms\tremaining: 2.02s\n",
      "54:\tlearn: 0.1335352\ttotal: 142ms\tremaining: 2.02s\n",
      "55:\tlearn: 0.1307721\ttotal: 145ms\tremaining: 2.01s\n",
      "56:\tlearn: 0.1282689\ttotal: 147ms\tremaining: 2.01s\n",
      "57:\tlearn: 0.1257998\ttotal: 150ms\tremaining: 2s\n",
      "58:\tlearn: 0.1233894\ttotal: 152ms\tremaining: 2s\n",
      "59:\tlearn: 0.1212549\ttotal: 155ms\tremaining: 1.99s\n",
      "60:\tlearn: 0.1191708\ttotal: 157ms\tremaining: 1.99s\n",
      "61:\tlearn: 0.1172918\ttotal: 159ms\tremaining: 1.98s\n",
      "62:\tlearn: 0.1154319\ttotal: 162ms\tremaining: 1.98s\n",
      "63:\tlearn: 0.1134282\ttotal: 164ms\tremaining: 1.97s\n",
      "64:\tlearn: 0.1115217\ttotal: 166ms\tremaining: 1.97s\n",
      "65:\tlearn: 0.1095417\ttotal: 169ms\tremaining: 1.96s\n",
      "66:\tlearn: 0.1076722\ttotal: 171ms\tremaining: 1.96s\n",
      "67:\tlearn: 0.1060384\ttotal: 174ms\tremaining: 1.96s\n",
      "68:\tlearn: 0.1045506\ttotal: 177ms\tremaining: 1.96s\n",
      "69:\tlearn: 0.1026836\ttotal: 179ms\tremaining: 1.95s\n",
      "70:\tlearn: 0.1012965\ttotal: 181ms\tremaining: 1.95s\n",
      "71:\tlearn: 0.0998680\ttotal: 183ms\tremaining: 1.94s\n",
      "72:\tlearn: 0.0985875\ttotal: 186ms\tremaining: 1.93s\n",
      "73:\tlearn: 0.0972181\ttotal: 188ms\tremaining: 1.93s\n",
      "74:\tlearn: 0.0958976\ttotal: 190ms\tremaining: 1.93s\n",
      "75:\tlearn: 0.0947093\ttotal: 193ms\tremaining: 1.92s\n",
      "76:\tlearn: 0.0935227\ttotal: 195ms\tremaining: 1.92s\n",
      "77:\tlearn: 0.0919254\ttotal: 197ms\tremaining: 1.91s\n",
      "78:\tlearn: 0.0908482\ttotal: 200ms\tremaining: 1.91s\n",
      "79:\tlearn: 0.0896233\ttotal: 202ms\tremaining: 1.9s\n",
      "80:\tlearn: 0.0884012\ttotal: 204ms\tremaining: 1.9s\n",
      "81:\tlearn: 0.0871000\ttotal: 207ms\tremaining: 1.9s\n",
      "82:\tlearn: 0.0861144\ttotal: 209ms\tremaining: 1.89s\n",
      "83:\tlearn: 0.0851876\ttotal: 211ms\tremaining: 1.89s\n",
      "84:\tlearn: 0.0840886\ttotal: 214ms\tremaining: 1.88s\n",
      "85:\tlearn: 0.0830883\ttotal: 217ms\tremaining: 1.89s\n",
      "86:\tlearn: 0.0822280\ttotal: 220ms\tremaining: 1.89s\n",
      "87:\tlearn: 0.0814248\ttotal: 223ms\tremaining: 1.89s\n",
      "88:\tlearn: 0.0806217\ttotal: 225ms\tremaining: 1.88s\n",
      "89:\tlearn: 0.0799162\ttotal: 228ms\tremaining: 1.88s\n",
      "90:\tlearn: 0.0791307\ttotal: 230ms\tremaining: 1.88s\n",
      "91:\tlearn: 0.0784101\ttotal: 233ms\tremaining: 1.88s\n",
      "92:\tlearn: 0.0773815\ttotal: 235ms\tremaining: 1.87s\n",
      "93:\tlearn: 0.0766401\ttotal: 238ms\tremaining: 1.87s\n",
      "94:\tlearn: 0.0759339\ttotal: 240ms\tremaining: 1.87s\n",
      "95:\tlearn: 0.0750365\ttotal: 243ms\tremaining: 1.87s\n",
      "96:\tlearn: 0.0743603\ttotal: 245ms\tremaining: 1.86s\n",
      "97:\tlearn: 0.0735924\ttotal: 248ms\tremaining: 1.86s\n",
      "98:\tlearn: 0.0729275\ttotal: 250ms\tremaining: 1.86s\n",
      "99:\tlearn: 0.0723567\ttotal: 253ms\tremaining: 1.86s\n",
      "100:\tlearn: 0.0717729\ttotal: 256ms\tremaining: 1.85s\n",
      "101:\tlearn: 0.0711279\ttotal: 258ms\tremaining: 1.85s\n",
      "102:\tlearn: 0.0704135\ttotal: 261ms\tremaining: 1.85s\n",
      "103:\tlearn: 0.0699562\ttotal: 263ms\tremaining: 1.85s\n",
      "104:\tlearn: 0.0692900\ttotal: 266ms\tremaining: 1.84s\n",
      "105:\tlearn: 0.0687679\ttotal: 269ms\tremaining: 1.84s\n",
      "106:\tlearn: 0.0681303\ttotal: 271ms\tremaining: 1.84s\n",
      "107:\tlearn: 0.0676770\ttotal: 274ms\tremaining: 1.84s\n",
      "108:\tlearn: 0.0673191\ttotal: 276ms\tremaining: 1.84s\n",
      "109:\tlearn: 0.0668484\ttotal: 279ms\tremaining: 1.83s\n",
      "110:\tlearn: 0.0663470\ttotal: 283ms\tremaining: 1.84s\n",
      "111:\tlearn: 0.0660313\ttotal: 286ms\tremaining: 1.84s\n",
      "112:\tlearn: 0.0654827\ttotal: 288ms\tremaining: 1.84s\n",
      "113:\tlearn: 0.0651962\ttotal: 291ms\tremaining: 1.83s\n",
      "114:\tlearn: 0.0647227\ttotal: 293ms\tremaining: 1.83s\n",
      "115:\tlearn: 0.0642145\ttotal: 296ms\tremaining: 1.83s\n",
      "116:\tlearn: 0.0638154\ttotal: 298ms\tremaining: 1.83s\n",
      "117:\tlearn: 0.0634727\ttotal: 301ms\tremaining: 1.83s\n",
      "118:\tlearn: 0.0631600\ttotal: 304ms\tremaining: 1.82s\n",
      "119:\tlearn: 0.0628406\ttotal: 306ms\tremaining: 1.82s\n",
      "120:\tlearn: 0.0625650\ttotal: 308ms\tremaining: 1.82s\n",
      "121:\tlearn: 0.0623557\ttotal: 311ms\tremaining: 1.81s\n",
      "122:\tlearn: 0.0619139\ttotal: 313ms\tremaining: 1.81s\n",
      "123:\tlearn: 0.0615575\ttotal: 316ms\tremaining: 1.81s\n",
      "124:\tlearn: 0.0613258\ttotal: 318ms\tremaining: 1.8s\n",
      "125:\tlearn: 0.0609001\ttotal: 321ms\tremaining: 1.8s\n",
      "126:\tlearn: 0.0606599\ttotal: 323ms\tremaining: 1.8s\n",
      "127:\tlearn: 0.0602211\ttotal: 326ms\tremaining: 1.79s\n",
      "128:\tlearn: 0.0599262\ttotal: 328ms\tremaining: 1.79s\n",
      "129:\tlearn: 0.0595814\ttotal: 331ms\tremaining: 1.79s\n",
      "130:\tlearn: 0.0593667\ttotal: 334ms\tremaining: 1.79s\n",
      "131:\tlearn: 0.0589248\ttotal: 337ms\tremaining: 1.79s\n",
      "132:\tlearn: 0.0585890\ttotal: 339ms\tremaining: 1.79s\n",
      "133:\tlearn: 0.0583486\ttotal: 342ms\tremaining: 1.78s\n",
      "134:\tlearn: 0.0580084\ttotal: 344ms\tremaining: 1.78s\n",
      "135:\tlearn: 0.0576436\ttotal: 347ms\tremaining: 1.78s\n",
      "136:\tlearn: 0.0573801\ttotal: 349ms\tremaining: 1.78s\n",
      "137:\tlearn: 0.0570920\ttotal: 352ms\tremaining: 1.77s\n",
      "138:\tlearn: 0.0568218\ttotal: 354ms\tremaining: 1.77s\n",
      "139:\tlearn: 0.0566149\ttotal: 357ms\tremaining: 1.77s\n",
      "140:\tlearn: 0.0562848\ttotal: 359ms\tremaining: 1.76s\n",
      "141:\tlearn: 0.0561202\ttotal: 362ms\tremaining: 1.76s\n",
      "142:\tlearn: 0.0559124\ttotal: 364ms\tremaining: 1.76s\n",
      "143:\tlearn: 0.0556327\ttotal: 366ms\tremaining: 1.76s\n",
      "144:\tlearn: 0.0553824\ttotal: 369ms\tremaining: 1.75s\n",
      "145:\tlearn: 0.0551355\ttotal: 371ms\tremaining: 1.75s\n",
      "146:\tlearn: 0.0549632\ttotal: 374ms\tremaining: 1.75s\n",
      "147:\tlearn: 0.0547179\ttotal: 376ms\tremaining: 1.74s\n",
      "148:\tlearn: 0.0545265\ttotal: 379ms\tremaining: 1.74s\n",
      "149:\tlearn: 0.0542601\ttotal: 381ms\tremaining: 1.74s\n",
      "150:\tlearn: 0.0541129\ttotal: 384ms\tremaining: 1.74s\n",
      "151:\tlearn: 0.0539308\ttotal: 386ms\tremaining: 1.73s\n",
      "152:\tlearn: 0.0537323\ttotal: 389ms\tremaining: 1.73s\n",
      "153:\tlearn: 0.0535251\ttotal: 391ms\tremaining: 1.73s\n",
      "154:\tlearn: 0.0533308\ttotal: 394ms\tremaining: 1.73s\n",
      "155:\tlearn: 0.0531336\ttotal: 397ms\tremaining: 1.72s\n",
      "156:\tlearn: 0.0528952\ttotal: 399ms\tremaining: 1.72s\n",
      "157:\tlearn: 0.0526804\ttotal: 402ms\tremaining: 1.72s\n",
      "158:\tlearn: 0.0524855\ttotal: 404ms\tremaining: 1.72s\n",
      "159:\tlearn: 0.0522726\ttotal: 407ms\tremaining: 1.71s\n",
      "160:\tlearn: 0.0520774\ttotal: 409ms\tremaining: 1.71s\n",
      "161:\tlearn: 0.0519588\ttotal: 412ms\tremaining: 1.71s\n",
      "162:\tlearn: 0.0517734\ttotal: 414ms\tremaining: 1.7s\n",
      "163:\tlearn: 0.0515742\ttotal: 417ms\tremaining: 1.7s\n",
      "164:\tlearn: 0.0513934\ttotal: 419ms\tremaining: 1.7s\n",
      "165:\tlearn: 0.0512151\ttotal: 422ms\tremaining: 1.7s\n",
      "166:\tlearn: 0.0510690\ttotal: 425ms\tremaining: 1.7s\n",
      "167:\tlearn: 0.0509190\ttotal: 427ms\tremaining: 1.69s\n",
      "168:\tlearn: 0.0508161\ttotal: 430ms\tremaining: 1.69s\n",
      "169:\tlearn: 0.0507283\ttotal: 432ms\tremaining: 1.69s\n",
      "170:\tlearn: 0.0505645\ttotal: 435ms\tremaining: 1.69s\n",
      "171:\tlearn: 0.0504162\ttotal: 437ms\tremaining: 1.68s\n",
      "172:\tlearn: 0.0502995\ttotal: 440ms\tremaining: 1.68s\n",
      "173:\tlearn: 0.0501425\ttotal: 442ms\tremaining: 1.68s\n",
      "174:\tlearn: 0.0500411\ttotal: 445ms\tremaining: 1.68s\n",
      "175:\tlearn: 0.0498714\ttotal: 447ms\tremaining: 1.67s\n",
      "176:\tlearn: 0.0497654\ttotal: 450ms\tremaining: 1.67s\n",
      "177:\tlearn: 0.0496157\ttotal: 452ms\tremaining: 1.67s\n",
      "178:\tlearn: 0.0494601\ttotal: 455ms\tremaining: 1.66s\n",
      "179:\tlearn: 0.0493209\ttotal: 457ms\tremaining: 1.66s\n",
      "180:\tlearn: 0.0492023\ttotal: 460ms\tremaining: 1.66s\n",
      "181:\tlearn: 0.0490534\ttotal: 462ms\tremaining: 1.66s\n",
      "182:\tlearn: 0.0489662\ttotal: 465ms\tremaining: 1.65s\n",
      "183:\tlearn: 0.0488956\ttotal: 467ms\tremaining: 1.65s\n",
      "184:\tlearn: 0.0487744\ttotal: 470ms\tremaining: 1.65s\n",
      "185:\tlearn: 0.0486515\ttotal: 472ms\tremaining: 1.65s\n",
      "186:\tlearn: 0.0485586\ttotal: 475ms\tremaining: 1.64s\n",
      "187:\tlearn: 0.0484450\ttotal: 477ms\tremaining: 1.64s\n",
      "188:\tlearn: 0.0483288\ttotal: 480ms\tremaining: 1.64s\n",
      "189:\tlearn: 0.0482071\ttotal: 482ms\tremaining: 1.63s\n",
      "190:\tlearn: 0.0481059\ttotal: 485ms\tremaining: 1.63s\n",
      "191:\tlearn: 0.0479934\ttotal: 487ms\tremaining: 1.63s\n",
      "192:\tlearn: 0.0478697\ttotal: 489ms\tremaining: 1.63s\n",
      "193:\tlearn: 0.0477995\ttotal: 492ms\tremaining: 1.62s\n",
      "194:\tlearn: 0.0476856\ttotal: 494ms\tremaining: 1.62s\n",
      "195:\tlearn: 0.0476066\ttotal: 497ms\tremaining: 1.62s\n",
      "196:\tlearn: 0.0475049\ttotal: 500ms\tremaining: 1.61s\n",
      "197:\tlearn: 0.0474067\ttotal: 502ms\tremaining: 1.61s\n",
      "198:\tlearn: 0.0473001\ttotal: 505ms\tremaining: 1.61s\n",
      "199:\tlearn: 0.0472391\ttotal: 507ms\tremaining: 1.61s\n",
      "200:\tlearn: 0.0471537\ttotal: 509ms\tremaining: 1.6s\n",
      "201:\tlearn: 0.0470452\ttotal: 512ms\tremaining: 1.6s\n",
      "202:\tlearn: 0.0469771\ttotal: 514ms\tremaining: 1.6s\n",
      "203:\tlearn: 0.0468873\ttotal: 517ms\tremaining: 1.6s\n",
      "204:\tlearn: 0.0468014\ttotal: 519ms\tremaining: 1.59s\n",
      "205:\tlearn: 0.0467297\ttotal: 522ms\tremaining: 1.59s\n",
      "206:\tlearn: 0.0466152\ttotal: 524ms\tremaining: 1.59s\n",
      "207:\tlearn: 0.0465584\ttotal: 527ms\tremaining: 1.58s\n",
      "208:\tlearn: 0.0464598\ttotal: 529ms\tremaining: 1.58s\n",
      "209:\tlearn: 0.0464176\ttotal: 532ms\tremaining: 1.58s\n",
      "210:\tlearn: 0.0463202\ttotal: 534ms\tremaining: 1.58s\n",
      "211:\tlearn: 0.0462351\ttotal: 537ms\tremaining: 1.57s\n",
      "212:\tlearn: 0.0461289\ttotal: 539ms\tremaining: 1.57s\n",
      "213:\tlearn: 0.0460387\ttotal: 542ms\tremaining: 1.57s\n",
      "214:\tlearn: 0.0459778\ttotal: 544ms\tremaining: 1.57s\n",
      "215:\tlearn: 0.0458776\ttotal: 547ms\tremaining: 1.56s\n",
      "216:\tlearn: 0.0458284\ttotal: 549ms\tremaining: 1.56s\n",
      "217:\tlearn: 0.0457449\ttotal: 552ms\tremaining: 1.56s\n",
      "218:\tlearn: 0.0456575\ttotal: 554ms\tremaining: 1.56s\n",
      "219:\tlearn: 0.0455813\ttotal: 557ms\tremaining: 1.55s\n",
      "220:\tlearn: 0.0455101\ttotal: 559ms\tremaining: 1.55s\n",
      "221:\tlearn: 0.0454541\ttotal: 562ms\tremaining: 1.55s\n",
      "222:\tlearn: 0.0454101\ttotal: 565ms\tremaining: 1.55s\n",
      "223:\tlearn: 0.0453431\ttotal: 568ms\tremaining: 1.54s\n",
      "224:\tlearn: 0.0452556\ttotal: 570ms\tremaining: 1.54s\n",
      "225:\tlearn: 0.0451795\ttotal: 573ms\tremaining: 1.54s\n",
      "226:\tlearn: 0.0451417\ttotal: 576ms\tremaining: 1.54s\n",
      "227:\tlearn: 0.0450919\ttotal: 578ms\tremaining: 1.54s\n",
      "228:\tlearn: 0.0450398\ttotal: 581ms\tremaining: 1.53s\n",
      "229:\tlearn: 0.0450051\ttotal: 583ms\tremaining: 1.53s\n",
      "230:\tlearn: 0.0449490\ttotal: 587ms\tremaining: 1.53s\n",
      "231:\tlearn: 0.0448656\ttotal: 589ms\tremaining: 1.53s\n",
      "232:\tlearn: 0.0448172\ttotal: 592ms\tremaining: 1.53s\n",
      "233:\tlearn: 0.0447492\ttotal: 595ms\tremaining: 1.52s\n",
      "234:\tlearn: 0.0446809\ttotal: 598ms\tremaining: 1.52s\n",
      "235:\tlearn: 0.0446212\ttotal: 601ms\tremaining: 1.52s\n",
      "236:\tlearn: 0.0445587\ttotal: 603ms\tremaining: 1.52s\n",
      "237:\tlearn: 0.0444870\ttotal: 606ms\tremaining: 1.52s\n",
      "238:\tlearn: 0.0444282\ttotal: 609ms\tremaining: 1.52s\n",
      "239:\tlearn: 0.0443583\ttotal: 612ms\tremaining: 1.51s\n",
      "240:\tlearn: 0.0443195\ttotal: 615ms\tremaining: 1.51s\n",
      "241:\tlearn: 0.0442715\ttotal: 618ms\tremaining: 1.51s\n",
      "242:\tlearn: 0.0442185\ttotal: 621ms\tremaining: 1.51s\n",
      "243:\tlearn: 0.0441276\ttotal: 624ms\tremaining: 1.51s\n",
      "244:\tlearn: 0.0440873\ttotal: 627ms\tremaining: 1.51s\n",
      "245:\tlearn: 0.0440389\ttotal: 630ms\tremaining: 1.51s\n",
      "246:\tlearn: 0.0439873\ttotal: 634ms\tremaining: 1.5s\n",
      "247:\tlearn: 0.0439066\ttotal: 637ms\tremaining: 1.5s\n",
      "248:\tlearn: 0.0438404\ttotal: 644ms\tremaining: 1.51s\n",
      "249:\tlearn: 0.0437947\ttotal: 649ms\tremaining: 1.52s\n",
      "250:\tlearn: 0.0437490\ttotal: 653ms\tremaining: 1.52s\n",
      "251:\tlearn: 0.0437066\ttotal: 656ms\tremaining: 1.51s\n",
      "252:\tlearn: 0.0436575\ttotal: 660ms\tremaining: 1.51s\n",
      "253:\tlearn: 0.0436003\ttotal: 665ms\tremaining: 1.52s\n",
      "254:\tlearn: 0.0434664\ttotal: 668ms\tremaining: 1.52s\n",
      "255:\tlearn: 0.0434393\ttotal: 672ms\tremaining: 1.52s\n",
      "256:\tlearn: 0.0433820\ttotal: 676ms\tremaining: 1.52s\n",
      "257:\tlearn: 0.0433273\ttotal: 681ms\tremaining: 1.52s\n",
      "258:\tlearn: 0.0432613\ttotal: 684ms\tremaining: 1.52s\n",
      "259:\tlearn: 0.0432103\ttotal: 687ms\tremaining: 1.52s\n",
      "260:\tlearn: 0.0431587\ttotal: 690ms\tremaining: 1.51s\n",
      "261:\tlearn: 0.0431324\ttotal: 693ms\tremaining: 1.51s\n",
      "262:\tlearn: 0.0430520\ttotal: 697ms\tremaining: 1.51s\n",
      "263:\tlearn: 0.0429825\ttotal: 699ms\tremaining: 1.51s\n",
      "264:\tlearn: 0.0429456\ttotal: 702ms\tremaining: 1.51s\n",
      "265:\tlearn: 0.0429116\ttotal: 705ms\tremaining: 1.5s\n",
      "266:\tlearn: 0.0428527\ttotal: 708ms\tremaining: 1.5s\n",
      "267:\tlearn: 0.0427974\ttotal: 711ms\tremaining: 1.5s\n",
      "268:\tlearn: 0.0426854\ttotal: 714ms\tremaining: 1.5s\n",
      "269:\tlearn: 0.0426405\ttotal: 717ms\tremaining: 1.5s\n",
      "270:\tlearn: 0.0426104\ttotal: 721ms\tremaining: 1.5s\n",
      "271:\tlearn: 0.0425513\ttotal: 724ms\tremaining: 1.49s\n",
      "272:\tlearn: 0.0425208\ttotal: 727ms\tremaining: 1.49s\n",
      "273:\tlearn: 0.0424648\ttotal: 730ms\tremaining: 1.49s\n",
      "274:\tlearn: 0.0424090\ttotal: 733ms\tremaining: 1.49s\n",
      "275:\tlearn: 0.0423828\ttotal: 736ms\tremaining: 1.49s\n",
      "276:\tlearn: 0.0423281\ttotal: 739ms\tremaining: 1.49s\n",
      "277:\tlearn: 0.0422759\ttotal: 743ms\tremaining: 1.49s\n",
      "278:\tlearn: 0.0422421\ttotal: 746ms\tremaining: 1.48s\n",
      "279:\tlearn: 0.0422153\ttotal: 749ms\tremaining: 1.48s\n",
      "280:\tlearn: 0.0421742\ttotal: 752ms\tremaining: 1.48s\n",
      "281:\tlearn: 0.0421438\ttotal: 755ms\tremaining: 1.48s\n",
      "282:\tlearn: 0.0421269\ttotal: 758ms\tremaining: 1.48s\n",
      "283:\tlearn: 0.0420994\ttotal: 761ms\tremaining: 1.47s\n",
      "284:\tlearn: 0.0420636\ttotal: 764ms\tremaining: 1.47s\n",
      "285:\tlearn: 0.0420282\ttotal: 767ms\tremaining: 1.47s\n",
      "286:\tlearn: 0.0419961\ttotal: 770ms\tremaining: 1.47s\n",
      "287:\tlearn: 0.0419625\ttotal: 774ms\tremaining: 1.47s\n",
      "288:\tlearn: 0.0419472\ttotal: 777ms\tremaining: 1.47s\n",
      "289:\tlearn: 0.0418948\ttotal: 780ms\tremaining: 1.46s\n",
      "290:\tlearn: 0.0418818\ttotal: 783ms\tremaining: 1.46s\n",
      "291:\tlearn: 0.0418340\ttotal: 786ms\tremaining: 1.46s\n",
      "292:\tlearn: 0.0417964\ttotal: 789ms\tremaining: 1.46s\n",
      "293:\tlearn: 0.0417494\ttotal: 792ms\tremaining: 1.45s\n",
      "294:\tlearn: 0.0417156\ttotal: 795ms\tremaining: 1.45s\n",
      "295:\tlearn: 0.0416645\ttotal: 797ms\tremaining: 1.45s\n",
      "296:\tlearn: 0.0416341\ttotal: 800ms\tremaining: 1.45s\n",
      "297:\tlearn: 0.0416084\ttotal: 802ms\tremaining: 1.44s\n",
      "298:\tlearn: 0.0415595\ttotal: 805ms\tremaining: 1.44s\n",
      "299:\tlearn: 0.0414543\ttotal: 809ms\tremaining: 1.44s\n",
      "300:\tlearn: 0.0414231\ttotal: 811ms\tremaining: 1.44s\n",
      "301:\tlearn: 0.0413972\ttotal: 814ms\tremaining: 1.43s\n",
      "302:\tlearn: 0.0413196\ttotal: 817ms\tremaining: 1.43s\n",
      "303:\tlearn: 0.0412743\ttotal: 821ms\tremaining: 1.43s\n",
      "304:\tlearn: 0.0412349\ttotal: 823ms\tremaining: 1.43s\n",
      "305:\tlearn: 0.0412082\ttotal: 826ms\tremaining: 1.43s\n",
      "306:\tlearn: 0.0411745\ttotal: 829ms\tremaining: 1.42s\n",
      "307:\tlearn: 0.0411113\ttotal: 832ms\tremaining: 1.42s\n",
      "308:\tlearn: 0.0410630\ttotal: 835ms\tremaining: 1.42s\n",
      "309:\tlearn: 0.0410328\ttotal: 838ms\tremaining: 1.42s\n",
      "310:\tlearn: 0.0410081\ttotal: 841ms\tremaining: 1.41s\n",
      "311:\tlearn: 0.0409850\ttotal: 845ms\tremaining: 1.41s\n",
      "312:\tlearn: 0.0409389\ttotal: 848ms\tremaining: 1.41s\n",
      "313:\tlearn: 0.0409107\ttotal: 853ms\tremaining: 1.41s\n",
      "314:\tlearn: 0.0408760\ttotal: 857ms\tremaining: 1.41s\n",
      "315:\tlearn: 0.0408370\ttotal: 867ms\tremaining: 1.42s\n",
      "316:\tlearn: 0.0408071\ttotal: 870ms\tremaining: 1.42s\n",
      "317:\tlearn: 0.0407707\ttotal: 873ms\tremaining: 1.42s\n",
      "318:\tlearn: 0.0407419\ttotal: 876ms\tremaining: 1.41s\n",
      "319:\tlearn: 0.0406934\ttotal: 879ms\tremaining: 1.41s\n",
      "320:\tlearn: 0.0406658\ttotal: 882ms\tremaining: 1.41s\n",
      "321:\tlearn: 0.0406474\ttotal: 885ms\tremaining: 1.41s\n",
      "322:\tlearn: 0.0406184\ttotal: 888ms\tremaining: 1.4s\n",
      "323:\tlearn: 0.0405792\ttotal: 891ms\tremaining: 1.4s\n",
      "324:\tlearn: 0.0405461\ttotal: 895ms\tremaining: 1.4s\n",
      "325:\tlearn: 0.0404509\ttotal: 898ms\tremaining: 1.4s\n",
      "326:\tlearn: 0.0404038\ttotal: 901ms\tremaining: 1.4s\n",
      "327:\tlearn: 0.0403790\ttotal: 904ms\tremaining: 1.4s\n",
      "328:\tlearn: 0.0403531\ttotal: 907ms\tremaining: 1.39s\n",
      "329:\tlearn: 0.0403206\ttotal: 911ms\tremaining: 1.39s\n",
      "330:\tlearn: 0.0402967\ttotal: 915ms\tremaining: 1.39s\n",
      "331:\tlearn: 0.0402488\ttotal: 918ms\tremaining: 1.39s\n",
      "332:\tlearn: 0.0402378\ttotal: 921ms\tremaining: 1.39s\n",
      "333:\tlearn: 0.0401914\ttotal: 924ms\tremaining: 1.38s\n",
      "334:\tlearn: 0.0401564\ttotal: 927ms\tremaining: 1.38s\n",
      "335:\tlearn: 0.0401125\ttotal: 931ms\tremaining: 1.38s\n",
      "336:\tlearn: 0.0400844\ttotal: 934ms\tremaining: 1.38s\n",
      "337:\tlearn: 0.0400378\ttotal: 937ms\tremaining: 1.37s\n",
      "338:\tlearn: 0.0400008\ttotal: 940ms\tremaining: 1.37s\n",
      "339:\tlearn: 0.0399460\ttotal: 943ms\tremaining: 1.37s\n",
      "340:\tlearn: 0.0399284\ttotal: 947ms\tremaining: 1.37s\n",
      "341:\tlearn: 0.0398883\ttotal: 950ms\tremaining: 1.37s\n",
      "342:\tlearn: 0.0398623\ttotal: 953ms\tremaining: 1.36s\n",
      "343:\tlearn: 0.0398304\ttotal: 956ms\tremaining: 1.36s\n",
      "344:\tlearn: 0.0397888\ttotal: 959ms\tremaining: 1.36s\n",
      "345:\tlearn: 0.0397700\ttotal: 963ms\tremaining: 1.36s\n",
      "346:\tlearn: 0.0397513\ttotal: 966ms\tremaining: 1.35s\n",
      "347:\tlearn: 0.0397046\ttotal: 969ms\tremaining: 1.35s\n",
      "348:\tlearn: 0.0396598\ttotal: 972ms\tremaining: 1.35s\n",
      "349:\tlearn: 0.0395815\ttotal: 976ms\tremaining: 1.35s\n",
      "350:\tlearn: 0.0395520\ttotal: 979ms\tremaining: 1.35s\n",
      "351:\tlearn: 0.0395182\ttotal: 982ms\tremaining: 1.34s\n",
      "352:\tlearn: 0.0394998\ttotal: 985ms\tremaining: 1.34s\n",
      "353:\tlearn: 0.0394579\ttotal: 988ms\tremaining: 1.34s\n",
      "354:\tlearn: 0.0394053\ttotal: 991ms\tremaining: 1.34s\n",
      "355:\tlearn: 0.0393824\ttotal: 994ms\tremaining: 1.33s\n",
      "356:\tlearn: 0.0393401\ttotal: 997ms\tremaining: 1.33s\n",
      "357:\tlearn: 0.0393221\ttotal: 1s\tremaining: 1.33s\n",
      "358:\tlearn: 0.0392916\ttotal: 1s\tremaining: 1.33s\n",
      "359:\tlearn: 0.0392625\ttotal: 1s\tremaining: 1.32s\n",
      "360:\tlearn: 0.0392480\ttotal: 1.01s\tremaining: 1.32s\n",
      "361:\tlearn: 0.0391907\ttotal: 1.01s\tremaining: 1.32s\n",
      "362:\tlearn: 0.0391585\ttotal: 1.01s\tremaining: 1.32s\n",
      "363:\tlearn: 0.0391374\ttotal: 1.02s\tremaining: 1.31s\n",
      "364:\tlearn: 0.0391229\ttotal: 1.02s\tremaining: 1.31s\n",
      "365:\tlearn: 0.0391039\ttotal: 1.02s\tremaining: 1.31s\n",
      "366:\tlearn: 0.0390740\ttotal: 1.03s\tremaining: 1.3s\n",
      "367:\tlearn: 0.0390409\ttotal: 1.03s\tremaining: 1.3s\n",
      "368:\tlearn: 0.0390139\ttotal: 1.03s\tremaining: 1.3s\n",
      "369:\tlearn: 0.0389953\ttotal: 1.03s\tremaining: 1.3s\n",
      "370:\tlearn: 0.0389526\ttotal: 1.04s\tremaining: 1.29s\n",
      "371:\tlearn: 0.0389146\ttotal: 1.04s\tremaining: 1.29s\n",
      "372:\tlearn: 0.0389012\ttotal: 1.04s\tremaining: 1.29s\n",
      "373:\tlearn: 0.0388894\ttotal: 1.04s\tremaining: 1.28s\n",
      "374:\tlearn: 0.0388590\ttotal: 1.05s\tremaining: 1.28s\n",
      "375:\tlearn: 0.0388405\ttotal: 1.05s\tremaining: 1.28s\n",
      "376:\tlearn: 0.0388249\ttotal: 1.05s\tremaining: 1.28s\n",
      "377:\tlearn: 0.0388075\ttotal: 1.06s\tremaining: 1.27s\n",
      "378:\tlearn: 0.0387918\ttotal: 1.06s\tremaining: 1.27s\n",
      "379:\tlearn: 0.0387667\ttotal: 1.06s\tremaining: 1.27s\n",
      "380:\tlearn: 0.0387568\ttotal: 1.06s\tremaining: 1.27s\n",
      "381:\tlearn: 0.0387408\ttotal: 1.07s\tremaining: 1.26s\n",
      "382:\tlearn: 0.0387010\ttotal: 1.07s\tremaining: 1.26s\n",
      "383:\tlearn: 0.0386591\ttotal: 1.07s\tremaining: 1.26s\n",
      "384:\tlearn: 0.0386462\ttotal: 1.08s\tremaining: 1.25s\n",
      "385:\tlearn: 0.0386151\ttotal: 1.08s\tremaining: 1.25s\n",
      "386:\tlearn: 0.0385763\ttotal: 1.08s\tremaining: 1.25s\n",
      "387:\tlearn: 0.0385644\ttotal: 1.08s\tremaining: 1.25s\n",
      "388:\tlearn: 0.0385459\ttotal: 1.09s\tremaining: 1.25s\n",
      "389:\tlearn: 0.0385337\ttotal: 1.09s\tremaining: 1.24s\n",
      "390:\tlearn: 0.0384986\ttotal: 1.09s\tremaining: 1.24s\n",
      "391:\tlearn: 0.0384791\ttotal: 1.1s\tremaining: 1.24s\n",
      "392:\tlearn: 0.0384461\ttotal: 1.1s\tremaining: 1.23s\n",
      "393:\tlearn: 0.0384218\ttotal: 1.1s\tremaining: 1.23s\n",
      "394:\tlearn: 0.0383652\ttotal: 1.1s\tremaining: 1.23s\n",
      "395:\tlearn: 0.0383421\ttotal: 1.11s\tremaining: 1.23s\n",
      "396:\tlearn: 0.0383271\ttotal: 1.11s\tremaining: 1.22s\n",
      "397:\tlearn: 0.0382987\ttotal: 1.12s\tremaining: 1.22s\n",
      "398:\tlearn: 0.0382739\ttotal: 1.12s\tremaining: 1.22s\n",
      "399:\tlearn: 0.0382561\ttotal: 1.12s\tremaining: 1.22s\n",
      "400:\tlearn: 0.0382277\ttotal: 1.13s\tremaining: 1.22s\n",
      "401:\tlearn: 0.0382172\ttotal: 1.13s\tremaining: 1.21s\n",
      "402:\tlearn: 0.0381993\ttotal: 1.13s\tremaining: 1.21s\n",
      "403:\tlearn: 0.0381873\ttotal: 1.14s\tremaining: 1.21s\n",
      "404:\tlearn: 0.0381596\ttotal: 1.14s\tremaining: 1.21s\n",
      "405:\tlearn: 0.0381332\ttotal: 1.14s\tremaining: 1.2s\n",
      "406:\tlearn: 0.0381011\ttotal: 1.14s\tremaining: 1.2s\n",
      "407:\tlearn: 0.0380622\ttotal: 1.15s\tremaining: 1.2s\n",
      "408:\tlearn: 0.0380382\ttotal: 1.15s\tremaining: 1.19s\n",
      "409:\tlearn: 0.0380002\ttotal: 1.15s\tremaining: 1.19s\n",
      "410:\tlearn: 0.0379811\ttotal: 1.16s\tremaining: 1.19s\n",
      "411:\tlearn: 0.0379682\ttotal: 1.16s\tremaining: 1.19s\n",
      "412:\tlearn: 0.0379533\ttotal: 1.16s\tremaining: 1.18s\n",
      "413:\tlearn: 0.0379068\ttotal: 1.16s\tremaining: 1.18s\n",
      "414:\tlearn: 0.0378888\ttotal: 1.17s\tremaining: 1.18s\n",
      "415:\tlearn: 0.0378543\ttotal: 1.17s\tremaining: 1.17s\n",
      "416:\tlearn: 0.0378292\ttotal: 1.17s\tremaining: 1.17s\n",
      "417:\tlearn: 0.0378017\ttotal: 1.17s\tremaining: 1.17s\n",
      "418:\tlearn: 0.0377869\ttotal: 1.18s\tremaining: 1.17s\n",
      "419:\tlearn: 0.0377732\ttotal: 1.18s\tremaining: 1.16s\n",
      "420:\tlearn: 0.0377526\ttotal: 1.18s\tremaining: 1.16s\n",
      "421:\tlearn: 0.0377389\ttotal: 1.18s\tremaining: 1.16s\n",
      "422:\tlearn: 0.0377020\ttotal: 1.19s\tremaining: 1.15s\n",
      "423:\tlearn: 0.0376874\ttotal: 1.19s\tremaining: 1.15s\n",
      "424:\tlearn: 0.0376670\ttotal: 1.19s\tremaining: 1.15s\n",
      "425:\tlearn: 0.0376503\ttotal: 1.2s\tremaining: 1.15s\n",
      "426:\tlearn: 0.0376181\ttotal: 1.2s\tremaining: 1.14s\n",
      "427:\tlearn: 0.0375980\ttotal: 1.2s\tremaining: 1.14s\n",
      "428:\tlearn: 0.0375686\ttotal: 1.21s\tremaining: 1.14s\n",
      "429:\tlearn: 0.0375480\ttotal: 1.21s\tremaining: 1.14s\n",
      "430:\tlearn: 0.0375124\ttotal: 1.21s\tremaining: 1.13s\n",
      "431:\tlearn: 0.0374666\ttotal: 1.21s\tremaining: 1.13s\n",
      "432:\tlearn: 0.0374492\ttotal: 1.22s\tremaining: 1.13s\n",
      "433:\tlearn: 0.0374223\ttotal: 1.22s\tremaining: 1.12s\n",
      "434:\tlearn: 0.0374065\ttotal: 1.22s\tremaining: 1.12s\n",
      "435:\tlearn: 0.0373813\ttotal: 1.23s\tremaining: 1.12s\n",
      "436:\tlearn: 0.0373529\ttotal: 1.23s\tremaining: 1.12s\n",
      "437:\tlearn: 0.0373350\ttotal: 1.23s\tremaining: 1.11s\n",
      "438:\tlearn: 0.0373220\ttotal: 1.23s\tremaining: 1.11s\n",
      "439:\tlearn: 0.0373049\ttotal: 1.24s\tremaining: 1.11s\n",
      "440:\tlearn: 0.0372506\ttotal: 1.24s\tremaining: 1.1s\n",
      "441:\tlearn: 0.0372217\ttotal: 1.24s\tremaining: 1.1s\n",
      "442:\tlearn: 0.0372069\ttotal: 1.24s\tremaining: 1.1s\n",
      "443:\tlearn: 0.0371877\ttotal: 1.25s\tremaining: 1.09s\n",
      "444:\tlearn: 0.0371730\ttotal: 1.25s\tremaining: 1.09s\n",
      "445:\tlearn: 0.0371480\ttotal: 1.25s\tremaining: 1.09s\n",
      "446:\tlearn: 0.0371313\ttotal: 1.25s\tremaining: 1.09s\n",
      "447:\tlearn: 0.0371129\ttotal: 1.26s\tremaining: 1.08s\n",
      "448:\tlearn: 0.0370969\ttotal: 1.26s\tremaining: 1.08s\n",
      "449:\tlearn: 0.0370460\ttotal: 1.26s\tremaining: 1.08s\n",
      "450:\tlearn: 0.0370258\ttotal: 1.27s\tremaining: 1.07s\n",
      "451:\tlearn: 0.0370094\ttotal: 1.27s\tremaining: 1.07s\n",
      "452:\tlearn: 0.0370020\ttotal: 1.27s\tremaining: 1.07s\n",
      "453:\tlearn: 0.0369699\ttotal: 1.27s\tremaining: 1.07s\n",
      "454:\tlearn: 0.0369576\ttotal: 1.28s\tremaining: 1.06s\n",
      "455:\tlearn: 0.0369375\ttotal: 1.28s\tremaining: 1.06s\n",
      "456:\tlearn: 0.0369241\ttotal: 1.28s\tremaining: 1.06s\n",
      "457:\tlearn: 0.0369018\ttotal: 1.28s\tremaining: 1.05s\n",
      "458:\tlearn: 0.0368699\ttotal: 1.29s\tremaining: 1.05s\n",
      "459:\tlearn: 0.0368405\ttotal: 1.29s\tremaining: 1.05s\n",
      "460:\tlearn: 0.0368219\ttotal: 1.29s\tremaining: 1.05s\n",
      "461:\tlearn: 0.0368031\ttotal: 1.29s\tremaining: 1.04s\n",
      "462:\tlearn: 0.0367949\ttotal: 1.3s\tremaining: 1.04s\n",
      "463:\tlearn: 0.0367792\ttotal: 1.3s\tremaining: 1.04s\n",
      "464:\tlearn: 0.0367659\ttotal: 1.3s\tremaining: 1.03s\n",
      "465:\tlearn: 0.0367496\ttotal: 1.31s\tremaining: 1.03s\n",
      "466:\tlearn: 0.0367350\ttotal: 1.31s\tremaining: 1.03s\n",
      "467:\tlearn: 0.0367254\ttotal: 1.31s\tremaining: 1.03s\n",
      "468:\tlearn: 0.0367004\ttotal: 1.31s\tremaining: 1.02s\n",
      "469:\tlearn: 0.0366912\ttotal: 1.32s\tremaining: 1.02s\n",
      "470:\tlearn: 0.0366820\ttotal: 1.32s\tremaining: 1.02s\n",
      "471:\tlearn: 0.0366671\ttotal: 1.32s\tremaining: 1.01s\n",
      "472:\tlearn: 0.0366517\ttotal: 1.32s\tremaining: 1.01s\n",
      "473:\tlearn: 0.0366379\ttotal: 1.33s\tremaining: 1.01s\n",
      "474:\tlearn: 0.0366133\ttotal: 1.33s\tremaining: 1s\n",
      "475:\tlearn: 0.0365805\ttotal: 1.33s\tremaining: 1s\n",
      "476:\tlearn: 0.0365626\ttotal: 1.33s\tremaining: 1000ms\n",
      "477:\tlearn: 0.0365539\ttotal: 1.34s\tremaining: 997ms\n",
      "478:\tlearn: 0.0365378\ttotal: 1.34s\tremaining: 994ms\n",
      "479:\tlearn: 0.0364751\ttotal: 1.34s\tremaining: 991ms\n",
      "480:\tlearn: 0.0364605\ttotal: 1.35s\tremaining: 988ms\n",
      "481:\tlearn: 0.0364420\ttotal: 1.35s\tremaining: 985ms\n",
      "482:\tlearn: 0.0364283\ttotal: 1.35s\tremaining: 982ms\n",
      "483:\tlearn: 0.0364191\ttotal: 1.35s\tremaining: 980ms\n",
      "484:\tlearn: 0.0364083\ttotal: 1.36s\tremaining: 977ms\n",
      "485:\tlearn: 0.0363928\ttotal: 1.36s\tremaining: 974ms\n",
      "486:\tlearn: 0.0363820\ttotal: 1.36s\tremaining: 971ms\n",
      "487:\tlearn: 0.0363588\ttotal: 1.36s\tremaining: 968ms\n",
      "488:\tlearn: 0.0363316\ttotal: 1.37s\tremaining: 965ms\n",
      "489:\tlearn: 0.0363262\ttotal: 1.37s\tremaining: 962ms\n",
      "490:\tlearn: 0.0363092\ttotal: 1.37s\tremaining: 959ms\n",
      "491:\tlearn: 0.0362898\ttotal: 1.38s\tremaining: 956ms\n",
      "492:\tlearn: 0.0362772\ttotal: 1.38s\tremaining: 953ms\n",
      "493:\tlearn: 0.0362640\ttotal: 1.38s\tremaining: 950ms\n",
      "494:\tlearn: 0.0362343\ttotal: 1.38s\tremaining: 948ms\n",
      "495:\tlearn: 0.0362202\ttotal: 1.39s\tremaining: 946ms\n",
      "496:\tlearn: 0.0362027\ttotal: 1.39s\tremaining: 943ms\n",
      "497:\tlearn: 0.0361793\ttotal: 1.39s\tremaining: 940ms\n",
      "498:\tlearn: 0.0361638\ttotal: 1.4s\tremaining: 938ms\n",
      "499:\tlearn: 0.0361476\ttotal: 1.4s\tremaining: 935ms\n",
      "500:\tlearn: 0.0361325\ttotal: 1.4s\tremaining: 932ms\n",
      "501:\tlearn: 0.0361164\ttotal: 1.41s\tremaining: 930ms\n",
      "502:\tlearn: 0.0360928\ttotal: 1.41s\tremaining: 927ms\n",
      "503:\tlearn: 0.0360813\ttotal: 1.41s\tremaining: 924ms\n",
      "504:\tlearn: 0.0360585\ttotal: 1.41s\tremaining: 921ms\n",
      "505:\tlearn: 0.0360297\ttotal: 1.42s\tremaining: 919ms\n",
      "506:\tlearn: 0.0360033\ttotal: 1.42s\tremaining: 916ms\n",
      "507:\tlearn: 0.0359929\ttotal: 1.42s\tremaining: 913ms\n",
      "508:\tlearn: 0.0359810\ttotal: 1.43s\tremaining: 911ms\n",
      "509:\tlearn: 0.0359673\ttotal: 1.43s\tremaining: 908ms\n",
      "510:\tlearn: 0.0359526\ttotal: 1.43s\tremaining: 906ms\n",
      "511:\tlearn: 0.0359434\ttotal: 1.44s\tremaining: 903ms\n",
      "512:\tlearn: 0.0359204\ttotal: 1.44s\tremaining: 900ms\n",
      "513:\tlearn: 0.0359101\ttotal: 1.44s\tremaining: 897ms\n",
      "514:\tlearn: 0.0358893\ttotal: 1.44s\tremaining: 895ms\n",
      "515:\tlearn: 0.0358745\ttotal: 1.45s\tremaining: 892ms\n",
      "516:\tlearn: 0.0358553\ttotal: 1.45s\tremaining: 889ms\n",
      "517:\tlearn: 0.0358419\ttotal: 1.45s\tremaining: 886ms\n",
      "518:\tlearn: 0.0358311\ttotal: 1.46s\tremaining: 883ms\n",
      "519:\tlearn: 0.0358188\ttotal: 1.46s\tremaining: 880ms\n",
      "520:\tlearn: 0.0358035\ttotal: 1.46s\tremaining: 878ms\n",
      "521:\tlearn: 0.0357896\ttotal: 1.46s\tremaining: 875ms\n",
      "522:\tlearn: 0.0357689\ttotal: 1.47s\tremaining: 872ms\n",
      "523:\tlearn: 0.0357418\ttotal: 1.47s\tremaining: 869ms\n",
      "524:\tlearn: 0.0357285\ttotal: 1.47s\tremaining: 866ms\n",
      "525:\tlearn: 0.0357093\ttotal: 1.47s\tremaining: 864ms\n",
      "526:\tlearn: 0.0356958\ttotal: 1.48s\tremaining: 861ms\n",
      "527:\tlearn: 0.0356780\ttotal: 1.48s\tremaining: 858ms\n",
      "528:\tlearn: 0.0356338\ttotal: 1.48s\tremaining: 855ms\n",
      "529:\tlearn: 0.0356106\ttotal: 1.49s\tremaining: 852ms\n",
      "530:\tlearn: 0.0355720\ttotal: 1.49s\tremaining: 850ms\n",
      "531:\tlearn: 0.0355549\ttotal: 1.49s\tremaining: 847ms\n",
      "532:\tlearn: 0.0355427\ttotal: 1.5s\tremaining: 845ms\n",
      "533:\tlearn: 0.0355338\ttotal: 1.5s\tremaining: 842ms\n",
      "534:\tlearn: 0.0355185\ttotal: 1.5s\tremaining: 839ms\n",
      "535:\tlearn: 0.0355081\ttotal: 1.5s\tremaining: 836ms\n",
      "536:\tlearn: 0.0354996\ttotal: 1.51s\tremaining: 833ms\n",
      "537:\tlearn: 0.0354681\ttotal: 1.51s\tremaining: 830ms\n",
      "538:\tlearn: 0.0354521\ttotal: 1.51s\tremaining: 827ms\n",
      "539:\tlearn: 0.0354323\ttotal: 1.51s\tremaining: 824ms\n",
      "540:\tlearn: 0.0354176\ttotal: 1.52s\tremaining: 822ms\n",
      "541:\tlearn: 0.0354008\ttotal: 1.52s\tremaining: 819ms\n",
      "542:\tlearn: 0.0353887\ttotal: 1.52s\tremaining: 816ms\n",
      "543:\tlearn: 0.0353658\ttotal: 1.52s\tremaining: 813ms\n",
      "544:\tlearn: 0.0353428\ttotal: 1.53s\tremaining: 810ms\n",
      "545:\tlearn: 0.0353300\ttotal: 1.53s\tremaining: 807ms\n",
      "546:\tlearn: 0.0353009\ttotal: 1.53s\tremaining: 804ms\n",
      "547:\tlearn: 0.0352958\ttotal: 1.53s\tremaining: 801ms\n",
      "548:\tlearn: 0.0352821\ttotal: 1.54s\tremaining: 798ms\n",
      "549:\tlearn: 0.0352694\ttotal: 1.54s\tremaining: 796ms\n",
      "550:\tlearn: 0.0352444\ttotal: 1.54s\tremaining: 793ms\n",
      "551:\tlearn: 0.0352324\ttotal: 1.54s\tremaining: 790ms\n",
      "552:\tlearn: 0.0352189\ttotal: 1.55s\tremaining: 787ms\n",
      "553:\tlearn: 0.0352106\ttotal: 1.55s\tremaining: 784ms\n",
      "554:\tlearn: 0.0352015\ttotal: 1.55s\tremaining: 781ms\n",
      "555:\tlearn: 0.0351854\ttotal: 1.56s\tremaining: 778ms\n",
      "556:\tlearn: 0.0351635\ttotal: 1.56s\tremaining: 776ms\n",
      "557:\tlearn: 0.0351535\ttotal: 1.56s\tremaining: 773ms\n",
      "558:\tlearn: 0.0351336\ttotal: 1.56s\tremaining: 770ms\n",
      "559:\tlearn: 0.0351201\ttotal: 1.57s\tremaining: 767ms\n",
      "560:\tlearn: 0.0350891\ttotal: 1.57s\tremaining: 764ms\n",
      "561:\tlearn: 0.0350739\ttotal: 1.57s\tremaining: 761ms\n",
      "562:\tlearn: 0.0350477\ttotal: 1.57s\tremaining: 758ms\n",
      "563:\tlearn: 0.0350356\ttotal: 1.58s\tremaining: 756ms\n",
      "564:\tlearn: 0.0350179\ttotal: 1.58s\tremaining: 753ms\n",
      "565:\tlearn: 0.0350067\ttotal: 1.58s\tremaining: 750ms\n",
      "566:\tlearn: 0.0349888\ttotal: 1.59s\tremaining: 747ms\n",
      "567:\tlearn: 0.0349613\ttotal: 1.59s\tremaining: 744ms\n",
      "568:\tlearn: 0.0349463\ttotal: 1.59s\tremaining: 741ms\n",
      "569:\tlearn: 0.0349202\ttotal: 1.59s\tremaining: 739ms\n",
      "570:\tlearn: 0.0349108\ttotal: 1.6s\tremaining: 736ms\n",
      "571:\tlearn: 0.0348916\ttotal: 1.6s\tremaining: 733ms\n",
      "572:\tlearn: 0.0348804\ttotal: 1.6s\tremaining: 730ms\n",
      "573:\tlearn: 0.0348664\ttotal: 1.61s\tremaining: 728ms\n",
      "574:\tlearn: 0.0348472\ttotal: 1.61s\tremaining: 726ms\n",
      "575:\tlearn: 0.0348334\ttotal: 1.61s\tremaining: 723ms\n",
      "576:\tlearn: 0.0348150\ttotal: 1.62s\tremaining: 721ms\n",
      "577:\tlearn: 0.0347970\ttotal: 1.62s\tremaining: 718ms\n",
      "578:\tlearn: 0.0347812\ttotal: 1.62s\tremaining: 715ms\n",
      "579:\tlearn: 0.0347700\ttotal: 1.63s\tremaining: 712ms\n",
      "580:\tlearn: 0.0347550\ttotal: 1.63s\tremaining: 709ms\n",
      "581:\tlearn: 0.0347390\ttotal: 1.63s\tremaining: 706ms\n",
      "582:\tlearn: 0.0347185\ttotal: 1.63s\tremaining: 704ms\n",
      "583:\tlearn: 0.0347052\ttotal: 1.64s\tremaining: 701ms\n",
      "584:\tlearn: 0.0346947\ttotal: 1.64s\tremaining: 698ms\n",
      "585:\tlearn: 0.0346731\ttotal: 1.64s\tremaining: 695ms\n",
      "586:\tlearn: 0.0346542\ttotal: 1.64s\tremaining: 692ms\n",
      "587:\tlearn: 0.0346406\ttotal: 1.65s\tremaining: 689ms\n",
      "588:\tlearn: 0.0346225\ttotal: 1.65s\tremaining: 686ms\n",
      "589:\tlearn: 0.0346042\ttotal: 1.65s\tremaining: 683ms\n",
      "590:\tlearn: 0.0345871\ttotal: 1.65s\tremaining: 680ms\n",
      "591:\tlearn: 0.0345767\ttotal: 1.66s\tremaining: 677ms\n",
      "592:\tlearn: 0.0345498\ttotal: 1.66s\tremaining: 675ms\n",
      "593:\tlearn: 0.0345310\ttotal: 1.66s\tremaining: 672ms\n",
      "594:\tlearn: 0.0345232\ttotal: 1.66s\tremaining: 669ms\n",
      "595:\tlearn: 0.0345080\ttotal: 1.67s\tremaining: 666ms\n",
      "596:\tlearn: 0.0344877\ttotal: 1.67s\tremaining: 663ms\n",
      "597:\tlearn: 0.0344708\ttotal: 1.67s\tremaining: 660ms\n",
      "598:\tlearn: 0.0344576\ttotal: 1.68s\tremaining: 657ms\n",
      "599:\tlearn: 0.0344479\ttotal: 1.68s\tremaining: 654ms\n",
      "600:\tlearn: 0.0344324\ttotal: 1.68s\tremaining: 652ms\n",
      "601:\tlearn: 0.0344132\ttotal: 1.68s\tremaining: 649ms\n",
      "602:\tlearn: 0.0343622\ttotal: 1.69s\tremaining: 646ms\n",
      "603:\tlearn: 0.0343476\ttotal: 1.69s\tremaining: 643ms\n",
      "604:\tlearn: 0.0343278\ttotal: 1.69s\tremaining: 640ms\n",
      "605:\tlearn: 0.0343053\ttotal: 1.69s\tremaining: 637ms\n",
      "606:\tlearn: 0.0342947\ttotal: 1.7s\tremaining: 634ms\n",
      "607:\tlearn: 0.0342831\ttotal: 1.7s\tremaining: 631ms\n",
      "608:\tlearn: 0.0342686\ttotal: 1.7s\tremaining: 629ms\n",
      "609:\tlearn: 0.0342453\ttotal: 1.7s\tremaining: 626ms\n",
      "610:\tlearn: 0.0342355\ttotal: 1.71s\tremaining: 623ms\n",
      "611:\tlearn: 0.0342273\ttotal: 1.71s\tremaining: 620ms\n",
      "612:\tlearn: 0.0342170\ttotal: 1.71s\tremaining: 617ms\n",
      "613:\tlearn: 0.0342066\ttotal: 1.71s\tremaining: 614ms\n",
      "614:\tlearn: 0.0341825\ttotal: 1.72s\tremaining: 611ms\n",
      "615:\tlearn: 0.0341735\ttotal: 1.72s\tremaining: 609ms\n",
      "616:\tlearn: 0.0341613\ttotal: 1.72s\tremaining: 606ms\n",
      "617:\tlearn: 0.0341356\ttotal: 1.72s\tremaining: 603ms\n",
      "618:\tlearn: 0.0341222\ttotal: 1.73s\tremaining: 600ms\n",
      "619:\tlearn: 0.0341095\ttotal: 1.73s\tremaining: 597ms\n",
      "620:\tlearn: 0.0340935\ttotal: 1.73s\tremaining: 594ms\n",
      "621:\tlearn: 0.0340892\ttotal: 1.73s\tremaining: 591ms\n",
      "622:\tlearn: 0.0340723\ttotal: 1.74s\tremaining: 588ms\n",
      "623:\tlearn: 0.0340619\ttotal: 1.74s\tremaining: 586ms\n",
      "624:\tlearn: 0.0340403\ttotal: 1.74s\tremaining: 583ms\n",
      "625:\tlearn: 0.0340241\ttotal: 1.75s\tremaining: 580ms\n",
      "626:\tlearn: 0.0340087\ttotal: 1.75s\tremaining: 577ms\n",
      "627:\tlearn: 0.0339883\ttotal: 1.75s\tremaining: 574ms\n",
      "628:\tlearn: 0.0339713\ttotal: 1.75s\tremaining: 571ms\n",
      "629:\tlearn: 0.0339618\ttotal: 1.76s\tremaining: 569ms\n",
      "630:\tlearn: 0.0339509\ttotal: 1.76s\tremaining: 566ms\n",
      "631:\tlearn: 0.0339406\ttotal: 1.76s\tremaining: 563ms\n",
      "632:\tlearn: 0.0339301\ttotal: 1.76s\tremaining: 560ms\n",
      "633:\tlearn: 0.0339172\ttotal: 1.77s\tremaining: 558ms\n",
      "634:\tlearn: 0.0339008\ttotal: 1.77s\tremaining: 555ms\n",
      "635:\tlearn: 0.0338918\ttotal: 1.77s\tremaining: 552ms\n",
      "636:\tlearn: 0.0338762\ttotal: 1.78s\tremaining: 550ms\n",
      "637:\tlearn: 0.0338651\ttotal: 1.78s\tremaining: 547ms\n",
      "638:\tlearn: 0.0338494\ttotal: 1.78s\tremaining: 544ms\n",
      "639:\tlearn: 0.0338393\ttotal: 1.78s\tremaining: 541ms\n",
      "640:\tlearn: 0.0338177\ttotal: 1.79s\tremaining: 538ms\n",
      "641:\tlearn: 0.0338017\ttotal: 1.79s\tremaining: 536ms\n",
      "642:\tlearn: 0.0337937\ttotal: 1.79s\tremaining: 533ms\n",
      "643:\tlearn: 0.0337665\ttotal: 1.8s\tremaining: 530ms\n",
      "644:\tlearn: 0.0337467\ttotal: 1.8s\tremaining: 527ms\n",
      "645:\tlearn: 0.0337350\ttotal: 1.8s\tremaining: 525ms\n",
      "646:\tlearn: 0.0337235\ttotal: 1.8s\tremaining: 522ms\n",
      "647:\tlearn: 0.0337126\ttotal: 1.81s\tremaining: 519ms\n",
      "648:\tlearn: 0.0336962\ttotal: 1.81s\tremaining: 517ms\n",
      "649:\tlearn: 0.0336810\ttotal: 1.82s\tremaining: 515ms\n",
      "650:\tlearn: 0.0336624\ttotal: 1.83s\tremaining: 514ms\n",
      "651:\tlearn: 0.0336526\ttotal: 1.83s\tremaining: 511ms\n",
      "652:\tlearn: 0.0336441\ttotal: 1.83s\tremaining: 509ms\n",
      "653:\tlearn: 0.0336300\ttotal: 1.84s\tremaining: 506ms\n",
      "654:\tlearn: 0.0336076\ttotal: 1.84s\tremaining: 504ms\n",
      "655:\tlearn: 0.0335997\ttotal: 1.86s\tremaining: 505ms\n",
      "656:\tlearn: 0.0335683\ttotal: 1.86s\tremaining: 502ms\n",
      "657:\tlearn: 0.0335541\ttotal: 1.87s\tremaining: 499ms\n",
      "658:\tlearn: 0.0335405\ttotal: 1.87s\tremaining: 497ms\n",
      "659:\tlearn: 0.0335310\ttotal: 1.88s\tremaining: 495ms\n",
      "660:\tlearn: 0.0335177\ttotal: 1.88s\tremaining: 492ms\n",
      "661:\tlearn: 0.0335039\ttotal: 1.88s\tremaining: 490ms\n",
      "662:\tlearn: 0.0334900\ttotal: 1.89s\tremaining: 488ms\n",
      "663:\tlearn: 0.0334627\ttotal: 1.89s\tremaining: 485ms\n",
      "664:\tlearn: 0.0334412\ttotal: 1.91s\tremaining: 485ms\n",
      "665:\tlearn: 0.0334209\ttotal: 1.91s\tremaining: 482ms\n",
      "666:\tlearn: 0.0334096\ttotal: 1.92s\tremaining: 480ms\n",
      "667:\tlearn: 0.0333878\ttotal: 1.92s\tremaining: 478ms\n",
      "668:\tlearn: 0.0333787\ttotal: 1.93s\tremaining: 476ms\n",
      "669:\tlearn: 0.0333635\ttotal: 1.93s\tremaining: 473ms\n",
      "670:\tlearn: 0.0333403\ttotal: 1.94s\tremaining: 471ms\n",
      "671:\tlearn: 0.0333301\ttotal: 1.94s\tremaining: 468ms\n",
      "672:\tlearn: 0.0333009\ttotal: 1.95s\tremaining: 466ms\n",
      "673:\tlearn: 0.0332765\ttotal: 1.95s\tremaining: 463ms\n",
      "674:\tlearn: 0.0332695\ttotal: 1.97s\tremaining: 465ms\n",
      "675:\tlearn: 0.0332455\ttotal: 1.98s\tremaining: 462ms\n",
      "676:\tlearn: 0.0332326\ttotal: 1.98s\tremaining: 460ms\n",
      "677:\tlearn: 0.0332263\ttotal: 1.99s\tremaining: 457ms\n",
      "678:\tlearn: 0.0332257\ttotal: 1.99s\tremaining: 454ms\n",
      "679:\tlearn: 0.0332108\ttotal: 1.99s\tremaining: 451ms\n",
      "680:\tlearn: 0.0332034\ttotal: 2s\tremaining: 449ms\n",
      "681:\tlearn: 0.0331926\ttotal: 2.03s\tremaining: 452ms\n",
      "682:\tlearn: 0.0331705\ttotal: 2.03s\tremaining: 450ms\n",
      "683:\tlearn: 0.0331551\ttotal: 2.04s\tremaining: 447ms\n",
      "684:\tlearn: 0.0331407\ttotal: 2.04s\tremaining: 444ms\n",
      "685:\tlearn: 0.0331210\ttotal: 2.05s\tremaining: 442ms\n",
      "686:\tlearn: 0.0330990\ttotal: 2.05s\tremaining: 439ms\n",
      "687:\tlearn: 0.0330697\ttotal: 2.06s\tremaining: 437ms\n",
      "688:\tlearn: 0.0330565\ttotal: 2.07s\tremaining: 436ms\n",
      "689:\tlearn: 0.0330378\ttotal: 2.08s\tremaining: 434ms\n",
      "690:\tlearn: 0.0330207\ttotal: 2.08s\tremaining: 431ms\n",
      "691:\tlearn: 0.0330086\ttotal: 2.08s\tremaining: 428ms\n",
      "692:\tlearn: 0.0329931\ttotal: 2.09s\tremaining: 426ms\n",
      "693:\tlearn: 0.0329854\ttotal: 2.1s\tremaining: 423ms\n",
      "694:\tlearn: 0.0329791\ttotal: 2.1s\tremaining: 420ms\n",
      "695:\tlearn: 0.0329724\ttotal: 2.1s\tremaining: 417ms\n",
      "696:\tlearn: 0.0329623\ttotal: 2.1s\tremaining: 413ms\n",
      "697:\tlearn: 0.0329464\ttotal: 2.11s\tremaining: 410ms\n",
      "698:\tlearn: 0.0329315\ttotal: 2.11s\tremaining: 407ms\n",
      "699:\tlearn: 0.0329199\ttotal: 2.11s\tremaining: 404ms\n",
      "700:\tlearn: 0.0329027\ttotal: 2.12s\tremaining: 401ms\n",
      "701:\tlearn: 0.0328920\ttotal: 2.12s\tremaining: 398ms\n",
      "702:\tlearn: 0.0328767\ttotal: 2.14s\tremaining: 398ms\n",
      "703:\tlearn: 0.0328588\ttotal: 2.15s\tremaining: 397ms\n",
      "704:\tlearn: 0.0328439\ttotal: 2.15s\tremaining: 394ms\n",
      "705:\tlearn: 0.0328275\ttotal: 2.16s\tremaining: 392ms\n",
      "706:\tlearn: 0.0328120\ttotal: 2.16s\tremaining: 389ms\n",
      "707:\tlearn: 0.0328007\ttotal: 2.17s\tremaining: 386ms\n",
      "708:\tlearn: 0.0327938\ttotal: 2.17s\tremaining: 383ms\n",
      "709:\tlearn: 0.0327786\ttotal: 2.17s\tremaining: 379ms\n",
      "710:\tlearn: 0.0327597\ttotal: 2.18s\tremaining: 377ms\n",
      "711:\tlearn: 0.0327361\ttotal: 2.18s\tremaining: 374ms\n",
      "712:\tlearn: 0.0327133\ttotal: 2.18s\tremaining: 370ms\n",
      "713:\tlearn: 0.0327071\ttotal: 2.19s\tremaining: 367ms\n",
      "714:\tlearn: 0.0327001\ttotal: 2.19s\tremaining: 364ms\n",
      "715:\tlearn: 0.0326814\ttotal: 2.19s\tremaining: 362ms\n",
      "716:\tlearn: 0.0326658\ttotal: 2.2s\tremaining: 359ms\n",
      "717:\tlearn: 0.0326453\ttotal: 2.2s\tremaining: 356ms\n",
      "718:\tlearn: 0.0326358\ttotal: 2.2s\tremaining: 352ms\n",
      "719:\tlearn: 0.0326174\ttotal: 2.21s\tremaining: 349ms\n",
      "720:\tlearn: 0.0326006\ttotal: 2.21s\tremaining: 346ms\n",
      "721:\tlearn: 0.0325923\ttotal: 2.21s\tremaining: 343ms\n",
      "722:\tlearn: 0.0325643\ttotal: 2.22s\tremaining: 340ms\n",
      "723:\tlearn: 0.0325411\ttotal: 2.22s\tremaining: 337ms\n",
      "724:\tlearn: 0.0324946\ttotal: 2.22s\tremaining: 334ms\n",
      "725:\tlearn: 0.0324846\ttotal: 2.23s\tremaining: 331ms\n",
      "726:\tlearn: 0.0324707\ttotal: 2.23s\tremaining: 328ms\n",
      "727:\tlearn: 0.0324552\ttotal: 2.23s\tremaining: 325ms\n",
      "728:\tlearn: 0.0324475\ttotal: 2.23s\tremaining: 322ms\n",
      "729:\tlearn: 0.0324344\ttotal: 2.24s\tremaining: 319ms\n",
      "730:\tlearn: 0.0324149\ttotal: 2.24s\tremaining: 316ms\n",
      "731:\tlearn: 0.0324050\ttotal: 2.24s\tremaining: 313ms\n",
      "732:\tlearn: 0.0323884\ttotal: 2.25s\tremaining: 310ms\n",
      "733:\tlearn: 0.0323719\ttotal: 2.25s\tremaining: 306ms\n",
      "734:\tlearn: 0.0323649\ttotal: 2.25s\tremaining: 303ms\n",
      "735:\tlearn: 0.0323405\ttotal: 2.25s\tremaining: 300ms\n",
      "736:\tlearn: 0.0323320\ttotal: 2.26s\tremaining: 297ms\n",
      "737:\tlearn: 0.0323102\ttotal: 2.26s\tremaining: 294ms\n",
      "738:\tlearn: 0.0323043\ttotal: 2.26s\tremaining: 291ms\n",
      "739:\tlearn: 0.0322934\ttotal: 2.26s\tremaining: 288ms\n",
      "740:\tlearn: 0.0322677\ttotal: 2.27s\tremaining: 285ms\n",
      "741:\tlearn: 0.0322529\ttotal: 2.27s\tremaining: 281ms\n",
      "742:\tlearn: 0.0322265\ttotal: 2.27s\tremaining: 278ms\n",
      "743:\tlearn: 0.0322153\ttotal: 2.27s\tremaining: 275ms\n",
      "744:\tlearn: 0.0322070\ttotal: 2.28s\tremaining: 272ms\n",
      "745:\tlearn: 0.0321869\ttotal: 2.28s\tremaining: 269ms\n",
      "746:\tlearn: 0.0321655\ttotal: 2.28s\tremaining: 266ms\n",
      "747:\tlearn: 0.0321465\ttotal: 2.29s\tremaining: 263ms\n",
      "748:\tlearn: 0.0321186\ttotal: 2.29s\tremaining: 260ms\n",
      "749:\tlearn: 0.0321085\ttotal: 2.29s\tremaining: 257ms\n",
      "750:\tlearn: 0.0320931\ttotal: 2.29s\tremaining: 253ms\n",
      "751:\tlearn: 0.0320779\ttotal: 2.29s\tremaining: 250ms\n",
      "752:\tlearn: 0.0320579\ttotal: 2.3s\tremaining: 247ms\n",
      "753:\tlearn: 0.0320432\ttotal: 2.3s\tremaining: 244ms\n",
      "754:\tlearn: 0.0320243\ttotal: 2.3s\tremaining: 241ms\n",
      "755:\tlearn: 0.0320057\ttotal: 2.31s\tremaining: 238ms\n",
      "756:\tlearn: 0.0319890\ttotal: 2.31s\tremaining: 235ms\n",
      "757:\tlearn: 0.0319760\ttotal: 2.31s\tremaining: 232ms\n",
      "758:\tlearn: 0.0319641\ttotal: 2.31s\tremaining: 229ms\n",
      "759:\tlearn: 0.0319530\ttotal: 2.32s\tremaining: 226ms\n",
      "760:\tlearn: 0.0319402\ttotal: 2.32s\tremaining: 222ms\n",
      "761:\tlearn: 0.0319244\ttotal: 2.32s\tremaining: 219ms\n",
      "762:\tlearn: 0.0319065\ttotal: 2.32s\tremaining: 216ms\n",
      "763:\tlearn: 0.0318888\ttotal: 2.33s\tremaining: 213ms\n",
      "764:\tlearn: 0.0318521\ttotal: 2.33s\tremaining: 210ms\n",
      "765:\tlearn: 0.0318301\ttotal: 2.33s\tremaining: 207ms\n",
      "766:\tlearn: 0.0318066\ttotal: 2.33s\tremaining: 204ms\n",
      "767:\tlearn: 0.0317840\ttotal: 2.34s\tremaining: 201ms\n",
      "768:\tlearn: 0.0317603\ttotal: 2.34s\tremaining: 198ms\n",
      "769:\tlearn: 0.0317541\ttotal: 2.34s\tremaining: 195ms\n",
      "770:\tlearn: 0.0317372\ttotal: 2.35s\tremaining: 192ms\n",
      "771:\tlearn: 0.0317134\ttotal: 2.35s\tremaining: 189ms\n",
      "772:\tlearn: 0.0316943\ttotal: 2.35s\tremaining: 185ms\n",
      "773:\tlearn: 0.0316681\ttotal: 2.35s\tremaining: 182ms\n",
      "774:\tlearn: 0.0316446\ttotal: 2.36s\tremaining: 179ms\n",
      "775:\tlearn: 0.0316346\ttotal: 2.36s\tremaining: 176ms\n",
      "776:\tlearn: 0.0316170\ttotal: 2.36s\tremaining: 173ms\n",
      "777:\tlearn: 0.0316028\ttotal: 2.36s\tremaining: 170ms\n",
      "778:\tlearn: 0.0315928\ttotal: 2.37s\tremaining: 167ms\n",
      "779:\tlearn: 0.0315747\ttotal: 2.37s\tremaining: 164ms\n",
      "780:\tlearn: 0.0315485\ttotal: 2.37s\tremaining: 161ms\n",
      "781:\tlearn: 0.0315348\ttotal: 2.37s\tremaining: 158ms\n",
      "782:\tlearn: 0.0315195\ttotal: 2.38s\tremaining: 155ms\n",
      "783:\tlearn: 0.0314782\ttotal: 2.38s\tremaining: 152ms\n",
      "784:\tlearn: 0.0314684\ttotal: 2.38s\tremaining: 149ms\n",
      "785:\tlearn: 0.0314554\ttotal: 2.38s\tremaining: 146ms\n",
      "786:\tlearn: 0.0314498\ttotal: 2.39s\tremaining: 143ms\n",
      "787:\tlearn: 0.0314352\ttotal: 2.39s\tremaining: 140ms\n",
      "788:\tlearn: 0.0314231\ttotal: 2.39s\tremaining: 137ms\n",
      "789:\tlearn: 0.0314123\ttotal: 2.4s\tremaining: 133ms\n",
      "790:\tlearn: 0.0313905\ttotal: 2.4s\tremaining: 130ms\n",
      "791:\tlearn: 0.0313767\ttotal: 2.4s\tremaining: 127ms\n",
      "792:\tlearn: 0.0313609\ttotal: 2.4s\tremaining: 124ms\n",
      "793:\tlearn: 0.0313493\ttotal: 2.41s\tremaining: 121ms\n",
      "794:\tlearn: 0.0313381\ttotal: 2.41s\tremaining: 118ms\n",
      "795:\tlearn: 0.0313305\ttotal: 2.41s\tremaining: 115ms\n",
      "796:\tlearn: 0.0313058\ttotal: 2.41s\tremaining: 112ms\n",
      "797:\tlearn: 0.0312855\ttotal: 2.42s\tremaining: 109ms\n",
      "798:\tlearn: 0.0312706\ttotal: 2.42s\tremaining: 106ms\n",
      "799:\tlearn: 0.0312594\ttotal: 2.42s\tremaining: 103ms\n",
      "800:\tlearn: 0.0312383\ttotal: 2.42s\tremaining: 99.9ms\n",
      "801:\tlearn: 0.0312246\ttotal: 2.43s\tremaining: 96.8ms\n",
      "802:\tlearn: 0.0312182\ttotal: 2.43s\tremaining: 93.8ms\n",
      "803:\tlearn: 0.0312015\ttotal: 2.43s\tremaining: 90.7ms\n",
      "804:\tlearn: 0.0311913\ttotal: 2.43s\tremaining: 87.7ms\n",
      "805:\tlearn: 0.0311751\ttotal: 2.44s\tremaining: 84.7ms\n",
      "806:\tlearn: 0.0311566\ttotal: 2.44s\tremaining: 81.6ms\n",
      "807:\tlearn: 0.0311442\ttotal: 2.44s\tremaining: 78.6ms\n",
      "808:\tlearn: 0.0311400\ttotal: 2.44s\tremaining: 75.5ms\n",
      "809:\tlearn: 0.0311326\ttotal: 2.45s\tremaining: 72.5ms\n",
      "810:\tlearn: 0.0310988\ttotal: 2.45s\tremaining: 69.5ms\n",
      "811:\tlearn: 0.0310787\ttotal: 2.45s\tremaining: 66.4ms\n",
      "812:\tlearn: 0.0310688\ttotal: 2.45s\tremaining: 63.4ms\n",
      "813:\tlearn: 0.0310533\ttotal: 2.46s\tremaining: 60.4ms\n",
      "814:\tlearn: 0.0310383\ttotal: 2.46s\tremaining: 57.3ms\n",
      "815:\tlearn: 0.0310296\ttotal: 2.46s\tremaining: 54.3ms\n",
      "816:\tlearn: 0.0310191\ttotal: 2.46s\tremaining: 51.3ms\n",
      "817:\tlearn: 0.0310088\ttotal: 2.47s\tremaining: 48.3ms\n",
      "818:\tlearn: 0.0309898\ttotal: 2.47s\tremaining: 45.2ms\n",
      "819:\tlearn: 0.0309748\ttotal: 2.47s\tremaining: 42.2ms\n",
      "820:\tlearn: 0.0309547\ttotal: 2.47s\tremaining: 39.2ms\n",
      "821:\tlearn: 0.0309467\ttotal: 2.48s\tremaining: 36.2ms\n",
      "822:\tlearn: 0.0309287\ttotal: 2.48s\tremaining: 33.1ms\n",
      "823:\tlearn: 0.0309172\ttotal: 2.48s\tremaining: 30.1ms\n",
      "824:\tlearn: 0.0309076\ttotal: 2.48s\tremaining: 27.1ms\n",
      "825:\tlearn: 0.0308962\ttotal: 2.49s\tremaining: 24.1ms\n",
      "826:\tlearn: 0.0308850\ttotal: 2.49s\tremaining: 21.1ms\n",
      "827:\tlearn: 0.0308699\ttotal: 2.49s\tremaining: 18.1ms\n",
      "828:\tlearn: 0.0308442\ttotal: 2.49s\tremaining: 15ms\n",
      "829:\tlearn: 0.0308297\ttotal: 2.5s\tremaining: 12ms\n",
      "830:\tlearn: 0.0308086\ttotal: 2.5s\tremaining: 9.02ms\n",
      "831:\tlearn: 0.0307988\ttotal: 2.5s\tremaining: 6.01ms\n",
      "832:\tlearn: 0.0307821\ttotal: 2.5s\tremaining: 3.01ms\n",
      "833:\tlearn: 0.0307732\ttotal: 2.51s\tremaining: 0us\n",
      "Model Performance for CatBoost Categoric Optuna\n",
      "Train Gini prob is 90.89882142262202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8004\n",
      "           1       1.00      0.40      0.57        96\n",
      "\n",
      "    accuracy                           0.99      8100\n",
      "   macro avg       1.00      0.70      0.78      8100\n",
      "weighted avg       0.99      0.99      0.99      8100\n",
      "\n",
      "[[8004    0]\n",
      " [  58   38]]\n",
      "Model Performance for CatBoost Categoric Optuna\n",
      "Test Gini prob is 51.2776290110289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2003\n",
      "           1       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       1.00      0.64      0.71      2025\n",
      "weighted avg       0.99      0.99      0.99      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  16    6]]\n",
      "Model Performance for RandomForest Optuna\n",
      "Train Gini prob is 99.89198109278693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8004\n",
      "           1       1.00      0.21      0.34        96\n",
      "\n",
      "    accuracy                           0.99      8100\n",
      "   macro avg       1.00      0.60      0.67      8100\n",
      "weighted avg       0.99      0.99      0.99      8100\n",
      "\n",
      "[[8004    0]\n",
      " [  76   20]]\n",
      "Model Performance for RandomForest Optuna\n",
      "Test Gini prob is 64.03576453501567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2003\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       0.49      0.50      0.50      2025\n",
      "weighted avg       0.98      0.99      0.98      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  22    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aysel Quliyeva\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Aysel Quliyeva\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Aysel Quliyeva\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Gini</th>\n",
       "      <th>Test Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest Optuna</td>\n",
       "      <td>0.998920</td>\n",
       "      <td>0.640358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost Optuna</td>\n",
       "      <td>0.697282</td>\n",
       "      <td>0.588889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Optuna</td>\n",
       "      <td>0.781453</td>\n",
       "      <td>0.517247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM Optuna</td>\n",
       "      <td>0.796806</td>\n",
       "      <td>0.515431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost Categoric Optuna</td>\n",
       "      <td>0.908988</td>\n",
       "      <td>0.512776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Train Gini  Test Gini\n",
       "4        RandomForest Optuna    0.998920   0.640358\n",
       "2            CatBoost Optuna    0.697282   0.588889\n",
       "0             XGBoost Optuna    0.781453   0.517247\n",
       "1            LightGBM Optuna    0.796806   0.515431\n",
       "3  CatBoost Categoric Optuna    0.908988   0.512776"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_df_optuna = pd.DataFrame(columns=['Model', 'Train Gini', 'Test Gini'])\n",
    "\n",
    "for model_name, model in models_optimized:\n",
    "    gini_prob = train_and_evaluate_model(model_name, model, X_train, y_train, X_test, y_test)\n",
    "    if gini_prob is not None:\n",
    "        gini_df_optuna = pd.concat([gini_df_optuna, pd.DataFrame({'Model': [model_name], 'Train Gini': [gini_prob[0]], 'Test Gini': [gini_prob[1]]})], ignore_index=True)\n",
    "\n",
    "gini_df_sorted_optuna = gini_df_optuna.sort_values(by='Test Gini', ascending=False)\n",
    "\n",
    "gini_df_sorted_optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "485059ef-bd81-412d-9702-6f2df8cb2aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Gini</th>\n",
       "      <th>Test Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest Optuna</td>\n",
       "      <td>0.998920</td>\n",
       "      <td>0.640358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost Optuna</td>\n",
       "      <td>0.697282</td>\n",
       "      <td>0.588889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Optuna</td>\n",
       "      <td>0.781453</td>\n",
       "      <td>0.517247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM Optuna</td>\n",
       "      <td>0.796806</td>\n",
       "      <td>0.515431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost Categoric Optuna</td>\n",
       "      <td>0.908988</td>\n",
       "      <td>0.512776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Train Gini  Test Gini\n",
       "4        RandomForest Optuna    0.998920   0.640358\n",
       "2            CatBoost Optuna    0.697282   0.588889\n",
       "0             XGBoost Optuna    0.781453   0.517247\n",
       "1            LightGBM Optuna    0.796806   0.515431\n",
       "3  CatBoost Categoric Optuna    0.908988   0.512776"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_df_sorted_optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "ae873568-0a59-43e6-aa2c-c0d6d3fa44c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Gini</th>\n",
       "      <th>Test Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest Optuna</td>\n",
       "      <td>0.998920</td>\n",
       "      <td>0.640358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost Optuna</td>\n",
       "      <td>0.697282</td>\n",
       "      <td>0.588889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.989266</td>\n",
       "      <td>0.568783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost_Custom</td>\n",
       "      <td>0.967769</td>\n",
       "      <td>0.518631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost Optuna</td>\n",
       "      <td>0.781453</td>\n",
       "      <td>0.517247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM Optuna</td>\n",
       "      <td>0.796806</td>\n",
       "      <td>0.515431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost Categoric Optuna</td>\n",
       "      <td>0.908988</td>\n",
       "      <td>0.512776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Train Gini  Test Gini\n",
       "0                    XGBoost    1.000000   0.658875\n",
       "1                   LightGBM    1.000000   0.656152\n",
       "2        RandomForest Optuna    0.998920   0.640358\n",
       "3               RandomForest    1.000000   0.601121\n",
       "4            CatBoost Optuna    0.697282   0.588889\n",
       "5                   CatBoost    0.989266   0.568783\n",
       "6            CatBoost_Custom    0.967769   0.518631\n",
       "7             XGBoost Optuna    0.781453   0.517247\n",
       "8            LightGBM Optuna    0.796806   0.515431\n",
       "9  CatBoost Categoric Optuna    0.908988   0.512776"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_review = pd.concat([gini_df_sorted,gini_df_sorted_optuna], axis=0)\n",
    "\n",
    "final_review_sorted = final_review.sort_values(by='Test Gini', ascending=False)\n",
    "final_review_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "final_review_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "cd087f98-039b-4119-8537-5480422c0188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Gini</th>\n",
       "      <th>Test Gini</th>\n",
       "      <th>Gini_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658875</td>\n",
       "      <td>0.341125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656152</td>\n",
       "      <td>0.343848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest Optuna</td>\n",
       "      <td>0.998920</td>\n",
       "      <td>0.640358</td>\n",
       "      <td>0.358562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601121</td>\n",
       "      <td>0.398879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost Optuna</td>\n",
       "      <td>0.697282</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.108392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.989266</td>\n",
       "      <td>0.568783</td>\n",
       "      <td>0.420483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost_Custom</td>\n",
       "      <td>0.967769</td>\n",
       "      <td>0.518631</td>\n",
       "      <td>0.449138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost Optuna</td>\n",
       "      <td>0.781453</td>\n",
       "      <td>0.517247</td>\n",
       "      <td>0.264206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM Optuna</td>\n",
       "      <td>0.796806</td>\n",
       "      <td>0.515431</td>\n",
       "      <td>0.281375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost Categoric Optuna</td>\n",
       "      <td>0.908988</td>\n",
       "      <td>0.512776</td>\n",
       "      <td>0.396212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Train Gini  Test Gini  Gini_gap\n",
       "0                    XGBoost    1.000000   0.658875  0.341125\n",
       "1                   LightGBM    1.000000   0.656152  0.343848\n",
       "2        RandomForest Optuna    0.998920   0.640358  0.358562\n",
       "3               RandomForest    1.000000   0.601121  0.398879\n",
       "4            CatBoost Optuna    0.697282   0.588889  0.108392\n",
       "5                   CatBoost    0.989266   0.568783  0.420483\n",
       "6            CatBoost_Custom    0.967769   0.518631  0.449138\n",
       "7             XGBoost Optuna    0.781453   0.517247  0.264206\n",
       "8            LightGBM Optuna    0.796806   0.515431  0.281375\n",
       "9  CatBoost Categoric Optuna    0.908988   0.512776  0.396212"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_review_sorted['Gini_gap'] = (final_review_sorted['Train Gini'] - final_review_sorted['Test Gini']).abs()\n",
    "\n",
    "final_review_sorted = final_review_sorted.sort_values(\n",
    "    by=['Test Gini', 'Gini_gap'],\n",
    "    ascending=[False, True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "final_review_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b8bfc-7903-49ba-bb31-d55bdcfaf6ba",
   "metadata": {},
   "source": [
    "## Importance of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "54b61d35-9288-4e1e-83b7-8082a07b1419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7oAAAMICAYAAADmBpkTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7cklEQVR4nOzde3zP9f//8ft7p/fOB4fZMIYxm8PkVEgITQ4fkhDKIh/ykZzLpxxGcj6l0EEbElYkSSiFOeSU6VPOsqYoOW2OM9vr90e/vb+928a2NtPL7Xq5vC/t9Xw9X8/X4/ne6/K+dPd8vV+zGIZhCAAAAAAAk3Ao6gIAAAAAAChIBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAApBbGysLBZLtq9hw4YVyjkPHDigsWPHKjExsVDG/zsSExNlsVg0bdq0oi4l37Zv366xY8fq4sWLRV0KAOA2nIq6AAAAzCwmJkZVq1a1aytdunShnOvAgQOKjo5W06ZNFRwcXCjnuJdt375d0dHRioqKkq+vb1GXAwC4BYIuAACFqHr16qpbt25Rl/G3pKWlyWKxyMnp3vzfhmvXrsnV1bWoywAA5AG3LgMAUISWL1+uBg0ayMPDQ56enoqMjNS+ffvs+uzZs0ddu3ZVcHCw3NzcFBwcrCeffFI//fSTrU9sbKyeeOIJSVKzZs1st0nHxsZKkoKDgxUVFZXl/E2bNlXTpk1t25s2bZLFYtHixYs1dOhQlSlTRlarVceOHZMkffnll2revLm8vb3l7u6uRo0aaePGjfmae+bt3V999ZX69Omj4sWLy9vbW08//bSuXLmiX3/9VZ07d5avr68CAwM1bNgwpaWl2Y7PvB16ypQpmjBhgsqVKydXV1fVrVs325q2bt2q5s2by8vLS+7u7mrYsKE+++yzbGvasGGDevXqpZIlS8rd3V0jR47U8OHDJUkVKlSwvb+bNm2S9Mfv8ZFHHlFgYKDc3NwUFhaml156SVeuXLEbPyoqSp6enjp27Jhat24tT09PBQUFaejQoUpNTbXrm5qaqnHjxiksLEyurq4qXry4mjVrpu3bt9v6GIahuXPnqlatWnJzc5Ofn586deqkH3/80W6sffv2qW3btvL395fValXp0qXVpk0b/fzzz3n/xQHAPwBBFwCAQpSenq6bN2/avTK99tprevLJJxUeHq64uDgtXrxYly5dUuPGjXXgwAFbv8TERIWGhmrWrFlav369Jk+erNOnT6tevXo6e/asJKlNmzZ67bXXJElvvvmmduzYoR07dqhNmzb5qnvkyJFKSkrS/Pnz9emnn8rf31/vv/++HnnkEXl7e2vhwoWKi4tTsWLFFBkZme+wK0nPPvusfHx8tGzZMr3yyiv64IMP1KdPH7Vp00YRERH66KOP1LNnT02fPl1z5szJcvwbb7yhdevWadasWXr//ffl4OCgRx99VDt27LD12bx5sx5++GElJydrwYIFWrp0qby8vNSuXTstX748y5i9evWSs7OzFi9erI8++kjPPfecnn/+eUnSypUrbe9v7dq1JUlHjx5V69attWDBAq1bt06DBg1SXFyc2rVrl2XstLQ0/etf/1Lz5s31ySefqFevXpo5c6YmT55s63Pz5k09+uijGj9+vNq2bauPP/5YsbGxatiwoZKSkmz9+vbtq0GDBqlFixZatWqV5s6dqx9++EENGzbUb7/9Jkm6cuWKWrZsqd9++01vvvmmvvjiC82aNUvlypXTpUuX8vlbA4C7nAEAAApcTEyMISnbV1pampGUlGQ4OTkZzz//vN1xly5dMgICAozOnTvnOPbNmzeNy5cvGx4eHsbs2bNt7R9++KEhyfj666+zHFO+fHmjZ8+eWdqbNGliNGnSxLb99ddfG5KMhx56yK7flStXjGLFihnt2rWza09PTzciIiKM+vXr3+LdMIwTJ04YkoypU6fa2jLfo7++Bx06dDAkGTNmzLBrr1WrllG7du0sY5YuXdq4du2arT0lJcUoVqyY0aJFC1vbAw88YPj7+xuXLl2ytd28edOoXr26UbZsWSMjI8OupqeffjrLHKZOnWpIMk6cOHHLuWZkZBhpaWnG5s2bDUnG/v37bft69uxpSDLi4uLsjmndurURGhpq2160aJEhyXjnnXdyPM+OHTsMScb06dPt2k+ePGm4ubkZI0aMMAzDMPbs2WNIMlatWnXLugHATFjRBQCgEC1atEi7d++2ezk5OWn9+vW6efOmnn76abvVXldXVzVp0sR2S6wkXb58WS+++KJCQkLk5OQkJycneXp66sqVKzp48GCh1P3444/bbW/fvl3nz59Xz5497erNyMhQq1attHv37iy36eZW27Zt7bbDwsIkKctqdFhYmN3t2pk6duxo9x3azJXaLVu2KD09XVeuXNHOnTvVqVMneXp62vo5Ojrqqaee0s8//6zDhw/fcv638+OPP6pbt24KCAiQo6OjnJ2d1aRJE0nK8juyWCxZVnpr1qxpN7fPP/9crq6u6tWrV47nXLNmjSwWi3r06GH3OwkICFBERITtGgoJCZGfn59efPFFzZ8/3+5uAQAwq3vzqRIAANwhYWFh2T6MKvO20nr16mV7nIPD//1bdLdu3bRx40aNGjVK9erVk7e3tywWi1q3bq1r164VSt2BgYHZ1tupU6ccjzl//rw8PDzyfK5ixYrZbbu4uOTYfv369SzHBwQEZNt248YNXb58WZcuXZJhGFnmJP3fE7DPnTtn155d35xcvnxZjRs3lqurq1599VVVqVJF7u7uOnnypDp27Jjld+Tu7p7l4VZWq9Vubr///rtKly5tdx381W+//SbDMFSqVKls91esWFGS5OPjo82bN2vChAn673//qwsXLigwMFB9+vTRK6+8Imdn51zPFQD+KQi6AAAUgRIlSkiSPvroI5UvXz7HfsnJyVqzZo3GjBmjl156ydaempqq8+fP5/p8rq6uWR52JElnz5611fJnFosl23rnzJmjBx54INtz5BS4Ctuvv/6abZuLi4s8PT3l5OQkBwcHnT59Oku/U6dOSVKW9+Cv87+Vr776SqdOndKmTZtsq7iS/tbf2y1ZsqS2bt2qjIyMHMNuiRIlZLFYFB8fL6vVmmX/n9tq1KihZcuWyTAMfffdd4qNjdW4cePk5uZmd10BgFkQdAEAKAKRkZFycnLS8ePHb3mbrMVikWEYWYLMu+++q/T0dLu2zD7ZrfIGBwfru+++s2s7cuSIDh8+nG3Q/atGjRrJ19dXBw4c0IABA27b/05auXKlpk6dalslvXTpkj799FM1btxYjo6O8vDw0P3336+VK1dq2rRpcnNzkyRlZGTo/fffV9myZVWlSpXbnien9zczFP/1d/TWW2/le06PPvqoli5dqtjY2BxvX27btq0mTZqkX375RZ07d87VuBaLRREREZo5c6ZiY2P17bff5rtGALibEXQBACgCwcHBGjdunF5++WX9+OOPatWqlfz8/PTbb79p165d8vDwUHR0tLy9vfXQQw9p6tSpKlGihIKDg7V582YtWLBAvr6+dmNWr15dkvT222/Ly8tLrq6uqlChgooXL66nnnpKPXr0UP/+/fX444/rp59+0pQpU1SyZMlc1evp6ak5c+aoZ8+eOn/+vDp16iR/f3/9/vvv2r9/v37//XfNmzevoN+mXHF0dFTLli01ZMgQZWRkaPLkyUpJSVF0dLStz8SJE9WyZUs1a9ZMw4YNk4uLi+bOnavvv/9eS5cuzdUKbo0aNSRJs2fPVs+ePeXs7KzQ0FA1bNhQfn5+6tevn8aMGSNnZ2ctWbJE+/fvz/ecnnzyScXExKhfv346fPiwmjVrpoyMDO3cuVNhYWHq2rWrGjVqpH//+9965plntGfPHj300EPy8PDQ6dOntXXrVtWoUUPPPfec1qxZo7lz56pDhw6qWLGiDMPQypUrdfHiRbVs2TLfNQLA3YygCwBAERk5cqTCw8M1e/ZsLV26VKmpqQoICFC9evXUr18/W78PPvhAL7zwgkaMGKGbN2+qUaNG+uKLL7I8rKlChQqaNWuWZs+eraZNmyo9PV0xMTGKiopSt27ddOrUKc2fP18xMTGqXr265s2bZxcGb6dHjx4qV66cpkyZor59++rSpUvy9/dXrVq1sv0bvXfKgAEDdP36dQ0cOFBnzpxRtWrV9Nlnn6lRo0a2Pk2aNNFXX32lMWPGKCoqShkZGYqIiNDq1auzPAwrJ02bNtXIkSO1cOFCvfPOO8rIyNDXX3+tpk2b6rPPPtPQoUPVo0cPeXh4qH379lq+fLntzw/llZOTk9auXauJEydq6dKlmjVrlry8vBQREaFWrVrZ+r311lt64IEH9NZbb2nu3LnKyMhQ6dKl1ahRI9WvX1+SVLlyZfn6+mrKlCk6deqUXFxcFBoaqtjYWPXs2TNf9QHA3c5iGIZR1EUAAADkVWJioipUqKCpU6dq2LBhRV0OAOAuwp8XAgAAAACYCkEXAAAAAGAq3LoMAAAAADAVVnQBAAAAAKZC0AUAAAAAmApBFwAAAABgKvwdXdz1MjIydOrUKXl5eclisRR1OQAAAACKiGEYunTpkkqXLi0Hh5zXbQm6uOudOnVKQUFBRV0GAAAAgLvEyZMnVbZs2Rz3E3Rx1/Py8pL0x8Xs7e1dxNUAAAAAKCopKSkKCgqyZYScEHRx18u8Xdnb25ugCwAAAOC2X2nkYVQAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUnIq6ACC3qo9ZLwere1GXAQAAANwzEie1KeoS8oUVXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoEXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoEXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoEXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoEXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoE3TxKTEyUxWJRQkLC3xonKipKHTp0KJCa7iZmnRcAAACAfw6CLrJYuHCh6tevLw8PD3l5eemhhx7SmjVrcnXs7NmzFRsbW7gFAgAAAMAtEHRhZ9iwYerbt686d+6s/fv3a9euXWrcuLHat2+vN954I8fj0tPTlZGRIR8fH/n6+t65ggEAAADgL0wRdJs2baqBAwdqxIgRKlasmAICAjR27Fjb/uTkZP373/+Wv7+/vL299fDDD2v//v22fY6Ojtq7d68kyTAMFStWTPXq1bMdv3TpUgUGBtqd89ChQ2rYsKFcXV1VrVo1bdq0ybYvPT1dvXv3VoUKFeTm5qbQ0FDNnj37lnNYt26dHnzwQfn6+qp48eJq27atjh8/btufecv0ypUr1axZM7m7uysiIkI7duywG2fbtm1q0qSJ3N3d5efnp8jISF24cME2tylTpqhixYpyc3NTRESEPvroI9ux33zzjaZPn66pU6dq2LBhCgkJUVhYmCZMmKBBgwZpyJAhOnnypCQpNjZWvr6+WrNmjcLDw2W1WvXTTz9luXX50qVL6t69uzw8PBQYGKiZM2eqadOmGjRo0C3fDwAAAADIL1MEXemP2209PDy0c+dOTZkyRePGjdMXX3whwzDUpk0b/frrr1q7dq327t2r2rVrq3nz5jp//rx8fHxUq1YtW1D97rvvbP9NSUmRJG3atElNmjSxO9/w4cM1dOhQ7du3Tw0bNtS//vUvnTt3TpKUkZGhsmXLKi4uTgcOHNDo0aP13//+V3FxcTnWf+XKFQ0ZMkS7d+/Wxo0b5eDgoMcee0wZGRl2/V5++WUNGzZMCQkJqlKlip588kndvHlTkpSQkKDmzZurWrVq2rFjh7Zu3ap27dopPT1dkvTKK68oJiZG8+bN0w8//KDBgwerR48e2rx5s6Q/Ar2np6f69u2bpb6hQ4cqLS1NK1assLVdvXpVEydO1LvvvqsffvhB/v7+WY4bMmSItm3bptWrV+uLL75QfHy8vv3225x/kZJSU1OVkpJi9wIAAACA3HIq6gIKSs2aNTVmzBhJUuXKlfXGG29o48aNcnR01P/+9z+dOXNGVqtVkjRt2jStWrVKH330kf7973+radOm2rRpk4YOHapNmzapefPm+vHHH7V161a1bt1amzZt0uDBg+3ON2DAAD3++OOSpHnz5mndunVasGCBRowYIWdnZ0VHR9v6VqhQQdu3b1dcXJw6d+6cbf2ZY2VasGCB/P39deDAAVWvXt3WPmzYMLVp00aSFB0drWrVqunYsWOqWrWqpkyZorp162ru3Lm2/tWqVZP0R5CeMWOGvvrqKzVo0ECSVLFiRW3dulVvvfWWmjRpoiNHjqhSpUpycXHJUl/p0qXl4+OjI0eO2NrS0tI0d+5cRUREZDunS5cuaeHChfrggw/UvHlzSVJMTIxKly6dbf9MEydOtHv/AAAAACAvTLOiW7NmTbvtwMBAnTlzRnv37tXly5dVvHhxeXp62l4nTpyw3RrctGlTxcfHKyMjQ5s3b1bTpk3VtGlTbd68Wb/++quOHDmSZUU3MyxKkpOTk+rWrauDBw/a2ubPn6+6deuqZMmS8vT01DvvvKOkpKQc6z9+/Li6deumihUrytvbWxUqVJCkLMf8eZ6Zt1OfOXNG0v+t6GbnwIEDun79ulq2bGn3PixatMjuFulbMQxDFovFtu3i4pLlff+zH3/8UWlpaapfv76tzcfHR6Ghobc8z8iRI5WcnGx7Zd4uDQAAAAC5YZoVXWdnZ7tti8WijIwMZWRkKDAw0O47tJkyH5r00EMP6dKlS/r2228VHx+v8ePHKygoSK+99ppq1aolf39/hYWF3baGzBAYFxenwYMHa/r06WrQoIG8vLw0depU7dy5M8dj27Vrp6CgIL3zzjsqXbq0MjIyVL16dd24cSPHeWaeL/P2Zjc3txzHz+zz2WefqUyZMnb7Mle6q1Spoq1bt+rGjRtZVnVPnTqllJQUVa5c2dbm5uZmF3z/yjAMuzr/2p4Tq9VqqwkAAAAA8so0K7o5qV27tn799Vc5OTkpJCTE7lWiRAlJsn1P94033pDFYlF4eLgaN26sffv2ac2aNVlWc6U/HtyU6ebNm9q7d6+qVq0qSYqPj1fDhg3Vv39/3XfffQoJCbnlqum5c+d08OBBvfLKK2revLnCwsJsD5DKi5o1a2rjxo3Z7st8YFRSUlKW9yEoKEiS1LVrV12+fFlvvfVWluOnTZsmZ2fnLLdY30qlSpXk7OysXbt22dpSUlJ09OjRPM4MAAAAAHLPNCu6OWnRooUaNGigDh06aPLkyQoNDdWpU6e0du1adejQQXXr1pX0x+3Ls2fP1mOPPSaLxSI/Pz+Fh4dr+fLlev3117OM++abb6py5coKCwvTzJkzdeHCBfXq1UuSFBISokWLFmn9+vWqUKGCFi9erN27d9tuR/4rPz8/FS9eXG+//bYCAwOVlJSkl156Kc9zHTlypGrUqKH+/furX79+cnFx0ddff60nnnhCJUqU0LBhwzR48GBlZGTowQcfVEpKirZv3y5PT0/17NlTDRo00AsvvKDhw4frxo0b6tChg9LS0vT+++9r9uzZmjVrli0U54aXl5d69uyp4cOHq1ixYvL399eYMWPk4OBwy5VgAAAAAPg7TL+ia7FYtHbtWj300EPq1auXqlSpoq5duyoxMVGlSpWy9WvWrJnS09PVtGlTW1uTJk2Unp6e7YrupEmTNHnyZEVERCg+Pl6ffPKJbYW4X79+6tixo7p06aL7779f586dU//+/XOs0cHBQcuWLdPevXtVvXp1DR48WFOnTs3zXKtUqaINGzZo//79ql+/vho0aKBPPvlETk5//HvG+PHjNXr0aE2cOFFhYWGKjIzUp59+ahfAZ82apblz52rZsmWqUaOG6tSpo82bN2vVqlV6/vnn81zTjBkz1KBBA7Vt21YtWrRQo0aNFBYWJldX1zyPBQAAAAC5YTFu94VJoABduXJFZcqU0fTp09W7d+9cHZOSkiIfHx8FDYqTg9W9kCsEAAAAkClxUpuiLsFOZjZITk6Wt7d3jv1Mf+syita+fft06NAh1a9fX8nJyRo3bpwkqX379kVcGQAAAACzIuii0E2bNk2HDx+Wi4uL6tSpo/j4eNtt3gAAAABQ0Ai6KFT33Xef9u7dW9RlAAAAALiHmP5hVAAAAACAewtBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKbiVNQFALn1fXSkvL29i7oMAAAAAHc5VnQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpOBV1AUBuVR+zXg5W96IuAwAAALjrJE5qU9Ql3FVY0QUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHT/YtOmTbJYLLp48WKOfWJjY+Xr62vbHjt2rGrVqvW3z22xWLRq1aq/PQ4AAAAA3MsIurit8+fPa9CgQQoODpaLi4sCAwP1zDPPKCkpqahLAwAAAIAsCLq4pfPnz+uBBx7Ql19+qblz5+rYsWNavny5jh8/rnr16unHH3/M8dgbN27cwUoBAAAA4A/3ZNBNTU3VwIED5e/vL1dXVz344IPavXt3jv1jY2NVrlw5ubu767HHHtO5c+ey7ffWW28pKChI7u7ueuKJJ+xuf969e7datmypEiVKyMfHR02aNNG33357yzpffPFFValSRe7u7qpYsaJGjRqltLQ02/7MW6YXL16s4OBg+fj4qGvXrrp06ZKtT0ZGhiZPnqyQkBBZrVaVK1dOEyZMsO3/5Zdf1KVLF/n5+al48eJq3769EhMTbftffvllnTp1Sl9++aVat26tcuXK6aGHHtL69evl7Oys//znP7a+TZs21YABAzRkyBCVKFFCLVu2lCStXr1alStXlpubm5o1a6aFCxfe9vZwAAAAAMivezLojhgxQitWrNDChQv17bffKiQkRJGRkTp//nyWvjt37lSvXr3Uv39/JSQkqFmzZnr11Vez9Dt27Jji4uL06aefat26dUpISLALgZcuXVLPnj0VHx+vb775RpUrV1br1q3tQulfeXl5KTY2VgcOHNDs2bP1zjvvaObMmXZ9jh8/rlWrVmnNmjVas2aNNm/erEmTJtn2jxw5UpMnT9aoUaN04MABffDBBypVqpQk6erVq2rWrJk8PT21ZcsWbd26VZ6enmrVqpVu3LihjIwMLVu2TN27d1dAQIDded3c3NS/f3+tX7/e7n1buHChnJyctG3bNr311ltKTExUp06d1KFDByUkJKhv3756+eWXb/n7SU1NVUpKit0LAAAAAHLLqagLuNOuXLmiefPmKTY2Vo8++qgk6Z133tEXX3yhBQsWqF69enb9Z8+ercjISL300kuSpCpVqmj79u1at26dXb/r169r4cKFKlu2rCRpzpw5atOmjaZPn66AgAA9/PDDdv3feust+fn5afPmzWrbtm22tb7yyiu2n4ODgzV06FAtX75cI0aMsLVnZGQoNjZWXl5ekqSnnnpKGzdu1IQJE3Tp0iXNnj1bb7zxhnr27ClJqlSpkh588EFJ0rJly+Tg4KB3331XFotFkhQTEyNfX19t2rRJERERunjxosLCwrKtLywsTIZh6NixY6pfv74kKSQkRFOmTLH1eemllxQaGqqpU6dKkkJDQ/X999/brSr/1cSJExUdHZ3jfgAAAAC4lXtuRff48eNKS0tTo0aNbG3Ozs6qX7++Dh48mKX/wYMH1aBBA7u2v25LUrly5WwhN7NPRkaGDh8+LEk6c+aM+vXrpypVqsjHx0c+Pj66fPnyLR/o9NFHH+nBBx9UQECAPD09NWrUqCz9g4ODbSFXkgIDA3XmzBlb7ampqWrevHm24+/du1fHjh2Tl5eXPD095enpqWLFiun69es6fvx4jnVlMgxDkmwhWZLq1q1r1+fw4cNZ/vEgMxTnZOTIkUpOTra9Tp48edtaAAAAACDTPbeim104y2z/a9uf++dV5liZ/42KitLvv/+uWbNmqXz58rJarWrQoEGOD2z65ptv1LVrV0VHRysyMlI+Pj5atmyZpk+fbtfP2dk5y3kzMjIk/XF78a1kZGSoTp06WrJkSZZ9JUuWlJeXl3x9fXXgwIFsjz906JAsFosqVapka/Pw8LDrk937erv31Gq1ymq13rIPAAAAAOTknlvRDQkJkYuLi7Zu3WprS0tL0549e7K9RTc8PFzffPONXdtftyUpKSlJp06dsm3v2LFDDg4OqlKliiQpPj5eAwcOVOvWrVWtWjVZrVadPXs2xzq3bdum8uXL6+WXX1bdunVVuXJl/fTTT3maa+YDoDZu3Jjt/tq1a+vo0aPy9/dXSEiI3cvHx0cODg7q3LmzPvjgA/366692x167dk1z585VZGSkihUrlmMNVatWzfKgrz179uRpHgAAAACQF/dc0PXw8NBzzz2n4cOHa926dTpw4ID69Omjq1evqnfv3ln6Dxw4UOvWrdOUKVN05MgRvfHGG1m+nytJrq6u6tmzp/bv328LtZ07d7Y9xCkkJESLFy/WwYMHtXPnTnXv3v2WK64hISFKSkrSsmXLdPz4cb3++uv6+OOP8zRXV1dXvfjiixoxYoQWLVqk48eP65tvvtGCBQskSd27d1eJEiXUvn17xcfH68SJE9q8ebNeeOEF/fzzz5KkCRMmKCAgQC1bttTnn3+ukydPasuWLYqMjFRaWprefPPNW9bQt29fHTp0SC+++KKOHDmiuLg4xcbGSsq6qg4AAAAABeGeC7qSNGnSJD3++ON66qmnVLt2bR07dkzr16+Xn59flr4PPPCA3n33Xc2ZM0e1atXShg0b7B4SlSkkJEQdO3ZU69at9cgjj6h69eqaO3eubf97772nCxcu6L777tNTTz1l+/NGOWnfvr0GDx6sAQMGqFatWtq+fbtGjRqV57mOGjVKQ4cO1ejRoxUWFqYuXbrYvsPr7u6uLVu2qFy5curYsaPCwsLUq1cvXbt2Td7e3pKkEiVK6JtvvlGzZs3Ut29fVaxYUZ07d1bFihW1e/duVaxY8Zbnr1Chgj766COtXLlSNWvW1Lx582xPXeb2ZAAAAACFwWLk90uoQD5NmDBB8+fPz/VDplJSUuTj46OgQXFysLoXcnUAAADAP0/ipDZFXcIdkZkNkpOTbYtz2bnnHkaFO2/u3LmqV6+eihcvrm3btmnq1KkaMGBAUZcFAAAAwKQIuih0R48e1auvvqrz58+rXLlyGjp0qEaOHFnUZQEAAAAwKYIuCt3MmTM1c+bMoi4DAAAAwD3innwYFQAAAADAvAi6AAAAAABTIegCAAAAAEyFoAsAAAAAMBWCLgAAAADAVAi6AAAAAABTIegCAAAAAEyFoAsAAAAAMBWCLgAAAADAVAi6AAAAAABTIegCAAAAAEyFoAsAAAAAMBWCLgAAAADAVAi6AAAAAABTIegCAAAAAEyFoAsAAAAAMBWnoi4AyK3voyPl7e1d1GUAAAAAuMuxogsAAAAAMBWCLgAAAADAVAi6AAAAAABTIegCAAAAAEyFoAsAAAAAMBWCLgAAAADAVAi6AAAAAABTIegCAAAAAEyFoAsAAAAAMBWCLgAAAADAVAi6AAAAAABTIegCAAAAAEzFqagLAHKr+pj1crC6F3UZAAAARSZxUpuiLgH4R2BFFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdSJKaNm2qQYMGFXUZAAAAAPC3EXQBAAAAAKZC0IWioqK0efNmzZ49WxaLRRaLRU5OTpo2bZpdv++//14ODg46fvy4JMlisWjevHl69NFH5ebmpgoVKujDDz+0O+aXX35Rly5d5Ofnp+LFi6t9+/ZKTEy8U1MDAAAAcA8i6EKzZ89WgwYN1KdPH50+fVqnT59WdHS0YmJi7Pq99957aty4sSpVqmRrGzVqlB5//HHt379fPXr00JNPPqmDBw9Kkq5evapmzZrJ09NTW7Zs0datW+Xp6alWrVrpxo0bOdaTmpqqlJQUuxcAAAAA5BZBF/Lx8ZGLi4vc3d0VEBCggIAA9erVS4cPH9auXbskSWlpaXr//ffVq1cvu2OfeOIJPfvss6pSpYrGjx+vunXras6cOZKkZcuWycHBQe+++65q1KihsLAwxcTEKCkpSZs2bcqxnokTJ8rHx8f2CgoKKrS5AwAAADAfgi6yFRgYqDZt2ui9996TJK1Zs0bXr1/XE088YdevQYMGWbYzV3T37t2rY8eOycvLS56envL09FSxYsV0/fp12+3P2Rk5cqSSk5Ntr5MnTxbw7AAAAACYmVNRF4C717PPPqunnnpKM2fOVExMjLp06SJ3d/fbHmexWCRJGRkZqlOnjpYsWZKlT8mSJXM83mq1ymq15r9wAAAAAPc0gi4kSS4uLkpPT7dra926tTw8PDRv3jx9/vnn2rJlS5bjvvnmGz399NN22/fdd58kqXbt2lq+fLn8/f3l7e1duBMAAAAAgP+PW5chSQoODtbOnTuVmJios2fPKiMjQ46OjoqKitLIkSMVEhKS5TZlSfrwww/13nvv6ciRIxozZox27dqlAQMGSJK6d++uEiVKqH379oqPj9eJEye0efNmvfDCC/r555/v9BQBAAAA3CMIupAkDRs2TI6OjgoPD1fJkiWVlJQkSerdu7du3LiR5SFUmaKjo7Vs2TLVrFlTCxcu1JIlSxQeHi5Jcnd315YtW1SuXDl17NhRYWFh6tWrl65du8YKLwAAAIBCw63LkCRVqVJFO3bsyNJ++vRpOTk52d2e/GelS5fWhg0bchw3ICBACxcuLLA6AQAAAOB2CLrIVmpqqk6ePKlRo0apc+fOKlWqVFGXBAAAAAC5wq3LyNbSpUsVGhqq5ORkTZkypajLAQAAAIBcY0UX2YqKilJUVNQt+xiGcWeKAQAAAIA8YEUXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApuJU1AUAufV9dKS8vb2LugwAAAAAdzlWdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKk4FXUBQG5VH7NeDlb3oi4DAIBClTipTVGXAAD/eKzoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaCLOyYqKkodOnQo6jIAAAAAmBxBFwAAAABgKgTdf5h169bpwQcflK+vr4oXL662bdvq+PHjkqTExERZLBbFxcWpcePGcnNzU7169XTkyBHt3r1bdevWlaenp1q1aqXff//dNmZGRobGjRunsmXLymq1qlatWlq3bp1t/6ZNm2SxWHTx4kVbW0JCgiwWixITEyVJsbGx8vX11fr16xUWFmY7z+nTpyVJY8eO1cKFC/XJJ5/IYrHIYrFo06ZNhf5+AQAAALj3EHT/Ya5cuaIhQ4Zo9+7d2rhxoxwcHPTYY48pIyPD1mfMmDF65ZVX9O2338rJyUlPPvmkRowYodmzZys+Pl7Hjx/X6NGjbf1nz56t6dOna9q0afruu+8UGRmpf/3rXzp69Gieart69aqmTZumxYsXa8uWLUpKStKwYcMkScOGDVPnzp1t4ff06dNq2LBhtuOkpqYqJSXF7gUAAAAAueVU1AUgbx5//HG77QULFsjf318HDhyQp6enpD9CZWRkpCTphRde0JNPPqmNGzeqUaNGkqTevXsrNjbWNsa0adP04osvqmvXrpKkyZMn6+uvv9asWbP05ptv5rq2tLQ0zZ8/X5UqVZIkDRgwQOPGjZMkeXp6ys3NTampqQoICLjlOBMnTlR0dHSuzwsAAAAAf8aK7j/M8ePH1a1bN1WsWFHe3t6qUKGCJCkpKcnWp2bNmrafS5UqJUmqUaOGXduZM2ckSSkpKTp16pQtBGdq1KiRDh48mKfa3N3dbSFXkgIDA23nyYuRI0cqOTnZ9jp58mSexwAAAABw72JF9x+mXbt2CgoK0jvvvKPSpUsrIyND1atX140bN2x9nJ2dbT9bLJZs2/58q/Of+2UyDMPW5uDgYGvLlJaWlqW2P58jc8w/H5NbVqtVVqs1z8cBAAAAgMSK7j/KuXPndPDgQb3yyitq3ry5wsLCdOHChb81pre3t0qXLq2tW7fatW/fvl1hYWGSpJIlS0qS7cFS0h8Po8orFxcXpaen579YAAAAAMgFVnT/Qfz8/FS8eHG9/fbbCgwMVFJSkl566aW/Pe7w4cM1ZswYVapUSbVq1VJMTIwSEhK0ZMkSSVJISIiCgoI0duxYvfrqqzp69KimT5+e5/MEBwdr/fr1Onz4sIoXLy4fH58sq8AAAAAA8HexovsP4uDgoGXLlmnv3r2qXr26Bg8erKlTp/7tcQcOHKihQ4dq6NChqlGjhtatW6fVq1ercuXKkv64JXnp0qU6dOiQIiIiNHnyZL366qt5Pk+fPn0UGhqqunXrqmTJktq2bdvfrh0AAAAA/spi5OdLlMAdlJKSIh8fHwUNipOD1b2oywEAoFAlTmpT1CUAwF0rMxskJyfL29s7x36s6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUnIq6ACC3vo+OlLe3d1GXAQAAAOAux4ouAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATIWgCwAAAAAwFYIuAAAAAMBUCLoAAAAAAFMh6AIAAAAATMWpqAsAcqv6mPVysLoXdRkAspE4qU1RlwAAAGDDii4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgu49xGKxaNWqVZKkxMREWSwWJSQkFOg5goODNWvWrAIdEwAAAADywqmoC4C57N69Wx4eHkVdBgAAAIB7GEEXBapkyZJFXQIAAACAexy3LudCdrfj1qpVS2PHjpX0xy3B7777rh577DG5u7urcuXKWr16ta1vbGysfH197Y5ftWqVLBaLbXv//v1q1qyZvLy85O3trTp16mjPnj2SpLFjx6pWrVp2x8+aNUvBwcG27d27d6tly5YqUaKEfHx81KRJE3377bd5mufmzZtVv359Wa1WBQYG6qWXXtLNmzdt+y9duqTu3bvLw8NDgYGBmjlzppo2bapBgwbl+F7d7r0BAAAAgIJG0C0g0dHR6ty5s7777ju1bt1a3bt31/nz53N9fPfu3VW2bFnt3r1be/fu1UsvvSRnZ+dcH3/p0iX17NlT8fHx+uabb1S5cmW1bt1aly5dytXxv/zyi1q3bq169epp//79mjdvnhYsWKBXX33V1mfIkCHatm2bVq9erS+++ELx8fG5CtN5fW9SU1OVkpJi9wIAAACA3CLoFpCoqCg9+eSTCgkJ0WuvvaYrV65o165duT4+KSlJLVq0UNWqVVW5cmU98cQTioiIyPXxDz/8sHr06KGwsDCFhYXprbfe0tWrV7V58+ZcHT937lwFBQXpjTfeUNWqVdWhQwdFR0dr+vTpysjI0KVLl7Rw4UJNmzZNzZs3V/Xq1RUTE6P09PTbjp3X92bixIny8fGxvYKCgnL9PgAAAAAAQbeA1KxZ0/azh4eHvLy8dObMmVwfP2TIED377LNq0aKFJk2apOPHj+fp/GfOnFG/fv1UpUoVW0C8fPmykpKScnX8wYMH1aBBA7vbqRs1aqTLly/r559/1o8//qi0tDTVr1/ftt/Hx0ehoaG3HTuv783IkSOVnJxse508eTJXcwAAAAAAiaCbKw4ODjIMw64tLS3NbvuvtxlbLBZlZGTk+vixY8fqhx9+UJs2bfTVV18pPDxcH3/8ca6Pj4qK0t69ezVr1ixt375dCQkJKl68uG7cuJGrORqGYRdyM9sy5/Lnn7Prcyu3em+yY7Va5e3tbfcCAAAAgNwi6OZCyZIldfr0adt2SkqKTpw4kafjL126pCtXrtjasvv7tVWqVNHgwYO1YcMGdezYUTExMbbjf/31V7tQ+dfj4+PjNXDgQLVu3VrVqlWT1WrV2bNnc11jeHi4tm/fbneO7du3y8vLS2XKlFGlSpXk7Oxsd8txSkqKjh49mutzAAAAAMCdQNDNhYcffliLFy9WfHy8vv/+e/Xs2VOOjo65Pv7++++Xu7u7/vvf/+rYsWP64IMPFBsba9t/7do1DRgwQJs2bdJPP/2kbdu2affu3QoLC5MkNW3aVL///rumTJmi48eP680339Tnn39ud46QkBAtXrxYBw8e1M6dO9W9e3e5ubnlusb+/fvr5MmTev7553Xo0CF98sknGjNmjIYMGSIHBwd5eXmpZ8+eGj58uL7++mv98MMP6tWrlxwcHLKs8gIAAABAUSLo5sLIkSP10EMPqW3btmrdurU6dOigSpUq5fr4YsWK6f3339fatWtVo0YNLV261PaniSTJ0dFR586d09NPP60qVaqoc+fOevTRRxUdHS1JCgsL09y5c/Xmm28qIiJCu3bt0rBhw+zO8d577+nChQu677779NRTT2ngwIHy9/fPdY1lypTR2rVrtWvXLkVERKhfv37q3bu3XnnlFVufGTNmqEGDBmrbtq1atGihRo0aKSwsTK6urrk+DwAAAAAUNouRmy9ZAtm4cuWKypQpo+nTp6t3796Fdp6UlJQ/nr48KE4OVvdCOw+A/Euc1KaoSwAAAPeAzGyQnJx8y2f5ON3BmvAPt2/fPh06dEj169dXcnKyxo0bJ0lq3759EVcGAAAAAP+HoIs8mTZtmg4fPiwXFxfVqVNH8fHxKlGiRFGXBQAAAAA2BF3k2n333ae9e/cWdRkAAAAAcEv5fhjV4sWL1ahRI5UuXVo//fSTJGnWrFn65JNPCqw4AAAAAADyKl9Bd968eRoyZIhat26tixcvKj09XZLk6+urWbNmFWR9AAAAAADkSb6C7pw5c/TOO+/o5Zdftvt7snXr1tX//ve/AisOAAAAAIC8ylfQPXHihO67774s7VarVVeuXPnbRQEAAAAAkF/5CroVKlRQQkJClvbPP/9c4eHhf7cmAAAAAADyLV9PXR4+fLj+85//6Pr16zIMQ7t27dLSpUs1ceJEvfvuuwVdIwAAAAAAuZavoPvMM8/o5s2bGjFihK5evapu3bqpTJkymj17trp27VrQNQIAAAAAkGt5Dro3b97UkiVL1K5dO/Xp00dnz55VRkaG/P39C6M+AAAAAADyJM/f0XVyctJzzz2n1NRUSVKJEiUIuQAAAACAu0a+HkZ1//33a9++fQVdCwAAAAAAf1u+vqPbv39/DR06VD///LPq1KkjDw8Pu/01a9YskOIAAAAAAMirfAXdLl26SJIGDhxoa7NYLDIMQxaLRenp6QVTHQAAAAAAeZSvoHvixImCrgMAAAAAgAKRr6Bbvnz5gq4DAAAAAIACka+gu2jRolvuf/rpp/NVDAAAAAAAf1e+gu4LL7xgt52WlqarV6/KxcVF7u7uBF0AAAAAQJHJV9C9cOFClrajR4/queee0/Dhw/92UUB2vo+OlLe3d1GXAQAAAOAul6+/o5udypUra9KkSVlWewEAAAAAuJMKLOhKkqOjo06dOlWQQwIAAAAAkCf5unV59erVdtuGYej06dN644031KhRowIpDAAAAACA/MhX0O3QoYPdtsViUcmSJfXwww9r+vTpBVEXAAAAAAD5kq+gm5GRUdB1AAAAAABQIPL1Hd1x48bp6tWrWdqvXbumcePG/e2iAAAAAADIL4thGEZeD3J0dNTp06fl7+9v137u3Dn5+/srPT29wAoEUlJS5OPjo+TkZP68EAAAAHAPy202yNeKrmEYslgsWdr379+vYsWK5WdIAAAAAAAKRJ6+o+vn5yeLxSKLxaIqVarYhd309HRdvnxZ/fr1K/AiAQAAAADIrTwF3VmzZskwDPXq1UvR0dHy8fGx7XNxcVFwcLAaNGhQ4EUCAAAAAJBbeQq6PXv2lCRVqFBBDRs2lLOzc6EUBQAAAABAfuXrzws1adLE9vO1a9eUlpZmt58HBgEAAAAAikq+gu7Vq1c1YsQIxcXF6dy5c1n289RlFIbqY9bLwepe1GUUmsRJbYq6BAAAAMAU8vXU5eHDh+urr77S3LlzZbVa9e677yo6OlqlS5fWokWLCrpGAAAAAAByLV8rup9++qkWLVqkpk2bqlevXmrcuLFCQkJUvnx5LVmyRN27dy/oOgEAAAAAyJV8reieP39eFSpUkPTH93HPnz8vSXrwwQe1ZcuWgqsOAAAAAIA8ylfQrVixohITEyVJ4eHhiouLk/THSq+vr29B1QYAAAAAQJ7lK+g+88wz2r9/vyRp5MiRtu/qDh48WMOHDy/QAgEAAAAAyIt8fUd38ODBtp+bNWumQ4cOac+ePapUqZIiIiIKrDgAAAAAAPIqX0H3z65fv65y5cqpXLlyBVEPAAAAAAB/S75uXU5PT9f48eNVpkwZeXp66scff5QkjRo1SgsWLCjQAgEAAAAAyIt8Bd0JEyYoNjZWU6ZMkYuLi629Ro0aevfddwusOAAAAAAA8ipfQXfRokV6++231b17dzk6Otraa9asqUOHDhVYcQAAAAAA5FW+gu4vv/yikJCQLO0ZGRlKS0v720UBAAAAAJBf+Qq61apVU3x8fJb2Dz/8UPfdd9/fLgoAAAAAgPzK11OXx4wZo6eeekq//PKLMjIytHLlSh0+fFiLFi3SmjVrCrpGAAAAAAByLU8ruj/++KMMw1C7du20fPlyrV27VhaLRaNHj9bBgwf16aefqmXLloVVKwAAAAAAt5WnFd3KlSvr9OnT8vf3V2RkpN577z0dO3ZMAQEBhVUfAAAAAAB5kqcVXcMw7LY///xzXb16tUALAgAAAADg78jXw6gy/TX4AgAAAABQ1PIUdC0WiywWS5Y2AAAAAADuFnn6jq5hGIqKipLVapUkXb9+Xf369ZOHh4ddv5UrVxZchQAAAAAA5EGegm7Pnj3ttnv06FGgxQAAAAAA8HflKejGxMQUVh24jU2bNqlZs2a6cOGCfH19i6SGxMREVahQQfv27VOtWrWKpAYAAAAAuJ2/9TCqu0nTpk01aNCgoi6jQGQ3l4YNG+r06dPy8fEpmqIAAAAA4B/CNEH3dgzD0M2bN4u6jHxzcXFRQEAAD/8CAAAAgNswRdCNiorS5s2bNXv2bNuToWNjY2WxWLR+/XrVrVtXVqtV8fHxOn78uNq3b69SpUrJ09NT9erV05dffmk3XnBwsF577TX16tVLXl5eKleunN5++23b/hs3bmjAgAEKDAyUq6urgoODNXHiRNv+GTNmqEaNGvLw8FBQUJD69++vy5cv251j27ZtatKkidzd3eXn56fIyEhduHAh27kkJiZq06ZNslgsunjxom2MFStWqFq1arJarQoODtb06dPzNI/b2bVrl+677z65urqqbt262rdvn93+9PR09e7dWxUqVJCbm5tCQ0M1e/Zs2/4tW7bI2dlZv/76q91xQ4cO1UMPPZTjeVNTU5WSkmL3AgAAAIDcMkXQnT17tho0aKA+ffro9OnTOn36tIKCgiRJI0aM0MSJE3Xw4EHVrFlTly9fVuvWrfXll19q3759ioyMVLt27ZSUlGQ35vTp023hrn///nruued06NAhSdLrr7+u1atXKy4uTocPH9b777+v4OBg27EODg56/fXX9f3332vhwoX66quvNGLECNv+hIQENW/eXNWqVdOOHTu0detWtWvXTunp6becy5/t3btXnTt3VteuXfW///1PY8eO1ahRoxQbG5vredzKlStX1LZtW4WGhmrv3r0aO3ashg0bZtcnIyNDZcuWVVxcnA4cOKDRo0frv//9r+Li4iRJDz30kCpWrKjFixfbjrl586bef/99PfPMMzmee+LEifLx8bG9sps/AAAAAOTEYhiGUdRFFISmTZuqVq1amjVrlqT/e3jTqlWr1L59+1seW61aNT333HMaMGCApD9WQhs3bmwLaIZhKCAgQNHR0erXr58GDhyoH374QV9++WWubiX+8MMP9dxzz+ns2bOSpG7duikpKUlbt27N1Vz+PJ/Mh1F1795dv//+uzZs2GDrM2LECH322Wf64YcfcjWPW3n77bc1cuRInTx5Uu7u7pKk+fPn67nnnrvlw6j+85//6LffftNHH30kSZoyZYpiY2N14MABSdInn3yiHj166Ndff83yZ6kypaamKjU11badkpKioKAgBQ2Kk4PV/ZZ1/5MlTmpT1CUAAAAAd7WUlBT5+PgoOTlZ3t7eOfYzxYrurdStW9du+8qVKxoxYoTCw8Pl6+srT09PHTp0KMuKbs2aNW0/WywWBQQE6MyZM5L+uFU6ISFBoaGhGjhwoF3YlKSvv/5aLVu2VJkyZeTl5aWnn35a586d05UrVyT934ru33Hw4EE1atTIrq1Ro0Y6evSo0tPTczWP240fERFhC7mS1KBBgyz95s+fr7p166pkyZLy9PTUO++8Y/deRkVF6dixY/rmm28kSe+99546d+6cY8iVJKvVKm9vb7sXAAAAAOSW6YPuXwPV8OHDtWLFCk2YMEHx8fFKSEhQjRo1dOPGDbt+zs7OdtsWi0UZGRmSpNq1a+vEiRMaP368rl27ps6dO6tTp06SpJ9++kmtW7dW9erVtWLFCu3du1dvvvmmJCktLU2S5Obm9rfnZRhGltXk7BbnbzWP241/O3FxcRo8eLB69eqlDRs2KCEhQc8884zde+nv76927dopJiZGZ86c0dq1a9WrV6/bjg0AAAAA+ZWnv6N7N3NxcbFbycxJfHy8oqKi9Nhjj0mSLl++rMTExDyfz9vbW126dFGXLl3UqVMntWrVSufPn9eePXt08+ZNTZ8+XQ4Of/w7QuZ3VjPVrFlTGzduVHR0dL7nEh4enuXW5+3bt6tKlSpydHTM83yyG3/x4sW6du2aLZhnrspmio+PV8OGDdW/f39b2/Hjx7OM9eyzz6pr164qW7asKlWqlGUlGgAAAAAKkmlWdIODg7Vz504lJibq7NmzOa5ahoSEaOXKlUpISND+/fvVrVu3XK1w/tnMmTO1bNkyHTp0SEeOHNGHH36ogIAA+fr6qlKlSrp586bmzJmjH3/8UYsXL9b8+fPtjh85cqR2796t/v3767vvvtOhQ4c0b94823d4czOXoUOHauPGjRo/fryOHDmihQsX6o033sjywKj86tatmxwcHNS7d28dOHBAa9eu1bRp0+z6hISEaM+ePVq/fr2OHDmiUaNGaffu3VnGioyMlI+Pj1599dVbPoQKAAAAAAqCaYLusGHD5OjoqPDwcJUsWTLLd24zzZw5U35+fmrYsKHatWunyMhI1a5dO0/n8vT01OTJk1W3bl3Vq1dPiYmJWrt2rRwcHFSrVi3NmDFDkydPVvXq1bVkyRK7Pz0kSVWqVNGGDRu0f/9+1a9fXw0aNNAnn3wiJyenXM+ldu3aiouL07Jly1S9enWNHj1a48aNU1RUVJ7mcqs5fvrppzpw4IDuu+8+vfzyy5o8ebJdn379+qljx47q0qWL7r//fp07d85udTeTg4ODoqKilJ6erqeffrpA6gMAAACAnJjmqcu4u/Xp00e//fabVq9enedjM5+sxlOXAQAAgHtbbp+6bJrv6OLulJycrN27d2vJkiX65JNPirocAAAAAPcA09y6jLx57bXX5Onpme3r0UcfLbDztG/fXv/617/Ut29ftWzZssDGBQAAAICcsKJ7j+rXr586d+6c7b6C+PNHmTZt2lRgYwEAAABAbhB071HFihVTsWLFiroMAAAAAChw3LoMAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFSciroAILe+j46Ut7d3UZcBAAAA4C7Hii4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVp6IuAMit6mPWy8HqbttOnNSmCKsBAAAAcLdiRRcAAAAAYCoEXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoEXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoEXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoEXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoEXQAAAACAqRB0AQAAAACmQtAFAAAAAJgKQRcAAAAAYCoE3bvE9u3b5ejoqFatWhXouJs2bZLFYtHFixdv2S82Nla+vr4Fem4AAAAAKAoE3bvEe++9p+eff15bt25VUlJSUZcDAAAAAP9YBN27wJUrVxQXF6fnnntObdu2VWxsbJY+q1evVt26deXq6qoSJUqoY8eOtn2pqakaMWKEgoKCZLVaVblyZS1YsECJiYlq1qyZJMnPz08Wi0VRUVFZxt60aZOeeeYZJScny2KxyGKxaOzYsRo3bpxq1KiRpX+dOnU0evRoSVJUVJQ6dOig6Oho+fv7y9vbW3379tWNGzds/Q3D0JQpU1SxYkW5ubkpIiJCH3300d981wAAAAAge05FXQCk5cuXKzQ0VKGhoerRo4eef/55jRo1ShaLRZL02WefqWPHjnr55Ze1ePFi3bhxQ5999pnt+Kefflo7duzQ66+/roiICJ04cUJnz55VUFCQVqxYoccff1yHDx+Wt7e33Nzcspy/YcOGmjVrlkaPHq3Dhw9Lkjw9PXXx4kVFR0dr9+7dqlevniTpu+++0759+/Thhx/ajt+4caNcXV319ddfKzExUc8884xKlCihCRMmSJJeeeUVrVy5UvPmzVPlypW1ZcsW9ejRQyVLllSTJk2y1JOamqrU1FTbdkpKSgG8ywAAAADuFQTdu8CCBQvUo0cPSVKrVq10+fJlbdy4US1atJAkTZgwQV27dlV0dLTtmIiICEnSkSNHFBcXpy+++MLWv2LFirZ+xYoVkyT5+/vn+B1cFxcX+fj4yGKxKCAgwNbu6empyMhIxcTE2IJuTEyMmjRpYncOFxcXvffee3J3d1e1atU0btw4DR8+XOPHj9e1a9c0Y8YMffXVV2rQoIGtvq1bt+qtt97KNuhOnDjRbq4AAAAAkBfculzEDh8+rF27dqlr166SJCcnJ3Xp0kXvvfeerU9CQoKaN2+e7fEJCQlydHTMNjAWhD59+mjp0qW6fv260tLStGTJEvXq1cuuT0REhNzd3W3bDRo00OXLl3Xy5EkdOHBA169fV8uWLeXp6Wl7LVq0SMePH8/2nCNHjlRycrLtdfLkyUKZGwAAAABzYkW3iC1YsEA3b95UmTJlbG2GYcjZ2VkXLlyQn59ftrcbZ7rVvoLQrl07Wa1Wffzxx7JarUpNTdXjjz+eq2MtFosyMjIk/XH79Z/nKElWqzXb46xWa477AAAAAOB2CLpF6ObNm1q0aJGmT5+uRx55xG7f448/riVLlmjAgAGqWbOmNm7cqGeeeSbLGDVq1FBGRoY2b95su3X5z1xcXCRJ6enpt6zFxcUl2z5OTk7q2bOnYmJiZLVa1bVrV7vVW0nav3+/rl27Zgvd33zzjTw9PVW2bFn5+fnJarUqKSmp0FadAQAAAODPCLpFaM2aNbpw4YJ69+4tHx8fu32dOnXSggULNGDAAI0ZM0bNmzdXpUqV1LVrV928eVOff/65RowYoeDgYPXs2VO9evWyPYzqp59+0pkzZ9S5c2eVL19eFotFa9asUevWreXm5iZPT88stQQHB9u+G5x5K3JmoH322WcVFhYmSdq2bVuWY2/cuKHevXvrlVde0U8//aQxY8ZowIABcnBwkJeXl4YNG6bBgwcrIyNDDz74oFJSUrR9+3Z5enqqZ8+ehfDOAgAAALiX8R3dIrRgwQK1aNEiS8iV/ljRTUhI0LfffqumTZvqww8/1OrVq1WrVi09/PDD2rlzp63vvHnz1KlTJ/Xv319Vq1ZVnz59dOXKFUlSmTJlFB0drZdeekmlSpXSgAEDsq2lYcOG6tevn7p06aKSJUtqypQptn2VK1dWw4YNFRoaqvvvvz/Lsc2bN1flypX10EMPqXPnzmrXrp3Gjh1r2z9+/HiNHj1aEydOVFhYmCIjI/Xpp5+qQoUK+X3rAAAAACBHFsMwjKIuAnc3wzBUtWpV9e3bV0OGDLHbFxUVpYsXL2rVqlWFdv6UlBT5+PgoaFCcHKz/d9t04qQ2hXZOAAAAAHefzGyQnJwsb2/vHPtx6zJu6cyZM1q8eLF++eWXbL8jDAAAAAB3G4IubqlUqVIqUaKE3n77bfn5+RV1OQAAAABwWwRd3NLt7myPjY29M4UAAAAAQC7xMCoAAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYilNRFwDk1vfRkfL29i7qMgAAAADc5VjRBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkEXAAAAAGAqBF0AAAAAgKkQdAEAAAAApkLQBQAAAACYCkG3EI0dO1a1atUq6jKyZRiG/v3vf6tYsWKyWCxKSEjI1XGxsbHy9fUt1NoAAAAA4O9wKuoC/qksFsst9/fs2VNvvPGGnn/++TtUUd6sW7dOsbGx2rRpkypWrKgSJUoUdUkAAAAAUCAIuvl0+vRp28/Lly/X6NGjdfjwYVubm5ubPD095enpWRTl3dbx48cVGBiohg0bFnUpAAAAAFCguHU5nwICAmwvHx8fWSyWLG1/vXU5KipKHTp00GuvvaZSpUrJ19dX0dHRunnzpoYPH65ixYqpbNmyeu+99+zO9csvv6hLly7y8/NT8eLF1b59eyUmJt6yvs2bN6t+/fqyWq0KDAzUSy+9pJs3b9rqeP7555WUlCSLxaLg4OAcx4mNjVW5cuXk7u6uxx57TOfOnbPbf/z4cbVv316lSpWSp6en6tWrpy+//NK2f9y4capRo0aWcevUqaPRo0ffcg4AAAAAkB8E3Tvsq6++0qlTp7RlyxbNmDFDY8eOVdu2beXn56edO3eqX79+6tevn06ePClJunr1qpo1ayZPT09t2bJFW7dulaenp1q1aqUbN25ke45ffvlFrVu3Vr169bR//37NmzdPCxYs0KuvvipJmj17tsaNG6eyZcvq9OnT2r17d7bj7Ny5U7169VL//v2VkJCgZs2a2cbIdPnyZbVu3Vpffvml9u3bp8jISLVr105JSUmSpF69eunAgQN25/juu++0b98+RUVFZXve1NRUpaSk2L0AAAAAILcIundYsWLF9Prrrys0NFS9evVSaGiorl69qv/+97+qXLmyRo4cKRcXF23btk2StGzZMjk4OOjdd99VjRo1FBYWppiYGCUlJWnTpk3ZnmPu3LkKCgrSG2+8oapVq6pDhw6Kjo7W9OnTlZGRIR8fH3l5ecnR0VEBAQEqWbJktuPMnj1bkZGReumll1SlShUNHDhQkZGRdn0iIiLUt29f1ahRQ5UrV9arr76qihUravXq1ZKksmXLKjIyUjExMbZjYmJi1KRJE1WsWDHb806cOFE+Pj62V1BQUF7fZgAAAAD3MILuHVatWjU5OPzf216qVCm7W3sdHR1VvHhxnTlzRpK0d+9eHTt2TF5eXrbv/BYrVkzXr1/X8ePHsz3HwYMH1aBBA7sHZjVq1EiXL1/Wzz//nOtaM8f5s79uX7lyRSNGjFB4eLh8fX3l6empQ4cO2VZ0JalPnz5aunSprl+/rrS0NC1ZskS9evXK8bwjR45UcnKy7ZW5ug0AAAAAucHDqO4wZ2dnu22LxZJtW0ZGhiQpIyNDderU0ZIlS7KMldNKrGEYWZ4KbRiGbezcyjzmVoYPH67169dr2rRpCgkJkZubmzp16mR3W3W7du1ktVr18ccfy2q1KjU1VY8//niOY1qtVlmt1lzXCQAAAAB/RtC9y9WuXVvLly+Xv7+/vL29c3VMeHi4VqxYYRd4t2/fLi8vL5UpUybX5w4PD9c333xj1/bX7fj4eEVFRemxxx6T9Md3dv/6oCwnJyf17NlTMTExslqt6tq1q9zd3XNdBwAAAADkBbcu3+W6d++uEiVKqH379oqPj9eJEye0efNmvfDCCznehty/f3+dPHlSzz//vA4dOqRPPvlEY8aM0ZAhQ+xum76dgQMHat26dZoyZYqOHDmiN954Q+vWrbPrExISopUrVyohIUH79+9Xt27dbKvRf/bss8/qq6++0ueff37L25YBAAAA4O8i6N7l3N3dtWXLFpUrV04dO3ZUWFiYevXqpWvXruW4wlumTBmtXbtWu3btUkREhPr166fevXvrlVdeydO5H3jgAb377ruaM2eOatWqpQ0bNmQZY+bMmfLz81PDhg3Vrl07RUZGqnbt2lnGqly5sho2bKjQ0FDdf//9eaoDAAAAAPLCYuTmi5jA32QYhqpWraq+fftqyJAheTo2JSVFPj4+Sk5OzvXt2wAAAADMJ7fZgO/ootCdOXNGixcv1i+//KJnnnmmqMsBAAAAYHIEXRS6UqVKqUSJEnr77bfl5+dX1OUAAAAAMDmCLgodd8cDAAAAuJN4GBUAAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFRMH3SbNm2qQYMG3TXj3CkWi0WrVq0q6jKydTfXBgAAAOCfz/RBd+XKlRo/fvxt+0VFRclisWR5HTt27A5UWfiym9uDDz5Y1GUBAAAAQIFzKuoCCluxYsVy3bdVq1aKiYmxaytZsmRBl1RkYmJi1KpVK9u2i4tLtv3S0tLk7Ox8p8oCAAAAgAJl+hXdP99yPHfuXFWuXFmurq4qVaqUOnXqZNfXarUqICDA7uXo6JjtuO+//77q1q0rLy8vBQQEqFu3bjpz5oxdn9WrV6ty5cpyc3NTs2bNtHDhQlksFl28eNHW55133lFQUJDc3d312GOPacaMGfL19bUb59NPP1WdOnXk6uqqihUrKjo6Wjdv3rTtP3r0qB566CG5uroqPDxcX3zxRbY1+/r62s2tWLFiSkxMlMViUVxcnJo2bSpXV1e9//77OnfunJ588kmVLVtW7u7uqlGjhpYuXWo3XnBwsGbNmmXXVqtWLY0dOzbPtQEAAABAQTH9im6mPXv2aODAgVq8eLEaNmyo8+fPKz4+Pt/j3bhxQ+PHj1doaKjOnDmjwYMHKyoqSmvXrpUkJSYmqlOnTnrhhRf07LPPat++fRo2bJjdGNu2bVO/fv00efJk/etf/9KXX36pUaNG2fVZv369evTooddff12NGzfW8ePH9e9//1uSNGbMGGVkZKhjx44qUaKEvvnmG6WkpOTru8Qvvviipk+frpiYGFmtVl2/fl116tTRiy++KG9vb3322Wd66qmnVLFiRd1///25GjO/taWmpio1NdW2nZKSkuf5AAAAALiHGSbXpEkT44UXXjBWrFhheHt7GykpKdn269mzp+Ho6Gh4eHjYXp06dcoyTk527dplSDIuXbpkGIZhvPjii0b16tXt+rz88suGJOPChQuGYRhGly5djDZt2tj16d69u+Hj42Pbbty4sfHaa6/Z9Vm8eLERGBhoGIZhrF+/3nB0dDROnjxp2//5558bkoyPP/7Y1ibJcHV1tZvfxx9/bJw4ccKQZMyaNSvHuWVq3bq1MXToUNt2+fLljZkzZ9r1iYiIMMaMGZOn2v5qzJgxhqQsr+Tk5NvWCAAAAMC8kpOTc5UN7pkV3ZYtW6p8+fKqWLGiWrVqpVatWumxxx6Tu7u7rU+zZs00b94827aHh0eO4+3bt09jx45VQkKCzp8/r4yMDElSUlKSwsPDdfjwYdWrV8/umPr169ttHz58WI899liWPmvWrLFt7927V7t379aECRNsbenp6bp+/bquXr2qgwcPqly5cipbtqxtf4MGDbKteebMmWrRooVtOzAwUL///rskqW7dunZ909PTNWnSJC1fvly//PKLbZX1Vu/JX+Wltj8bOXKkhgwZYttOSUlRUFBQrs8LAAAA4N52zwRdLy8vffvtt9q0aZM2bNig0aNHa+zYsdq9e7ftO7EeHh4KCQm57VhXrlzRI488okceeUTvv/++SpYsqaSkJEVGRurGjRuSJMMwZLFY7I4zDCPL9u36ZGRkKDo6Wh07dsxSh6ura5b+krKMmSkgICDL/DKD7l8D7PTp0zVz5kzNmjVLNWrUkIeHhwYNGmSbnyQ5ODhkOX9aWlqOc7lVbX9mtVpltVpv2w8AAAAAsnPPBF1JcnJyUosWLdSiRQuNGTNGvr6++uqrr7INkbdy6NAhnT17VpMmTbKtNO7Zs8euT9WqVW3f182UXZ9du3bdsk/t2rV1+PDhHAN4eHi4kpKSdOrUKZUuXVqStGPHjjzNJzvx8fFq3769evToIemPwH306FGFhYXZ+pQsWVKnT5+2baekpOjEiROFXhsAAAAA3Irpn7qcac2aNXr99deVkJCgn376SYsWLVJGRoZCQ0PzPFa5cuXk4uKiOXPm6Mcff9Tq1auz/K3evn376tChQ3rxxRd15MgRxcXFKTY2VtL/rWo+//zzWrt2rWbMmKGjR4/qrbfe0ueff2636jl69GgtWrRIY8eO1Q8//KCDBw9q+fLleuWVVyRJLVq0UGhoqJ5++mnt379f8fHxevnll/P5Lv2fkJAQffHFF9q+fbsOHjyovn376tdff7Xr8/DDD2vx4sWKj4/X999/r549e9o9pbqwagMAAACAW7lngq6vr69Wrlyphx9+WGFhYZo/f76WLl2qatWq5XmskiVLKjY2Vh9++KHCw8M1adIkTZs2za5PhQoV9NFHH2nlypWqWbOm5s2bZwt5mbflNmrUSPPnz9eMGTMUERGhdevWafDgwXJ1dbWNExkZqTVr1uiLL75QvXr19MADD2jGjBkqX768pD9uH/7444+Vmpqq+vXr69lnn7X7Pm9+jRo1SrVr11ZkZKSaNm2qgIAAdejQwa7PyJEj9dBDD6lt27Zq3bq1OnTooEqVKtn2F1ZtAAAAAHArFiO7L1KiUEyYMEHz58/XyZMnc+zTp08fHTp06G/96SOzSUlJkY+Pj5KTk+Xt7V3U5QAAAAAoIrnNBvfUd3TvtLlz56pevXoqXry4tm3bpqlTp2rAgAF2faZNm6aWLVvKw8NDn3/+uRYuXKi5c+cWUcUAAAAA8M9H0C1ER48e1auvvqrz58+rXLlyGjp0qEaOHGnXZ9euXZoyZYouXbqkihUr6vXXX9ezzz5bRBUDAAAAwD8fty7jrsetywAAAACk3GeDe+ZhVAAAAACAewNBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgTdQrRp0yZZLBZdvHixqEspMsHBwZo1a1ZRlwEAAADgHlKkQbdp06YaNGhQUZZQYLKbS8OGDXX69Gn5+PgUTVF3UGxsrHx9fYu6DAAAAAC4u1d0DcPQzZs3i7qMfHNxcVFAQIAsFktRlwIAAAAA94wiC7pRUVHavHmzZs+eLYvFIovFotjYWFksFq1fv15169aV1WpVfHy8jh8/rvbt26tUqVLy9PRUvXr19OWXX9qNFxwcrNdee029evWSl5eXypUrp7ffftu2/8aNGxowYIACAwPl6uqq4OBgTZw40bZ/xowZqlGjhjw8PBQUFKT+/fvr8uXLdufYtm2bmjRpInd3d/n5+SkyMlIXLlzIdi6JiYnZ3rq8YsUKVatWTVarVcHBwZo+fXqe5nEriYmJslgsiouLU+PGjeXm5qZ69erpyJEj2r17t+rWrStPT0+1atVKv//+u+24jIwMjRs3TmXLlpXValWtWrW0bt26LOOuXLlSzZo1k7u7uyIiIrRjxw5Jf9yi/cwzzyg5Odk2/7Fjx9qOv3r1ar7mAwAAAAD5YhSRixcvGg0aNDD69OljnD592jh9+rTx5ZdfGpKMmjVrGhs2bDCOHTtmnD171khISDDmz59vfPfdd8aRI0eMl19+2XB1dTV++ukn23jly5c3ihUrZrz55pvG0aNHjYkTJxoODg7GwYMHDcMwjKlTpxpBQUHGli1bjMTERCM+Pt744IMPbMfPnDnT+Oqrr4wff/zR2LhxoxEaGmo899xztv379u0zrFar8dxzzxkJCQnG999/b8yZM8f4/fffs53LzZs3ja+//tqQZFy4cMEwDMPYs2eP4eDgYIwbN844fPiwERMTY7i5uRkxMTG5nsetnDhxwpBkVK1a1Vi3bp1x4MAB44EHHjBq165tNG3a1Ni6davx7bffGiEhIUa/fv1sx82YMcPw9vY2li5dahw6dMgYMWKE4ezsbBw5ciTLuGvWrDEOHz5sdOrUyShfvryRlpZmpKamGrNmzTK8vb1t87906VK+53P9+nUjOTnZ9jp58qQhyUhOTr7tewAAAADAvJKTk3OVDYos6BqGYTRp0sR44YUXbNuZwXDVqlW3PTY8PNyYM2eObbt8+fJGjx49bNsZGRmGv7+/MW/ePMMwDOP55583Hn74YSMjIyNXtcXFxRnFixe3bT/55JNGo0aNcj2XP88nM+h269bNaNmypV2f4cOHG+Hh4bmex61kBtJ3333X1rZ06VJDkrFx40Zb28SJE43Q0FDbdunSpY0JEybYjVWvXj2jf//+OY77ww8/GJJsgTUmJsbw8fHJUlN+5jNmzBhDUpYXQRcAAAC4t+U26N6V39GtW7eu3faVK1c0YsQIhYeHy9fXV56enjp06JCSkpLs+tWsWdP2s8ViUUBAgM6cOSPpj1ulExISFBoaqoEDB2rDhg12x3799ddq2bKlypQpIy8vLz399NM6d+6crly5IklKSEhQ8+bN/9a8Dh48qEaNGtm1NWrUSEePHlV6enqu5pEbfz6+VKlSkqQaNWrYtWWOl5KSolOnTmVb18GDB3McNzAwUJJyVVde5zNy5EglJyfbXidPnrztOQAAAAAg010ZdD08POy2hw8frhUrVmjChAmKj49XQkKCatSooRs3btj1c3Z2ttu2WCzKyMiQJNWuXVsnTpzQ+PHjde3aNXXu3FmdOnWSJP30009q3bq1qlevrhUrVmjv3r168803JUlpaWmSJDc3t789L8MwsjyYyjCMLP1uNY/c+PPxmef7a9tfx8uurr+2ZTduburK63ysVqu8vb3tXgAAAACQW0UadF1cXOxWMnMSHx+vqKgoPfbYY6pRo4YCAgKUmJiY5/N5e3urS5cueuedd7R8+XKtWLFC58+f1549e3Tz5k1Nnz5dDzzwgKpUqaJTp07ZHVuzZk1t3Ljxb80lPDxcW7dutWvbvn27qlSpIkdHxzzPpyB4e3urdOnS2dYVFhaW63Fy+7sEAAAAgMLmVJQnDw4O1s6dO5WYmChPT88cV/lCQkK0cuVKtWvXThaLRaNGjcrTCqckzZw5U4GBgapVq5YcHBz04YcfKiAgQL6+vqpUqZJu3rypOXPmqF27dtq2bZvmz59vd/zIkSNVo0YN9e/fX/369ZOLi4u+/vprPfHEEypRokSWuRQrVixLDUOHDlW9evU0fvx4denSRTt27NAbb7yhuXPn5mkuBW348OEaM2aMKlWqpFq1aikmJkYJCQlasmRJrscIDg7W5cuXtXHjRkVERMjd3V3u7u6FWDUAAAAAZK9IV3SHDRsmR0dHhYeHq2TJklm+c5tp5syZ8vPzU8OGDdWuXTtFRkaqdu3aeTqXp6enJk+erLp166pevXpKTEzU2rVr5eDgoFq1amnGjBmaPHmyqlevriVLltj96SFJqlKlijZs2KD9+/erfv36atCggT755BM5OTnlei61a9dWXFycli1bpurVq2v06NEaN26coqKi8jSXgjZw4EANHTpUQ4cOVY0aNbRu3TqtXr1alStXzvUYDRs2VL9+/dSlSxeVLFlSU6ZMKcSKAQAAACBnFiO7L4kCd5GUlBT5+PgoOTmZ7+sCAAAA97DcZoO78mFUAAAAAADkF0H3H+S1116Tp6dntq9HH320qMsDAAAAgLsCty7/g5w/f17nz5/Pdp+bm5vKlClzhyu6M7h1GQAAAICU+2xQpE9dRt4UK1Ys26c5AwAAAAD+D7cuAwAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMxamoCwBuxzAMSVJKSkoRVwIAAACgKGVmgsyMkBOCLu56586dkyQFBQUVcSUAAAAA7gaXLl2Sj49PjvsJurjrFStWTJKUlJR0y4sZSElJUVBQkE6ePClvb++iLgd3Ma4V5BbXCnKLawW5wXXy9xmGoUuXLql06dK37EfQxV3PweGPr5L7+PjwgYBc8fb25lpBrnCtILe4VpBbXCvIDa6Tvyc3i188jAoAAAAAYCoEXQAAAACAqRB0cdezWq0aM2aMrFZrUZeCuxzXCnKLawW5xbWC3OJaQW5wndw5FuN2z2UGAAAAAOAfhBVdAAAAAICpEHQBAAAAAKZC0AUAAAAAmApBFwAAAABgKgRd3HFz585VhQoV5Orqqjp16ig+Pv6W/Tdv3qw6derI1dVVFStW1Pz587P0WbFihcLDw2W1WhUeHq6PP/64sMrHHVTQ10psbKwsFkuW1/Xr1wtzGrgD8nKtnD59Wt26dVNoaKgcHBw0aNCgbPvxuWJOBX2t8LliXnm5VlauXKmWLVuqZMmS8vb2VoMGDbR+/fos/fhcMaeCvlb4XCkYBF3cUcuXL9egQYP08ssva9++fWrcuLEeffRRJSUlZdv/xIkTat26tRo3bqx9+/bpv//9rwYOHKgVK1bY+uzYsUNdunTRU089pf379+upp55S586dtXPnzjs1LRSCwrhWJMnb21unT5+2e7m6ut6JKaGQ5PVaSU1NVcmSJfXyyy8rIiIi2z58rphTYVwrEp8rZpTXa2XLli1q2bKl1q5dq71796pZs2Zq166d9u3bZ+vD54o5Fca1IvG5UiAM4A6qX7++0a9fP7u2qlWrGi+99FK2/UeMGGFUrVrVrq1v377GAw88YNvu3Lmz0apVK7s+kZGRRteuXQuoahSFwrhWYmJiDB8fnwKvFUUrr9fKnzVp0sR44YUXsrTzuWJOhXGt8LliTn/nWskUHh5uREdH27b5XDGnwrhW+FwpGKzo4o65ceOG9u7dq0ceecSu/ZFHHtH27duzPWbHjh1Z+kdGRmrPnj1KS0u7ZZ+cxsTdr7CuFUm6fPmyypcvr7Jly6pt27ZZ/gUV/yz5uVZyg88V8ymsa0Xic8VsCuJaycjI0KVLl1SsWDFbG58r5lNY14rE50pBIOjijjl79qzS09NVqlQpu/ZSpUrp119/zfaYX3/9Ndv+N2/e1NmzZ2/ZJ6cxcfcrrGulatWqio2N1erVq7V06VK5urqqUaNGOnr0aOFMBIUuP9dKbvC5Yj6Fda3wuWI+BXGtTJ8+XVeuXFHnzp1tbXyumE9hXSt8rhQMp6IuAPcei8Vit20YRpa22/X/a3tex8Q/Q0FfKw888IAeeOAB2/5GjRqpdu3amjNnjl5//fWCKhtFoDA+A/hcMaeC/r3yuWJe+b1Wli5dqrFjx+qTTz6Rv79/gYyJu1tBXyt8rhQMgi7umBIlSsjR0THLv3CdOXMmy7+EZQoICMi2v5OTk4oXL37LPjmNibtfYV0rf+Xg4KB69erxL6T/YPm5VnKDzxXzKaxr5a/4XPnn+zvXyvLly9W7d299+OGHatGihd0+PlfMp7Culb/icyV/uHUZd4yLi4vq1KmjL774wq79iy++UMOGDbM9pkGDBln6b9iwQXXr1pWzs/Mt++Q0Ju5+hXWt/JVhGEpISFBgYGDBFI47Lj/XSm7wuWI+hXWt/BWfK/98+b1Wli5dqqioKH3wwQdq06ZNlv18rphPYV0rf8XnSj4VxROwcO9atmyZ4ezsbCxYsMA4cOCAMWjQIMPDw8NITEw0DMMwXnrpJeOpp56y9f/xxx8Nd3d3Y/DgwcaBAweMBQsWGM7OzsZHH31k67Nt2zbD0dHRmDRpknHw4EFj0qRJhpOTk/HNN9/c8fmh4BTGtTJ27Fhj3bp1xvHjx419+/YZzzzzjOHk5GTs3Lnzjs8PBSev14phGMa+ffuMffv2GXXq1DG6detm7Nu3z/jhhx9s+/lcMafCuFb4XDGnvF4rH3zwgeHk5GS8+eabxunTp22vixcv2vrwuWJOhXGt8LlSMAi6uOPefPNNo3z58oaLi4tRu3ZtY/PmzbZ9PXv2NJo0aWLXf9OmTcZ9991nuLi4GMHBwca8efOyjPnhhx8aoaGhhrOzs1G1alVjxYoVhT0N3AEFfa0MGjTIKFeunOHi4mKULFnSeOSRR4zt27ffiamgkOX1WpGU5VW+fHm7PnyumFNBXyt8rphXXq6VJk2aZHut9OzZ025MPlfMqaCvFT5XCobFMP7/01oAAAAAADABvqMLAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAAAAADAVgi4AAAAAwFQIugAAAAAAUyHoAgAAAABMhaALAIBJbNq0SRaLRRcvXpQkxcbGytfXt1DPGRUVpQ4dOhTqOQAAyCuCLgAAfxEVFSWLxaJJkybZta9atUoWi6WIqsq7Ll266MiRI0Vaw1/D992oadOmGjRoUFGXkWtvvfWWIiIi5OHhIV9fX913332aPHlyUZcFAHcVgi4AANlwdXXV5MmTdeHChQId98aNGwU63q24ubnJ39//jp3vnyYtLa2oS8izBQsWaMiQIRo4cKD279+vbdu2acSIEbp8+XKhnfOf+D4BAEEXAIBstGjRQgEBAZo4ceIt+61YsULVqlWT1WpVcHCwpk+fbrc/ODhYr776qqKiouTj46M+ffrYbiles2aNQkND5e7urk6dOunKlStauHChgoOD5efnp+eff17p6em2sd5//33VrVtXXl5eCggIULdu3XTmzJkca/vrrcvBwcGyWCxZXpl++eUXdenSRX5+fipevLjat2+vxMRE2/709HQNGTJEvr6+Kl68uEaMGCHDMHL5jtrXlNe5BwcHa/z48erWrZs8PT1VunRpzZkzx27spKQktW/fXp6envL29lbnzp3122+/2faPHTtWtWrV0nvvvaeKFSvKarWqZ8+e2rx5s2bPnm17PxITE5Wenq7evXurQoUKcnNzU2hoqGbPnm13vszbtqdNm6bAwEAVL15c//nPf+yCYWpqqkaMGKGgoCBZrVZVrlxZCxYssO0/cOCAWrduLU9PT5UqVUpPPfWUzp49m+P79+mnn6pz587q3bu3QkJCVK1aNT355JMaP368Xb/33nvPdl0GBgZqwIABf+t9MgxDycnJ+ve//y1/f395e3vr4Ycf1v79+2/3KweAIkHQBQAgG46Ojnrttdc0Z84c/fzzz9n22bt3rzp37qyuXbvqf//7n8aOHatRo0YpNjbWrt/UqVNVvXp17d27V6NGjZIkXb16Va+//rqWLVumdevWadOmTerYsaPWrl2rtWvXavHixXr77bf10Ucf2ca5ceOGxo8fr/3792vVqlU6ceKEoqKicj2n3bt36/Tp0zp9+rR+/vlnPfDAA/+vvbsPaer74wD+9qtJD7PnUZN0o2LZWmUrKJO0yJxRoWllJbgY9KTUCuuP7JH8Zz0IYc+FlVCUi7D6QzIxtWYtUwsiNd3KDMqiFlFRUd3z+0O8fMempt++9f3J+wX745x7z7nnfK7gzj3nnmHGjBlye2bNmgWFQoGbN2/CbrdDoVAgLi5OnoXOzs7GqVOnkJubC7vdDrfbjYKCgi5EFd3ue1scJ0yYgJqaGmzZsgUbN25EcXExAEAIgYSEBLjdbpSXl6O4uBgulwvJyckedTidTthsNly6dAkPHjxATk4OIiIisHLlSjk2ISEhkCQJI0aMgM1mQ21tLXbs2IHMzEzYbDaP+kpLS+FyuVBaWoq8vDycOXPG4/6npqbiwoULyMnJQV1dHY4dOwaFQgEAePnyJaKjoxEeHo6qqipcu3YNr169wpIlS9qN3fDhw+FwOPDs2bN2zzl69CjS09OxatUqPHz4EFevXsXo0aP/UZwAYN68eWhpaUFhYSGqq6thMBgwe/ZsuN3udttCRPTHCCIiIvJgMplEfHy8EEKIadOmCbPZLIQQoqCgQPz9X+fy5cvFnDlzPMpu3rxZ6HQ6Oa1Wq0VCQoLHOadPnxYAhNPplPNWr14t+vbtKz58+CDnGY1GsXr16nbbWVlZKQDIZUpLSwUA8e7dO/k6AwYM8Fl2/fr1Qq1Wi9evXwshhMjNzRVjxowRkiTJ53z9+lX06dNHFBUVCSGEUKlUwmq1yse/ffsmRowYIcfKF19t6k7f1Wq1iIuL86g7OTlZzJ07VwghxPXr14W/v79obm6Wjz969EgAEJWVlUIIIXbu3Cl69eol97lNdHS0sFgs7fahTVpamkhKSpLTJpNJqNVq8f37dzlv8eLFIjk5WQghxOPHjwUAUVxc7LO+7du3i9jYWI+858+fCwDi8ePHPsu8ePFCTJs2TQAQWq1WmEwmkZ+fL378+CGfExwcLLZu3eqzfHfjVFJSIvr37y++fPniUd+oUaPE8ePHfV6LiOhP4owuERFRB/bs2YO8vDzU1tZ6Haurq0NkZKRHXmRkJBobGz2W3U6ZMsWrbN++fTFq1Cg5PWzYMGg0Gnm2ry3v70uT79+/j/j4eKjVagQFBWHmzJkAWpeidsWJEyeQm5uLK1euQKlUAmidnXY6nQgKCoJCoYBCocDgwYPx5csXuFwuvH//Hi9fvkRERIRcT0BAgM++daY7fQfgce22dF1dHYDWexESEoKQkBD5uE6nw8CBA+VzAECtVst97syxY8cwZcoUKJVKKBQKnDx50ivW48aNg7+/v5xWqVRyux88eAB/f39ER0f7rL+6uhqlpaVyvBUKBcLCwgAALpfLZxmVSoU7d+7g4cOHWL9+Pb59+waTyYS4uDhIkoTXr1/jxYsXmD17ts/y3Y1TdXU1Pn78iCFDhni09+nTp+22lYjoTwr40w0gIiL6L4uKioLRaERmZqbXMmEhhNcuzMLHO6v9+vXzyuvVq5dH2s/Pz2eeJEkAgE+fPiE2NhaxsbE4e/YslEolmpubYTQau7TBVVlZGdatW4fz589j4sSJcr4kSZg8eTLOnTvnVeZnB4Y/q6t970hb/H3dC1/5vu6FLzabDRs3bkR2djYiIiIQFBSEffv24e7du532pa3dffr06fAakiRhwYIFPndMVqlUHZbV6/XQ6/VIT0+H3W7HjBkzUF5e3umDh+7GSZIkqFQqlJWVeZX9t3/CioioOzjQJSIi6oTVakV4eDi0Wq1Hvk6ng91u98i7ffs2tFqtxyzfr1BfX483b97AarXKs3FVVVVdqsPpdCIpKQmZmZlITEz0OGYwGJCfny9vNOSLSqWCw+FAVFQUAOD79+/yu5q/g8Ph8Eq3zYDqdDo0Nzfj+fPncnxqa2vx/v17jB07tsN6AwMDPWbgAeDWrVuYPn060tLS5LyuzlyOHz8ekiShvLwcMTExXscNBgMuXboEjUaDgIDufyXT6XQAWh+GBAUFQaPRoKSkBLNmzfJ5bnfiZDAY0NLSgoCAAGg0mm63lYjod+HSZSIiok6MHz8eKSkpXrv8ZmRkoKSkBFlZWWhoaEBeXh4OHTqETZs2/fI2hIaGIjAwEAcPHsSTJ09w9epVr512O/L582csWLAA4eHhWLVqFVpaWuQPAKSkpGDo0KGIj4/HrVu38PTpU5SXl8NiscibcVksFlitVhQUFKC+vh5paWm/9fdxKyoqsHfvXjQ0NODw4cO4ePEiLBYLgNZdsidMmICUlBTU1NSgsrISqampiI6O7nSWU6PR4O7du2hqasKbN28gSRJGjx6NqqoqFBUVoaGhAdu3b8e9e/e61F6NRgOTyQSz2SxvHlZWViZvaJWeng63241ly5ahsrIST548wfXr12E2m70G3m3Wrl2LrKwsVFRU4NmzZ3A4HEhNTYVSqZSXdu/atQvZ2dnIyclBY2Mjampq5L/d7sYpJiYGERERSEhIQFFREZqamnD79m1s27atyw9ciIh+Bw50iYiIfkJWVpbXsmSDwQCbzYYLFy5Ar9djx44d2L17d5d2Qv5ZSqUSZ86cwcWLF6HT6WC1WrF///6fLv/q1SvU19fjxo0bCA4Ohkqlkj9A63uzN2/eRGhoKBITEzF27FiYzWZ8/vxZnuHNyMhAamoqVqxYIS/nXbhw4S/va3syMjJQXV2NSZMmISsrC9nZ2TAajQBalwxfvnwZgwYNQlRUFGJiYjBy5Ejk5+d3Wu+mTZvg7+8PnU4nLwlfs2YNEhMTkZycjKlTp+Lt27ces7s/6+jRo1i0aBHS0tIQFhaGlStX4tOnTwCA4OBgVFRU4MePHzAajdDr9bBYLBgwYAD++sv3V7SYmBg4HA4sXrwYWq0WSUlJ6N27N0pKSjBkyBAAgMlkwoEDB3DkyBGMGzcO8+fPR2Nj4z+Kk5+fHwoLCxEVFQWz2QytVoulS5eiqakJw4YN63JciIj+bX7C18tERERERP8hGo0GGzZswIYNG/50U4iI6P8AZ3SJiIiIiIioR+FAl4iIiIiIiHoULl0mIiIiIiKiHoUzukRERERERNSjcKBLREREREREPQoHukRERERERNSjcKBLREREREREPQoHukRERERERNSjcKBLREREREREPQoHukRERERERNSjcKBLREREREREPcr/AGqeVrJlYEX+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newbalanceOrig</td>\n",
       "      <td>0.265682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldbalanceOrg</td>\n",
       "      <td>0.257862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>0.209194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amount</td>\n",
       "      <td>0.160327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unusuallogin</td>\n",
       "      <td>0.084002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>transaction_day</td>\n",
       "      <td>0.020570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acct type</td>\n",
       "      <td>0.001837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Time of day</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>isFlaggedFraud</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>transaction_month</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "3     newbalanceOrig    0.265682\n",
       "2      oldbalanceOrg    0.257862\n",
       "0               type    0.209194\n",
       "1             amount    0.160327\n",
       "4       unusuallogin    0.084002\n",
       "9    transaction_day    0.020570\n",
       "6          Acct type    0.001837\n",
       "7        Time of day    0.000527\n",
       "5     isFlaggedFraud    0.000000\n",
       "8  transaction_month    0.000000"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = best_cb_model.feature_importances_\n",
    "\n",
    "\n",
    "importances = importances / importances.sum()\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "        'Feature':  X_train.columns,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 9))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.xlabel(\"Normalized Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "af62795a-4b15-4e9f-8d3c-28c819550a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with Importance > 1%:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newbalanceOrig</td>\n",
       "      <td>0.265682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldbalanceOrg</td>\n",
       "      <td>0.257862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>0.209194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amount</td>\n",
       "      <td>0.160327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unusuallogin</td>\n",
       "      <td>0.084002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>transaction_day</td>\n",
       "      <td>0.020570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature  Importance\n",
       "3   newbalanceOrig    0.265682\n",
       "2    oldbalanceOrg    0.257862\n",
       "0             type    0.209194\n",
       "1           amount    0.160327\n",
       "4     unusuallogin    0.084002\n",
       "9  transaction_day    0.020570"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features_df = importance_df[importance_df['Importance'] > 0.01]\n",
    "\n",
    "print(\"Features with Importance > 1%:\")\n",
    "important_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "69edbc3d-8591-41a3-ad77-a066dcb1b361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['newbalanceOrig',\n",
       " 'oldbalanceOrg',\n",
       " 'type',\n",
       " 'amount',\n",
       " 'unusuallogin',\n",
       " 'transaction_day']"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features_df.Feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "62961c61-6d4e-40d4-9983-85910103d11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Values Summary (Selected Features)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x390 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "selected_features = [\n",
    "  'newbalanceOrig',\n",
    " 'oldbalanceOrg',\n",
    " 'type',\n",
    " 'amount',\n",
    " 'unusuallogin',\n",
    " 'transaction_day']\n",
    "\n",
    "\n",
    "\n",
    "explainer = shap.TreeExplainer(best_cb_model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "\n",
    "shap_df = pd.DataFrame(shap_values, columns=X_train.columns)\n",
    "shap_selected = shap_df[selected_features]\n",
    "X_selected = X_train[selected_features]\n",
    "\n",
    "\n",
    "print(\"SHAP Values Summary (Selected Features)\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_selected.values, X_selected, show=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "f76fb01a-6e46-49a1-beec-83d2a2783e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop(['transaction_day'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "1f1235ba-4079-497d-8d1a-15a4224eff25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['newbalanceOrig',\n",
       " 'oldbalanceOrg',\n",
       " 'type',\n",
       " 'amount',\n",
       " 'unusuallogin',\n",
       " 'transaction_day']"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features_df['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "23bc2ccb-8b56-47fc-a2d8-b70e0d8a3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_input = new_data[['newbalanceOrig',\n",
    " 'oldbalanceOrg',\n",
    " 'type',\n",
    " 'amount',\n",
    " 'unusuallogin']]\n",
    "fin_output = new_data['isFraud']\n",
    "\n",
    "X_train_fin, X_test_fin, y_train_fin, y_test_fin = train_test_split(fin_input, fin_output, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "4545056a-b082-47ab-a039-a3925c48956b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 15:42:09,521] A new study created in memory with name: no-name-df4e7065-262d-4aa1-85c1-c729854afd68\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\954626614.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\954626614.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.1, 10), # Regularization term that prevents overfitting by penalizing large parameter values.\n",
      "[I 2025-09-07 15:42:10,287] Trial 0 finished with value: 0.8111439072130602 and parameters: {'iterations': 178, 'learning_rate': 0.06134107153300721, 'depth': 8, 'l2_leaf_reg': 7.9584138077670685, 'loss_function': 'Logloss'}. Best is trial 0 with value: 0.8111439072130602.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.811\n",
      "  Params:  {'iterations': 178, 'learning_rate': 0.06134107153300721, 'depth': 8, 'l2_leaf_reg': 7.9584138077670685, 'loss_function': 'Logloss'}\n"
     ]
    }
   ],
   "source": [
    "def best_params_for_model(trial):\n",
    "\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 500),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.1, 10), # Regularization term that prevents overfitting by penalizing large parameter values.\n",
    "        # 'cat_features': [],  # Handle categorical features separately\n",
    "        'loss_function': trial.suggest_categorical('loss_function', ['Logloss']) # For regression tasks, use ‘RMSE,’ while for classification, use ‘Logloss’.\n",
    "    }\n",
    "\n",
    "    cb_clf = CatBoostClassifier(**param)\n",
    "\n",
    "    auc = cross_val_score(cb_clf, X_train_fin, y_train_fin, cv=2, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    return auc\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(best_params_for_model, n_trials=1)\n",
    "\n",
    "print('Best trial:')\n",
    "best_params = study.best_params\n",
    "print('  Value: {:.3f}'.format(study.best_value))\n",
    "print('  Params: ', best_params)\n",
    "\n",
    "best_cb_model_fin = CatBoostClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "ba1b51cc-d51f-43a2-9849-3e3020553861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6426495\ttotal: 7.09ms\tremaining: 1.25s\n",
      "1:\tlearn: 0.5936753\ttotal: 9.75ms\tremaining: 858ms\n",
      "2:\tlearn: 0.5511158\ttotal: 13.1ms\tremaining: 765ms\n",
      "3:\tlearn: 0.5133452\ttotal: 17.5ms\tremaining: 762ms\n",
      "4:\tlearn: 0.4792443\ttotal: 21.8ms\tremaining: 755ms\n",
      "5:\tlearn: 0.4476021\ttotal: 27.2ms\tremaining: 779ms\n",
      "6:\tlearn: 0.4174495\ttotal: 28.6ms\tremaining: 700ms\n",
      "7:\tlearn: 0.3915636\ttotal: 33.1ms\tremaining: 702ms\n",
      "8:\tlearn: 0.3682888\ttotal: 37.7ms\tremaining: 707ms\n",
      "9:\tlearn: 0.3462424\ttotal: 41.9ms\tremaining: 704ms\n",
      "10:\tlearn: 0.3262502\ttotal: 46.4ms\tremaining: 705ms\n",
      "11:\tlearn: 0.3074072\ttotal: 50.9ms\tremaining: 703ms\n",
      "12:\tlearn: 0.2901191\ttotal: 55ms\tremaining: 699ms\n",
      "13:\tlearn: 0.2731450\ttotal: 56.4ms\tremaining: 661ms\n",
      "14:\tlearn: 0.2585267\ttotal: 61.2ms\tremaining: 665ms\n",
      "15:\tlearn: 0.2456128\ttotal: 66.8ms\tremaining: 676ms\n",
      "16:\tlearn: 0.2320088\ttotal: 68.3ms\tremaining: 647ms\n",
      "17:\tlearn: 0.2196728\ttotal: 72.1ms\tremaining: 641ms\n",
      "18:\tlearn: 0.2092875\ttotal: 79.2ms\tremaining: 663ms\n",
      "19:\tlearn: 0.1992604\ttotal: 87.3ms\tremaining: 690ms\n",
      "20:\tlearn: 0.1908603\ttotal: 98.3ms\tremaining: 735ms\n",
      "21:\tlearn: 0.1827505\ttotal: 105ms\tremaining: 746ms\n",
      "22:\tlearn: 0.1742107\ttotal: 113ms\tremaining: 762ms\n",
      "23:\tlearn: 0.1664194\ttotal: 119ms\tremaining: 763ms\n",
      "24:\tlearn: 0.1589735\ttotal: 123ms\tremaining: 754ms\n",
      "25:\tlearn: 0.1526111\ttotal: 129ms\tremaining: 752ms\n",
      "26:\tlearn: 0.1462360\ttotal: 134ms\tremaining: 747ms\n",
      "27:\tlearn: 0.1408089\ttotal: 139ms\tremaining: 746ms\n",
      "28:\tlearn: 0.1353966\ttotal: 146ms\tremaining: 751ms\n",
      "29:\tlearn: 0.1305832\ttotal: 152ms\tremaining: 750ms\n",
      "30:\tlearn: 0.1260201\ttotal: 157ms\tremaining: 747ms\n",
      "31:\tlearn: 0.1216299\ttotal: 163ms\tremaining: 742ms\n",
      "32:\tlearn: 0.1172535\ttotal: 168ms\tremaining: 738ms\n",
      "33:\tlearn: 0.1135892\ttotal: 174ms\tremaining: 735ms\n",
      "34:\tlearn: 0.1101623\ttotal: 180ms\tremaining: 734ms\n",
      "35:\tlearn: 0.1065857\ttotal: 185ms\tremaining: 729ms\n",
      "36:\tlearn: 0.1030943\ttotal: 188ms\tremaining: 715ms\n",
      "37:\tlearn: 0.0998276\ttotal: 192ms\tremaining: 706ms\n",
      "38:\tlearn: 0.0967345\ttotal: 197ms\tremaining: 701ms\n",
      "39:\tlearn: 0.0940195\ttotal: 202ms\tremaining: 695ms\n",
      "40:\tlearn: 0.0913052\ttotal: 211ms\tremaining: 704ms\n",
      "41:\tlearn: 0.0890793\ttotal: 217ms\tremaining: 703ms\n",
      "42:\tlearn: 0.0868097\ttotal: 223ms\tremaining: 700ms\n",
      "43:\tlearn: 0.0848138\ttotal: 228ms\tremaining: 694ms\n",
      "44:\tlearn: 0.0828174\ttotal: 232ms\tremaining: 686ms\n",
      "45:\tlearn: 0.0808508\ttotal: 237ms\tremaining: 680ms\n",
      "46:\tlearn: 0.0787548\ttotal: 241ms\tremaining: 672ms\n",
      "47:\tlearn: 0.0770924\ttotal: 245ms\tremaining: 664ms\n",
      "48:\tlearn: 0.0754970\ttotal: 249ms\tremaining: 655ms\n",
      "49:\tlearn: 0.0739306\ttotal: 253ms\tremaining: 649ms\n",
      "50:\tlearn: 0.0724665\ttotal: 258ms\tremaining: 643ms\n",
      "51:\tlearn: 0.0708025\ttotal: 262ms\tremaining: 636ms\n",
      "52:\tlearn: 0.0692008\ttotal: 267ms\tremaining: 629ms\n",
      "53:\tlearn: 0.0680224\ttotal: 269ms\tremaining: 617ms\n",
      "54:\tlearn: 0.0669814\ttotal: 273ms\tremaining: 610ms\n",
      "55:\tlearn: 0.0659156\ttotal: 277ms\tremaining: 603ms\n",
      "56:\tlearn: 0.0647364\ttotal: 281ms\tremaining: 597ms\n",
      "57:\tlearn: 0.0638429\ttotal: 286ms\tremaining: 591ms\n",
      "58:\tlearn: 0.0628142\ttotal: 287ms\tremaining: 579ms\n",
      "59:\tlearn: 0.0618529\ttotal: 291ms\tremaining: 573ms\n",
      "60:\tlearn: 0.0610083\ttotal: 292ms\tremaining: 561ms\n",
      "61:\tlearn: 0.0604107\ttotal: 296ms\tremaining: 554ms\n",
      "62:\tlearn: 0.0595812\ttotal: 301ms\tremaining: 550ms\n",
      "63:\tlearn: 0.0587714\ttotal: 307ms\tremaining: 546ms\n",
      "64:\tlearn: 0.0580522\ttotal: 311ms\tremaining: 540ms\n",
      "65:\tlearn: 0.0573598\ttotal: 315ms\tremaining: 535ms\n",
      "66:\tlearn: 0.0567784\ttotal: 318ms\tremaining: 527ms\n",
      "67:\tlearn: 0.0562648\ttotal: 322ms\tremaining: 522ms\n",
      "68:\tlearn: 0.0556453\ttotal: 327ms\tremaining: 516ms\n",
      "69:\tlearn: 0.0550436\ttotal: 331ms\tremaining: 511ms\n",
      "70:\tlearn: 0.0546498\ttotal: 335ms\tremaining: 505ms\n",
      "71:\tlearn: 0.0542556\ttotal: 339ms\tremaining: 499ms\n",
      "72:\tlearn: 0.0538220\ttotal: 343ms\tremaining: 493ms\n",
      "73:\tlearn: 0.0532780\ttotal: 347ms\tremaining: 487ms\n",
      "74:\tlearn: 0.0528409\ttotal: 351ms\tremaining: 482ms\n",
      "75:\tlearn: 0.0524575\ttotal: 356ms\tremaining: 477ms\n",
      "76:\tlearn: 0.0521394\ttotal: 360ms\tremaining: 472ms\n",
      "77:\tlearn: 0.0519057\ttotal: 364ms\tremaining: 467ms\n",
      "78:\tlearn: 0.0516175\ttotal: 368ms\tremaining: 462ms\n",
      "79:\tlearn: 0.0513628\ttotal: 372ms\tremaining: 456ms\n",
      "80:\tlearn: 0.0511476\ttotal: 376ms\tremaining: 450ms\n",
      "81:\tlearn: 0.0508812\ttotal: 381ms\tremaining: 446ms\n",
      "82:\tlearn: 0.0504905\ttotal: 385ms\tremaining: 441ms\n",
      "83:\tlearn: 0.0501650\ttotal: 389ms\tremaining: 436ms\n",
      "84:\tlearn: 0.0498526\ttotal: 394ms\tremaining: 431ms\n",
      "85:\tlearn: 0.0496114\ttotal: 399ms\tremaining: 427ms\n",
      "86:\tlearn: 0.0494136\ttotal: 403ms\tremaining: 422ms\n",
      "87:\tlearn: 0.0492094\ttotal: 408ms\tremaining: 417ms\n",
      "88:\tlearn: 0.0489088\ttotal: 413ms\tremaining: 413ms\n",
      "89:\tlearn: 0.0487311\ttotal: 417ms\tremaining: 408ms\n",
      "90:\tlearn: 0.0484573\ttotal: 423ms\tremaining: 404ms\n",
      "91:\tlearn: 0.0481699\ttotal: 427ms\tremaining: 399ms\n",
      "92:\tlearn: 0.0478875\ttotal: 432ms\tremaining: 395ms\n",
      "93:\tlearn: 0.0477925\ttotal: 437ms\tremaining: 390ms\n",
      "94:\tlearn: 0.0476238\ttotal: 441ms\tremaining: 385ms\n",
      "95:\tlearn: 0.0474898\ttotal: 445ms\tremaining: 380ms\n",
      "96:\tlearn: 0.0473694\ttotal: 449ms\tremaining: 375ms\n",
      "97:\tlearn: 0.0472363\ttotal: 453ms\tremaining: 370ms\n",
      "98:\tlearn: 0.0471052\ttotal: 457ms\tremaining: 365ms\n",
      "99:\tlearn: 0.0468616\ttotal: 462ms\tremaining: 360ms\n",
      "100:\tlearn: 0.0467736\ttotal: 465ms\tremaining: 355ms\n",
      "101:\tlearn: 0.0465810\ttotal: 469ms\tremaining: 350ms\n",
      "102:\tlearn: 0.0464952\ttotal: 474ms\tremaining: 345ms\n",
      "103:\tlearn: 0.0462966\ttotal: 478ms\tremaining: 340ms\n",
      "104:\tlearn: 0.0462081\ttotal: 482ms\tremaining: 335ms\n",
      "105:\tlearn: 0.0460559\ttotal: 486ms\tremaining: 330ms\n",
      "106:\tlearn: 0.0458596\ttotal: 490ms\tremaining: 325ms\n",
      "107:\tlearn: 0.0456661\ttotal: 494ms\tremaining: 320ms\n",
      "108:\tlearn: 0.0455055\ttotal: 498ms\tremaining: 315ms\n",
      "109:\tlearn: 0.0453454\ttotal: 502ms\tremaining: 310ms\n",
      "110:\tlearn: 0.0452098\ttotal: 506ms\tremaining: 305ms\n",
      "111:\tlearn: 0.0451440\ttotal: 510ms\tremaining: 300ms\n",
      "112:\tlearn: 0.0450922\ttotal: 514ms\tremaining: 296ms\n",
      "113:\tlearn: 0.0449743\ttotal: 518ms\tremaining: 291ms\n",
      "114:\tlearn: 0.0448417\ttotal: 522ms\tremaining: 286ms\n",
      "115:\tlearn: 0.0446982\ttotal: 525ms\tremaining: 281ms\n",
      "116:\tlearn: 0.0446071\ttotal: 530ms\tremaining: 276ms\n",
      "117:\tlearn: 0.0445714\ttotal: 532ms\tremaining: 270ms\n",
      "118:\tlearn: 0.0445080\ttotal: 536ms\tremaining: 266ms\n",
      "119:\tlearn: 0.0444377\ttotal: 537ms\tremaining: 260ms\n",
      "120:\tlearn: 0.0444127\ttotal: 538ms\tremaining: 254ms\n",
      "121:\tlearn: 0.0442969\ttotal: 542ms\tremaining: 249ms\n",
      "122:\tlearn: 0.0441640\ttotal: 546ms\tremaining: 244ms\n",
      "123:\tlearn: 0.0441002\ttotal: 550ms\tremaining: 240ms\n",
      "124:\tlearn: 0.0440493\ttotal: 554ms\tremaining: 235ms\n",
      "125:\tlearn: 0.0439931\ttotal: 558ms\tremaining: 230ms\n",
      "126:\tlearn: 0.0439217\ttotal: 563ms\tremaining: 226ms\n",
      "127:\tlearn: 0.0438310\ttotal: 567ms\tremaining: 221ms\n",
      "128:\tlearn: 0.0437942\ttotal: 571ms\tremaining: 217ms\n",
      "129:\tlearn: 0.0437313\ttotal: 576ms\tremaining: 213ms\n",
      "130:\tlearn: 0.0436907\ttotal: 580ms\tremaining: 208ms\n",
      "131:\tlearn: 0.0435395\ttotal: 584ms\tremaining: 204ms\n",
      "132:\tlearn: 0.0434744\ttotal: 589ms\tremaining: 199ms\n",
      "133:\tlearn: 0.0434287\ttotal: 593ms\tremaining: 195ms\n",
      "134:\tlearn: 0.0434150\ttotal: 594ms\tremaining: 189ms\n",
      "135:\tlearn: 0.0432465\ttotal: 598ms\tremaining: 185ms\n",
      "136:\tlearn: 0.0432075\ttotal: 602ms\tremaining: 180ms\n",
      "137:\tlearn: 0.0431517\ttotal: 607ms\tremaining: 176ms\n",
      "138:\tlearn: 0.0430862\ttotal: 611ms\tremaining: 171ms\n",
      "139:\tlearn: 0.0430020\ttotal: 616ms\tremaining: 167ms\n",
      "140:\tlearn: 0.0429717\ttotal: 620ms\tremaining: 163ms\n",
      "141:\tlearn: 0.0428770\ttotal: 624ms\tremaining: 158ms\n",
      "142:\tlearn: 0.0427587\ttotal: 629ms\tremaining: 154ms\n",
      "143:\tlearn: 0.0426937\ttotal: 634ms\tremaining: 150ms\n",
      "144:\tlearn: 0.0426860\ttotal: 635ms\tremaining: 145ms\n",
      "145:\tlearn: 0.0426639\ttotal: 639ms\tremaining: 140ms\n",
      "146:\tlearn: 0.0426293\ttotal: 644ms\tremaining: 136ms\n",
      "147:\tlearn: 0.0425674\ttotal: 648ms\tremaining: 131ms\n",
      "148:\tlearn: 0.0425070\ttotal: 653ms\tremaining: 127ms\n",
      "149:\tlearn: 0.0424689\ttotal: 657ms\tremaining: 123ms\n",
      "150:\tlearn: 0.0423910\ttotal: 661ms\tremaining: 118ms\n",
      "151:\tlearn: 0.0423435\ttotal: 666ms\tremaining: 114ms\n",
      "152:\tlearn: 0.0423239\ttotal: 670ms\tremaining: 110ms\n",
      "153:\tlearn: 0.0422772\ttotal: 674ms\tremaining: 105ms\n",
      "154:\tlearn: 0.0422000\ttotal: 679ms\tremaining: 101ms\n",
      "155:\tlearn: 0.0421780\ttotal: 683ms\tremaining: 96.3ms\n",
      "156:\tlearn: 0.0421487\ttotal: 687ms\tremaining: 91.8ms\n",
      "157:\tlearn: 0.0420801\ttotal: 691ms\tremaining: 87.4ms\n",
      "158:\tlearn: 0.0420622\ttotal: 696ms\tremaining: 83.2ms\n",
      "159:\tlearn: 0.0420383\ttotal: 701ms\tremaining: 78.8ms\n",
      "160:\tlearn: 0.0419930\ttotal: 706ms\tremaining: 74.5ms\n",
      "161:\tlearn: 0.0419531\ttotal: 711ms\tremaining: 70.2ms\n",
      "162:\tlearn: 0.0418466\ttotal: 715ms\tremaining: 65.8ms\n",
      "163:\tlearn: 0.0417825\ttotal: 721ms\tremaining: 61.5ms\n",
      "164:\tlearn: 0.0417421\ttotal: 725ms\tremaining: 57.1ms\n",
      "165:\tlearn: 0.0417085\ttotal: 730ms\tremaining: 52.8ms\n",
      "166:\tlearn: 0.0416611\ttotal: 735ms\tremaining: 48.4ms\n",
      "167:\tlearn: 0.0415660\ttotal: 741ms\tremaining: 44.1ms\n",
      "168:\tlearn: 0.0415269\ttotal: 746ms\tremaining: 39.7ms\n",
      "169:\tlearn: 0.0415227\ttotal: 748ms\tremaining: 35.2ms\n",
      "170:\tlearn: 0.0414907\ttotal: 752ms\tremaining: 30.8ms\n",
      "171:\tlearn: 0.0414740\ttotal: 757ms\tremaining: 26.4ms\n",
      "172:\tlearn: 0.0414348\ttotal: 762ms\tremaining: 22ms\n",
      "173:\tlearn: 0.0414320\ttotal: 764ms\tremaining: 17.6ms\n",
      "174:\tlearn: 0.0414181\ttotal: 769ms\tremaining: 13.2ms\n",
      "175:\tlearn: 0.0414035\ttotal: 774ms\tremaining: 8.79ms\n",
      "176:\tlearn: 0.0413774\ttotal: 778ms\tremaining: 4.4ms\n",
      "177:\tlearn: 0.0413634\ttotal: 784ms\tremaining: 0us\n",
      "Model Performance for CB opitimized for selected features\n",
      "Train Gini prob is 72.01542457937697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8004\n",
      "           1       1.00      0.19      0.32        96\n",
      "\n",
      "    accuracy                           0.99      8100\n",
      "   macro avg       1.00      0.59      0.66      8100\n",
      "weighted avg       0.99      0.99      0.99      8100\n",
      "\n",
      "[[8004    0]\n",
      " [  78   18]]\n",
      "Model Performance for CB opitimized for selected features\n",
      "Test Gini prob is 67.02900195161803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2003\n",
      "           1       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.99      2025\n",
      "   macro avg       1.00      0.55      0.58      2025\n",
      "weighted avg       0.99      0.99      0.99      2025\n",
      "\n",
      "[[2003    0]\n",
      " [  20    2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7201542457937697, 0.6702900195161803]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate_model('CB opitimized for selected features', best_cb_model_fin, X_train_fin, y_train_fin, X_test_fin, y_test_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67877b20-025a-4f96-9458-02a794f80e12",
   "metadata": {},
   "source": [
    "# deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "6dbf3392-f551-4938-b2ad-571798c07c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>branch</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>unusuallogin</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>Acct type</th>\n",
       "      <th>Date of transaction</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>Irak</td>\n",
       "      <td>386683.04</td>\n",
       "      <td>C1373577787</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C33524623</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>504.83</td>\n",
       "      <td>C49365994</td>\n",
       "      <td>608907.09</td>\n",
       "      <td>608402.27</td>\n",
       "      <td>M1529649769</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>13/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Costa de Marfil</td>\n",
       "      <td>9805.46</td>\n",
       "      <td>C480184864</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1433956626</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>54395.20</td>\n",
       "      <td>C391915263</td>\n",
       "      <td>587.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1531333864</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>6/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Argelia</td>\n",
       "      <td>24258.10</td>\n",
       "      <td>C247576438</td>\n",
       "      <td>394.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M775635860</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>11/1/2018</td>\n",
       "      <td>Night</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>235409.03</td>\n",
       "      <td>C1538844412</td>\n",
       "      <td>10500000.00</td>\n",
       "      <td>10700000.00</td>\n",
       "      <td>C1538745405</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>19/1/2018</td>\n",
       "      <td>Night</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>29351.64</td>\n",
       "      <td>C853343978</td>\n",
       "      <td>10000000.00</td>\n",
       "      <td>10100000.00</td>\n",
       "      <td>C187649742</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>6/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>Turquia</td>\n",
       "      <td>363482.02</td>\n",
       "      <td>C1457226878</td>\n",
       "      <td>25365.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1899073220</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>13/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>Alemania</td>\n",
       "      <td>31980.86</td>\n",
       "      <td>C1558129795</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C257999182</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>13194.66</td>\n",
       "      <td>C1500512598</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M510536150</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>8/1/2018</td>\n",
       "      <td>Night</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          type           branch     amount     nameOrig  oldbalanceOrg  \\\n",
       "0     CASH_OUT             Irak  386683.04  C1373577787           0.00   \n",
       "1      PAYMENT   Estados Unidos     504.83    C49365994      608907.09   \n",
       "2      PAYMENT  Costa de Marfil    9805.46   C480184864           0.00   \n",
       "3     CASH_OUT           Mexico   54395.20   C391915263         587.49   \n",
       "4      PAYMENT          Argelia   24258.10   C247576438         394.00   \n",
       "...        ...              ...        ...          ...            ...   \n",
       "1007   CASH_IN           Mexico  235409.03  C1538844412    10500000.00   \n",
       "1008   CASH_IN           Mexico   29351.64   C853343978    10000000.00   \n",
       "1009  CASH_OUT          Turquia  363482.02  C1457226878       25365.85   \n",
       "1010  CASH_OUT         Alemania   31980.86  C1558129795           0.00   \n",
       "1011   PAYMENT           Mexico   13194.66  C1500512598           0.00   \n",
       "\n",
       "      newbalanceOrig     nameDest  unusuallogin  isFlaggedFraud Acct type  \\\n",
       "0               0.00    C33524623            12               0   Savings   \n",
       "1          608402.27  M1529649769             8               0   Savings   \n",
       "2               0.00  M1433956626            19               0   Savings   \n",
       "3               0.00  C1531333864             9               0   Current   \n",
       "4               0.00   M775635860             7               0   Savings   \n",
       "...              ...          ...           ...             ...       ...   \n",
       "1007     10700000.00  C1538745405            13               0   Savings   \n",
       "1008     10100000.00   C187649742            20               0   Savings   \n",
       "1009            0.00  C1899073220             7               0   Savings   \n",
       "1010            0.00   C257999182            13               0   Savings   \n",
       "1011            0.00   M510536150             4               0   Savings   \n",
       "\n",
       "     Date of transaction Time of day    id  \n",
       "0               7/1/2018     Morning     1  \n",
       "1              13/1/2018   Afternoon     2  \n",
       "2               7/1/2018     Morning     3  \n",
       "3               6/1/2018   Afternoon     4  \n",
       "4              11/1/2018       Night     5  \n",
       "...                  ...         ...   ...  \n",
       "1007           19/1/2018       Night  1008  \n",
       "1008            6/1/2018   Afternoon  1009  \n",
       "1009           13/1/2018   Afternoon  1010  \n",
       "1010            7/1/2018     Morning  1011  \n",
       "1011            8/1/2018       Night  1012  \n",
       "\n",
       "[1012 rows x 13 columns]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_excel(r'C:\\Users\\Aysel Quliyeva\\Desktop\\data science with python\\lesson 19\\fraud_deploy_data.xlsx')\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "f8d09c6f-e699-43be-9e5a-1d44729ae621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['newbalanceOrig', 'oldbalanceOrg', 'type', 'amount', 'unusuallogin'], dtype='object')"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_input.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "b0a9bc88-eac1-4f93-a64a-186e7d89b04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>unusuallogin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>386683.04</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608402.27</td>\n",
       "      <td>608907.09</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>504.83</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9805.46</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>587.49</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>54395.20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>394.00</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>24258.10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>10700000.00</td>\n",
       "      <td>10500000.00</td>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>235409.03</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>10100000.00</td>\n",
       "      <td>10000000.00</td>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>29351.64</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>0.00</td>\n",
       "      <td>25365.85</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>363482.02</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>31980.86</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>13194.66</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      newbalanceOrig  oldbalanceOrg      type     amount  unusuallogin\n",
       "0               0.00           0.00  CASH_OUT  386683.04            12\n",
       "1          608402.27      608907.09   PAYMENT     504.83             8\n",
       "2               0.00           0.00   PAYMENT    9805.46            19\n",
       "3               0.00         587.49  CASH_OUT   54395.20             9\n",
       "4               0.00         394.00   PAYMENT   24258.10             7\n",
       "...              ...            ...       ...        ...           ...\n",
       "1007     10700000.00    10500000.00   CASH_IN  235409.03            13\n",
       "1008     10100000.00    10000000.00   CASH_IN   29351.64            20\n",
       "1009            0.00       25365.85  CASH_OUT  363482.02             7\n",
       "1010            0.00           0.00  CASH_OUT   31980.86            13\n",
       "1011            0.00           0.00   PAYMENT   13194.66             4\n",
       "\n",
       "[1012 rows x 5 columns]"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_data = test[['newbalanceOrig', 'oldbalanceOrg', 'type', 'amount', 'unusuallogin']]\n",
    "\n",
    "deploy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "6fe5420b-7538-4aa2-9539-c170f92107be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aysel Quliyeva\\AppData\\Local\\Temp\\ipykernel_3908\\599973220.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  deploy_data[i] = le.transform(deploy_data[i])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>unusuallogin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>386683.04</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608402.27</td>\n",
       "      <td>608907.09</td>\n",
       "      <td>3</td>\n",
       "      <td>504.83</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>9805.46</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>587.49</td>\n",
       "      <td>1</td>\n",
       "      <td>54395.20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>394.00</td>\n",
       "      <td>3</td>\n",
       "      <td>24258.10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   newbalanceOrig  oldbalanceOrg  type     amount  unusuallogin\n",
       "0            0.00           0.00     1  386683.04            12\n",
       "1       608402.27      608907.09     3     504.83             8\n",
       "2            0.00           0.00     3    9805.46            19\n",
       "3            0.00         587.49     1   54395.20             9\n",
       "4            0.00         394.00     3   24258.10             7"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in ['type']:\n",
    "    le = encoders[i]   # use the encoder fitted on training\n",
    "    deploy_data[i] = le.transform(deploy_data[i])\n",
    "\n",
    "\n",
    "deploy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "9e272656-073a-40a3-b523-1a4e1660dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_data = deploy_data[X_train_fin.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "74e770bb-199b-44d2-9c89-cda30814361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>branch</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>unusuallogin</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>Acct type</th>\n",
       "      <th>Date of transaction</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>id</th>\n",
       "      <th>prediction_isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>Irak</td>\n",
       "      <td>386683.04</td>\n",
       "      <td>C1373577787</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C33524623</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>504.83</td>\n",
       "      <td>C49365994</td>\n",
       "      <td>608907.09</td>\n",
       "      <td>608402.27</td>\n",
       "      <td>M1529649769</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>13/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Costa de Marfil</td>\n",
       "      <td>9805.46</td>\n",
       "      <td>C480184864</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1433956626</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>54395.20</td>\n",
       "      <td>C391915263</td>\n",
       "      <td>587.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1531333864</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Current</td>\n",
       "      <td>6/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>4</td>\n",
       "      <td>0.011715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Argelia</td>\n",
       "      <td>24258.10</td>\n",
       "      <td>C247576438</td>\n",
       "      <td>394.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M775635860</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>11/1/2018</td>\n",
       "      <td>Night</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>235409.03</td>\n",
       "      <td>C1538844412</td>\n",
       "      <td>10500000.00</td>\n",
       "      <td>10700000.00</td>\n",
       "      <td>C1538745405</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>19/1/2018</td>\n",
       "      <td>Night</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.007076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>29351.64</td>\n",
       "      <td>C853343978</td>\n",
       "      <td>10000000.00</td>\n",
       "      <td>10100000.00</td>\n",
       "      <td>C187649742</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>6/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1009</td>\n",
       "      <td>0.012319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>Turquia</td>\n",
       "      <td>363482.02</td>\n",
       "      <td>C1457226878</td>\n",
       "      <td>25365.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1899073220</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>13/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1010</td>\n",
       "      <td>0.015880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>Alemania</td>\n",
       "      <td>31980.86</td>\n",
       "      <td>C1558129795</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C257999182</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.010012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>13194.66</td>\n",
       "      <td>C1500512598</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M510536150</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>8/1/2018</td>\n",
       "      <td>Night</td>\n",
       "      <td>1012</td>\n",
       "      <td>0.006476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          type           branch     amount     nameOrig  oldbalanceOrg  \\\n",
       "0     CASH_OUT             Irak  386683.04  C1373577787           0.00   \n",
       "1      PAYMENT   Estados Unidos     504.83    C49365994      608907.09   \n",
       "2      PAYMENT  Costa de Marfil    9805.46   C480184864           0.00   \n",
       "3     CASH_OUT           Mexico   54395.20   C391915263         587.49   \n",
       "4      PAYMENT          Argelia   24258.10   C247576438         394.00   \n",
       "...        ...              ...        ...          ...            ...   \n",
       "1007   CASH_IN           Mexico  235409.03  C1538844412    10500000.00   \n",
       "1008   CASH_IN           Mexico   29351.64   C853343978    10000000.00   \n",
       "1009  CASH_OUT          Turquia  363482.02  C1457226878       25365.85   \n",
       "1010  CASH_OUT         Alemania   31980.86  C1558129795           0.00   \n",
       "1011   PAYMENT           Mexico   13194.66  C1500512598           0.00   \n",
       "\n",
       "      newbalanceOrig     nameDest  unusuallogin  isFlaggedFraud Acct type  \\\n",
       "0               0.00    C33524623            12               0   Savings   \n",
       "1          608402.27  M1529649769             8               0   Savings   \n",
       "2               0.00  M1433956626            19               0   Savings   \n",
       "3               0.00  C1531333864             9               0   Current   \n",
       "4               0.00   M775635860             7               0   Savings   \n",
       "...              ...          ...           ...             ...       ...   \n",
       "1007     10700000.00  C1538745405            13               0   Savings   \n",
       "1008     10100000.00   C187649742            20               0   Savings   \n",
       "1009            0.00  C1899073220             7               0   Savings   \n",
       "1010            0.00   C257999182            13               0   Savings   \n",
       "1011            0.00   M510536150             4               0   Savings   \n",
       "\n",
       "     Date of transaction Time of day    id  prediction_isFraud  \n",
       "0               7/1/2018     Morning     1            0.005399  \n",
       "1              13/1/2018   Afternoon     2            0.007265  \n",
       "2               7/1/2018     Morning     3            0.006459  \n",
       "3               6/1/2018   Afternoon     4            0.011715  \n",
       "4              11/1/2018       Night     5            0.006468  \n",
       "...                  ...         ...   ...                 ...  \n",
       "1007           19/1/2018       Night  1008            0.007076  \n",
       "1008            6/1/2018   Afternoon  1009            0.012319  \n",
       "1009           13/1/2018   Afternoon  1010            0.015880  \n",
       "1010            7/1/2018     Morning  1011            0.010012  \n",
       "1011            8/1/2018       Night  1012            0.006476  \n",
       "\n",
       "[1012 rows x 14 columns]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['prediction_isFraud'] = best_cb_model_fin.predict_proba(deploy_data)[:,1]\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "4c1bc187-69b4-4581-9caa-bc403f4fd8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>branch</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>unusuallogin</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>Acct type</th>\n",
       "      <th>Date of transaction</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>id</th>\n",
       "      <th>prediction_isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>120074.73</td>\n",
       "      <td>C1409933277</td>\n",
       "      <td>120074.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C162114152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>25/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>402</td>\n",
       "      <td>0.178277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>El Salvador</td>\n",
       "      <td>120074.73</td>\n",
       "      <td>C1174000532</td>\n",
       "      <td>120074.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C410033330</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>3/1/2018</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>436</td>\n",
       "      <td>0.280606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>93296.50</td>\n",
       "      <td>C2105764938</td>\n",
       "      <td>50762.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C35126588</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>8/1/2018</td>\n",
       "      <td>Morning</td>\n",
       "      <td>913</td>\n",
       "      <td>0.116785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type          branch     amount     nameOrig  oldbalanceOrg  \\\n",
       "401  TRANSFER            Cuba  120074.73  C1409933277      120074.73   \n",
       "435  CASH_OUT     El Salvador  120074.73  C1174000532      120074.73   \n",
       "912  TRANSFER  Estados Unidos   93296.50  C2105764938       50762.00   \n",
       "\n",
       "     newbalanceOrig    nameDest  unusuallogin  isFlaggedFraud Acct type  \\\n",
       "401             0.0  C162114152             1               0   Savings   \n",
       "435             0.0  C410033330             1               0   Savings   \n",
       "912             0.0   C35126588             1               0   Savings   \n",
       "\n",
       "    Date of transaction Time of day   id  prediction_isFraud  \n",
       "401           25/1/2018     Morning  402            0.178277  \n",
       "435            3/1/2018   Afternoon  436            0.280606  \n",
       "912            8/1/2018     Morning  913            0.116785  "
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['prediction_isFraud']>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabfc13-ef76-4d38-9741-4ce0b22f9774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
